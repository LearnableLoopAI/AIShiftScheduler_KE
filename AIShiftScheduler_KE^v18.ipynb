{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L732Yo4caboD"
      },
      "source": [
        "---\n",
        "title: Automatic and optimal shift scheduling using Reinforcement Learning (Part 5)\n",
        "subtitle: Using Sequential Decision Analytics to find ongoing optimal decisions\n",
        "author: Kobus Esterhuysen\n",
        "date: '2023-11-04'\n",
        "date-modified: last-modified\n",
        "categories:\n",
        "  - Retail Industry\n",
        "  - Scheduling\n",
        "  - Powell Unified Framework\n",
        "  - Reinforcement Learning\n",
        "  - Python\n",
        "image: AIShiftScheduler1.png\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 4\n",
        "    toc-expand: true\n",
        "    toc-title: TOC\n",
        "    code-fold: false\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s92-2LrHdvqA",
        "outputId": "44160500-8c35-49b7-f760-a478e3bbf215"
      },
      "outputs": [],
      "source": [
        "#- !pip install mojo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Meo2j8Kjw-Wl"
      },
      "outputs": [],
      "source": [
        "# hide\n",
        "# BASED ON\n",
        "  # AIShiftScheduler_KE^v17.ipynb\n",
        "  # AIShiftScheduler_KE^v16.ipynb\n",
        "  # AIShiftScheduler_KE^v15.ipynb\n",
        "  # AIShiftScheduler_KE^v14.ipynb\n",
        "  # AIShiftScheduler_KE^v11.ipynb\n",
        "  # AIShiftScheduler_KE^v10.ipynb\n",
        "  # AIShiftScheduler_KE^v9.ipynb\n",
        "  # AIShiftScheduler_KE^v8.ipynb\n",
        "  # AIShiftScheduler_KE^v7.ipynb\n",
        "  # AIShiftScheduler_KE^v6.ipynb\n",
        "  # AIShiftScheduler_KE^v5.ipynb\n",
        "  # AIShiftScheduler_KE^v4.ipynb\n",
        "  # AIShiftScheduler_KE^v3.ipynb\n",
        "  # AIShiftScheduler_KE^v2.ipynb\n",
        "  # AIShiftScheduler_KE^v1.ipynb\n",
        "  # FractionalHR_KE^v1.ipynb\n",
        "  # CarRental_KE^v4.ipynb\n",
        "  # CarRental_KE^v3.ipynb\n",
        "  # CarRental_KE^v2.ipynb\n",
        "  # CarRental_KE^v1.ipynb\n",
        "  # InventoryStorage_KE^v4.ipynb\n",
        "\n",
        "# DONE\n",
        "# v1 starts ------------------------------------------------\n",
        "# added thHi (resources shifts below thHi considered for alloc)\n",
        "# v2 starts ------------------------------------------------\n",
        "# added Ucum for unallocated demands\n",
        "# updated text\n",
        "# v3 starts ------------------------------------------------\n",
        "# published\n",
        "# added DOW (day-of-week) availabilities\n",
        "# v4 starts ------------------------------------------------\n",
        "# published\n",
        "# tracking Ucum by resource type in addition to overall/total\n",
        "  # will inform what resource type to hire/fire\n",
        "# changed avails to candidates\n",
        "# changed thHi to thCumShifts\n",
        "# having datetimes in addition to t values\n",
        "  # https://www.youtube.com/watch?v=UFuo7EHI8zc\n",
        "  # https://matplotlib.org/stable/gallery/text_labels_and_annotations/date.html\n",
        "  # https://matplotlib.org/stable/api/dates_api.html\n",
        "  # subtract dates give Timedelta; each step add a Timedelta\n",
        "  # don't plot with datetime x-labels - too cluttered\n",
        "# added thSickProb and compare with each resource's SICK_PROB for the month\n",
        "  # resource's SICK_PROB for the month must be lower than thSickProb to\n",
        "  # be a candidate\n",
        "  # setup params by month for prob. of calling in sick for each resource\n",
        "# v5 starts ------------------------------------------------\n",
        "# published\n",
        "# changed X__AllocBelow to X__Alloc\n",
        "# having costs/contributions instead of excluding candidates below thCumShifts & thSickProb\n",
        "  # agent exploits by having thCumShifts & thSickProb around max so\n",
        "  #   that it can use the complete pool\n",
        "  # Ccum_CumShifts = -(RCumShifts - RCapacity) //Capacity in # shifts/week\n",
        "  # Ccum_SickProb = -SICK_PROB(R, month)\n",
        "  # LATER: Ccum_Merits = MERITS(R) //merits dissipate over time; positive or negative merits\n",
        "  # for thetas have the weights between\n",
        "    # thCumShifts*Ccum_CumShifts + thSickProb*Ccum_SickProb + thMerits*Ccum_Merits = 100%\n",
        "  # this way the whole (available) pool are candidates every step\n",
        "# updated text\n",
        "# v6 starts ------------------------------------------------\n",
        "# published part 4\n",
        "# added merits for resources [v]\n",
        "  # MERITS pars with columns MeritProb, DemeritProb\n",
        "  # RMerits_t in state vector\n",
        "  # simulated similar to demands\n",
        "  # add thMerits & Ccum_Merits\n",
        "# renamed SIM to DEM\n",
        "# created P.plot_Fhat_map_3()\n",
        "# throwed out Shift1 & Shift2\n",
        "# added thSelect (categorical; from candidates, list of resources to alloc) [v]\n",
        "  # first ??\n",
        "  # random\n",
        "  # ranked (say perf scores)\n",
        "# updated text\n",
        "# v7 starts ------------------------------------------------\n",
        "# published part 5\n",
        "# changed availability value from True/False to 1/0 [v]\n",
        "# added HOD (hour-of-day) availabilities [v]\n",
        "# renamed CumShifts to CumSlots.\n",
        "# added Ccum_ContSlots for contiguous slots\n",
        "# added S_t['xAlloc_t_1'] sub-vector to S_t (previous allocations)\n",
        "# v8 starts ------------------------------------------------\n",
        "# added DOW+HOD availabilities [v]\n",
        "# v9 starts ------------------------------------------------\n",
        "# tuned with longer MAX_DAILY_SHIFT_LENGTH, currently 4hours/16quarters\n",
        "# disabling parameters by setting them to constant instead of changing code\n",
        "# reduced granularity from 1 hour to 15 mins [v]\n",
        "# having a single shift/day/resource to reduce gaps [v]\n",
        "# v10 starts ------------------------------------------------\n",
        "# having flags for TRAIN/EVALU so that complete notebook can be run automatically [v]\n",
        "  # MODES = [TRAIN, EVALU, APPLY] OR [LEARN, APPLY]\n",
        "# anvil-enabled the notebook [v]\n",
        "  # https://anvil.works/learn/tutorials/google-colab-to-web-app\n",
        "  # capture procedure\n",
        "# v11 starts ------------------------------------------------\n",
        "# reading in AVAILABILITIES_DOW_QOD from excel [v]\n",
        "  # did NOT use .gsheet google docs spreadsheet, instead use gdocs excel version\n",
        "  # have resources on cols (fewer than the other)\n",
        "  # DOW, QOD down the rows\n",
        "# reading in SICK_PROBS and MERIT_PROBS from excel [v]\n",
        "# v12 starts ------------------------------------------------\n",
        "# tried to convert notebook to vscode & mojo\n",
        "  # migrated to vscode dev container\n",
        "  # not mature enough for now, but will keep working\n",
        "# v13 starts ------------------------------------------------\n",
        "# migrated to vscode dev container with github [v]\n",
        "  # allows more formal path to production\n",
        "  # can deploy container on DigitalOcean\n",
        "# understanding relationship between devcontainer and prdcontainer [v]\n",
        "# investigated python parallelization [v]\n",
        "# implemented parallelization for thetas [v]\n",
        "  # speedup experiments in 'PerfExperiments' tab of data file\n",
        "# v14 starts ------------------------------------------------\n",
        "# parameterized the schedule resolution [v]\n",
        "  # i.e. BLOCK_8_HOUR (bod), HOUR (hod), QUARTER_HOUR (qod)\n",
        "# going back to 1 hour resolution until more compute resources available [v]\n",
        "# v15 starts ------------------------------------------------\n",
        "# investigated why the Complete red dotted line does not always show\n",
        "# \twhen the Allocd purple line goes down (where the red dotted line needs to go up), AND this happens at the beginning of the LAST slot for the day, there is 'no time' for the Complete line to go up and it does not show\n",
        "# \twhen the Allocd purple line goes down at the beginning of the FIRST slot for the day, it DOES show\n",
        "# having Exogenous Info depend on dt (DOY?, MOY?, DOW, SOD) [v]\n",
        "  # read in from spreadsheet\n",
        "# v16 starts ------------------------------------------------\n",
        "# configured current version for 'The Boardroom' [v]\n",
        "# externalized SLOTS_PER_DAY & MAX_DAILY_SLOT_RUN as user input [v]\n",
        "# externalized types of resources with counts as user input [v]\n",
        "  # could be easily entered with a Anvil 'Text Area' using this format:\n",
        "    # Manager: John, Penelope; SalesPerson: Sally, Sarah, Jim, Costa\n",
        "    # from this input the RESOURCE_TYPES & RESOURCE_TYPE_COUNTS & RESOURCE_IDS \n",
        "      # can be calced\n",
        "  # the complication is to have the datafile in sync with user inputs\n",
        "    # HOWEVER, if we define: MAX_RESOURCE_TYPES & MAX_RESOURCE_IDS, and ensure that\n",
        "    # inputs stay within these limits, the excel data file should work\n",
        "# v17 starts ------------------------------------------------\n",
        "# added dollar cost of assigning a resource to a slot [v]\n",
        "# added popular times ro exogenous information [v]\n",
        "# v18 starts ------------------------------------------------\n",
        "# fixed deployment bug\n",
        "# renamed BUSYNESS_RATE to DEMAND_PER_BUSYNESS\n",
        "\n",
        "# TODO\n",
        "# add a rest-time state variable for a resource\n",
        "  # easy to reproduce using BLOCK_8_HOUR\n",
        "  # need to prevent the slot-run from being exceeded when a \n",
        "    # slot-run straddles midnight\n",
        "  # maybe all the below is as simple as, do NOT do:\n",
        "    # if sod == 0:\n",
        "    #       S_t['R_t']['RCumSlots_t'] = 0\n",
        "  # RAvail will not be reset when a new day starts but rather when the rest-time\n",
        "    # has run out\n",
        "  # maybe rename MAX_DAILY_SLOT_RUN to MAX_SLOT_RUN\n",
        "  # after each slot-run a rest-time should happen before another schedule can occur\n",
        "# add customer sentiment to the exogenous info\n",
        "  # as social media posts happen, they are processed asynchronously to be positive/negative\n",
        "    # works on \"tell\" principle; could also be using \"ask\"\n",
        "    # e.g. realtime twitter monitoring (I think there's a post on my blog/portfolio)\n",
        "    # mentally, this processing block (part of instrumentation) is on the far right \n",
        "      # where exog info comes from; can be done with a LLM such as Google's FLAN\n",
        "  # this async event updates a state variable with +1 (positive) & -1 (negative)\n",
        "  # state variable informs the reward of the agent\n",
        "# make dicts for SLOTS_PER_DAY & DATE_TIME_DELTA\n",
        "# make block durations flexible [v]\n",
        "  # SG, block 0 starting at midnight works, testing with other arrangements not\n",
        "  # feel unsure whether durations should be configurable\n",
        "  # block beginnings should not have to start at midnight\n",
        "  # block durations can be different, say 10h, 6h, and 8h\n",
        "    # make dt_delta a lookup function that depends on the bod (block-of-day)\n",
        "# track and use resource utilizations to compare againt gov incentive [v]\n",
        "# do cross-allocations, incurring cost [v]\n",
        "# add no-shows based on SICK_PROBS as exog info [v]\n",
        "  # incur penalty for no-show\n",
        "# consider learnability of pars in parameter cell [v]\n",
        "  # in particular:\n",
        "    # DEMAND_PER_BUSYNESS\n",
        "    # REVENUE_PER_BUSYNESS\n",
        "    # not REVENUE_PER_VOLUME, i.e. hard fact from company\n",
        "    # all of the above are per hour\n",
        "  # make learnable pars selectable by the UI\n",
        "# add demands for specific resources [v]\n",
        "  # part of DemandSimulator\n",
        "  # like Sally for first shift on Mon\n",
        "  # only b attribute is the id of the resource\n",
        "# implement parallelization for Ls [v]\n",
        "  # not sure how a single policy will behave when creating multiple models in parallel\n",
        "    # which will update the policy's model; I don't think this will work\n",
        "  # may have to create a separate policy for each l (el)\n",
        "  # rather leave for now; as it is, most cpus are used for thetas anyway on mac mini\n",
        "  # much later, when we have access to powerful resources (say 100 cores), \n",
        "    # this may come in handy\n",
        "# investigate the use of mojo [v]\n",
        "# have late/early starts relative to scheduled start time count as merits\n",
        "  # do after integration with database, i.e. rest of ERP\n",
        "  # current the merits are just pre-simulated and then added to shift_scheduler_data.xlsx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CQRwf-gE1sA"
      },
      "source": [
        "## 0 INTRODUCTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsOT4_KliNMa"
      },
      "source": [
        "In the previous part we found that the agent  exploited the situation by having `thCumShifts` and `thSickProb` near their max values so that it can use the complete pool. So, instead of using thresholds below which resources are included as candidates, we always had all (available) resources in the candidates pool. The agent earned rewards or incurred penalties to discourage allocation of less ideal resources. The had the parameters:\n",
        "\n",
        "- $\\theta^{CumShifts}$\n",
        "- $\\theta^{SickProb}$\n",
        "\n",
        "Each of these operated as weighting factors to weigh the associated component of the cumulative reward $C^{cum}$:\n",
        "\n",
        "$C^{cum} = \\theta^{CumShifts}.C^{cum}_{CumShifts} + \\theta^{SickProb}.C^{cum}_{SickProb}$\n",
        "\n",
        "In this part we add one more weighting parameters so that we now have:\n",
        "\n",
        "- $\\theta^{CumShifts}$\n",
        "- $\\theta^{SickProb}$\n",
        "- $\\theta^{CumMerits}$\n",
        "\n",
        "The cumulative reward is now calculated:\n",
        "$C^{cum} = \\theta^{CumShifts}.C^{cum}_{CumShifts} + \\theta^{SickProb}.C^{cum}_{SickProb} + \\theta^{CumMerits}.C^{cum}_{CumMerits}$\n",
        "\n",
        "In addition, we add a fourth (categorical) parameter called $\\theta^{Select}$ which can have one of two values:\n",
        "\n",
        "- 'random'\n",
        "- 'ranked_CumMerits'\n",
        "\n",
        "Once the list of available candidates are identified this list is either randomized ('random'), or it is ranked by the resources' cumulative merits ('ranked_CumMerits').\n",
        "\n",
        "To keep the visualizations manageable, we will still only have the resources:\n",
        "\n",
        "- Courtesy Clerk (7 resources)\n",
        "- Stocker (3 resources)\n",
        "\n",
        "In a later part we will also add:\n",
        "\n",
        "- Cleaner (2 resources)\n",
        "- Curbsider (4 resources)\n",
        "\n",
        "Daily demands are provided by a stochastic demand simulator based on past needs and trends. We also add a merit simulator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gUJvjDWD6ch"
      },
      "source": [
        "The overall *structure* of this project and report follows the traditional CRISP-DM format. However, instead of the CRISP-DM'S \"4 Modeling\" section, we inserted the \"6 step modeling process\" of [Dr. Warren Powell](https://castlelab.princeton.edu/people/) in section 4 of this document. Dr Powell's universal framework shows great promise for unifying the formalisms of at least a dozen different fields. Using his framework enables easier access to thinking patterns in these other fields that might be beneficial and informative to the sequential decision problem at hand. Traditionally, this kind of problem would be approached from the *reinforcement learning* perspective. However, using Dr. Powell's wider and more comprehensive perspective almost certainly provides additional value.\n",
        "\n",
        "Here is information on Dr. Powell's perspective on [Sequential Decision Analytics](https://castlelab.princeton.edu/sda).\n",
        "\n",
        "In order to make a strong mapping between the code in this notebook and the mathematics in the Powell Universal Framework (PUF), we follow the following convention for naming Python identifier names:\n",
        "\n",
        "- How to read/say\n",
        "  - var name & flavor first\n",
        "  - at t/n\n",
        "  - for entity OR of/with attribute\n",
        "  - $\\hat{R}^{fail}_{t+1,a}$ has code `Rhat__fail_tt1_a` which is read: \"Rhatfail at t+1 of/with (attribute) a\"\n",
        "- Superscripts\n",
        "  - variable names have a *double* underscore to indicate a superscript\n",
        "  - $X^{\\pi}$: has code `X__pi`, is read *X pi*\n",
        "  - when there is a 'natural' distinction between the variable symbol and the superscript (e.g. a change in case), the double underscore is sometimes omitted: `Xpi` instead of `X__pi`, or `MSpend_t` instead of `M__Spend_t`\n",
        "- Subscripts\n",
        "  - variable names have a *single* underscore to indicate a subscript\n",
        "  - $S_t$: has code `S_t`, is read 'S at t'\n",
        "  - $M^{Spend}_t$ has code `M__Spend_t` which is read: \"MSpend at t\"\n",
        "  - $\\hat{R}^{fail}_{t+1,a}$ has code `Rhat__fail_tt1_a` which is read: \"Rhatfail at t+1 of/with (attribute) a\" [RLSO-p436]\n",
        "- Arguments\n",
        "  - collection variable names may have argument information added\n",
        "  - $X^{\\pi}(S_t)$: has code `X__piIS_tI`, is read 'X pi in S at t'\n",
        "  - the surrounding `I`'s are used to imitate the parentheses around the argument\n",
        "- Next time/iteration\n",
        "  - variable names that indicate one step in the future are quite common\n",
        "  - $R_{t+1}$: has code `R_tt1`, is read 'R at t+1'\n",
        "  - $R^{n+1}$: has code `R__nt1`, is read 'R at n+1'\n",
        "- Rewards\n",
        "  - State-independent terminal reward and cumulative reward\n",
        "    - $F$: has code `F` for terminal reward\n",
        "    - $\\sum_{n}F$: has code `cumF` for cumulative reward\n",
        "  - State-dependent terminal reward and cumulative reward\n",
        "    - $C$: has code `C` for terminal reward\n",
        "    - $\\sum_{t}C$: has code `cumC` for cumulative reward\n",
        "- Vectors where components use different names\n",
        "  - $S_t(R_t, p_t)$: has code `S_t.R_t` and `S_t.p_t`, is read 'S at t in R at t, and, S at t in p at t'\n",
        "  - the code implementation is by means of a named tuple\n",
        "    - `self.State = namedtuple('State', SVarNames)` for the 'class' of the vector\n",
        "    - `self.S_t` for the 'instance' of the vector\n",
        "- Vectors where components reuse names\n",
        "  - $x_t(x_{t,GB}, x_{t,BL})$: has code `x_t.x_t_GB` and `x_t.x_t_BL`, is read 'x at t in x at t for GB, and, x at t in x at t for BL'\n",
        "  - the code implementation is by means of a named tuple\n",
        "    - `self.Decision = namedtuple('Decision', xVarNames)` for the 'class' of the vector\n",
        "    - `self.x_t` for the 'instance' of the vector\n",
        "- Use of mixed-case variable names\n",
        "  - to reduce confusion, sometimes the use of *mixed-case* variable names are preferred (even though it is not a best practice in the Python community), reserving the use of underscores and double underscores for math-related variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daMCm8jqFI21"
      },
      "source": [
        "## 1 BUSINESS UNDERSTANDING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42fg7rNGyu2m"
      },
      "source": [
        "The HR manager has to schedule resources for each day. This schedule will be automated and optimized by the AI agent.\n",
        "\n",
        "The number of resources of each type for each schedule slots for each day will be provided by the simulator. Only two resource types will be handled:\n",
        "\n",
        "- Courtesy\n",
        "- Stocker\n",
        "\n",
        "The HR manager typically runs the AI Shift Scheduler 2 weeks into the future to produce a tentative schedule to publish for the team.\n",
        "\n",
        "As demands for shift slot allocations come in, they are handled in the following way:\n",
        "\n",
        "- the candidates for the resource type must have their:\n",
        "  - $R^{Avail}_t$ be True\n",
        "\n",
        "- the specific resources are then marked for allocation considering the number of resources needed for the type\n",
        "- the state of the resources are then updated including the number of accumulated shifts\n",
        "- at the end of the shift all resources are made available again\n",
        "\n",
        "The overall objective will be to maximize the cumulative reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-HrABIBy4rN"
      },
      "source": [
        "## 2 DATA UNDERSTANDING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWm75LV3FV4r"
      },
      "source": [
        "Based on recent market research, the demand may be modeled by a Poisson distribution for each resource type:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mu^{ResourceType} &= \\mathrm{SIM\\_MU\\_D[RESOURCE\\_TYPE]}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "So we have:\n",
        "$$\n",
        "D^{ResourceType}_{t+1} \\sim Pois(\\mu^{ResourceType})\n",
        "$$\n",
        "\n",
        "For each decision window, a `MeritProb` and `DemeritProb` unique to each resource is used to simulate whether that resource earned a merit (+1) and/or demerit (-1). The two values are summed to get a net merit. These merit values are also accumulated.\n",
        "\n",
        "The decision window is 1 day and these simulations are for the daily demands for Shift1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGJaJsXuI9cE",
        "outputId": "dddbe4d6-3365-4478-ab64-e1c88b6f64a6"
      },
      "outputs": [],
      "source": [
        "# # #hide\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive', force_remount=True)\n",
        "# root_dir = \"/content/gdrive/My Drive\"\n",
        "# # base_dir = root_dir + '/Powell/SD.I_Inventory_Problems/InventoryStorage'\n",
        "# base_dir = root_dir + '/Powell/SD.CRA_Complex_Resource_Allocation_Problems/Scheduling'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtFLhQtAMARj",
        "outputId": "8586ce5f-8546-47a5-dbd3-7277d60c78b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.8.18\n"
          ]
        }
      ],
      "source": [
        "## import pdb\n",
        "from collections import namedtuple, defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import copy\n",
        "import time\n",
        "import math\n",
        "from pprint import pprint\n",
        "import matplotlib as mpl\n",
        "pd.options.display.float_format = '{:,.4f}'.format\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "## !pip install -U \"ray\"\n",
        "## from timebudget import timebudget\n",
        "import ray\n",
        "import json\n",
        "\n",
        "! python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "44cGegMCTrYG"
      },
      "outputs": [],
      "source": [
        "## hide\n",
        "## def contribution(aName, bName):\n",
        "#   a = aName.split('_')\n",
        "#   b = bName.split('_')\n",
        "#   if (\n",
        "#     a[0] == b[0]:\n",
        "#     bool(b[2]) == False and a[0] != b[0]) or \\\n",
        "#     (bool(b[2]) == True and mySubMatrix['_'.join([a[0], b[0]])] == False):\n",
        "#     value = params['INFEASIABLE_SUBSTITUTION_PENALTY']\n",
        "#   else:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k8-Ijh_jsPv8"
      },
      "outputs": [],
      "source": [
        "base_dir = '.'\n",
        "file_name = 'shift_scheduler_data.xlsx'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A3bm2-Hh-GHw"
      },
      "outputs": [],
      "source": [
        "def load_sick_probs(filename):\n",
        "  sick_df = pd.read_excel(\n",
        "      filename,\n",
        "      sheet_name='SickProbs',\n",
        "      ## skiprows=3,\n",
        "      converters={'ResourceId':str}\n",
        "      )\n",
        "  return sick_df\n",
        "SICK_PROBS = load_sick_probs(f'{base_dir}/{file_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MT5l2eMpeIqe"
      },
      "outputs": [],
      "source": [
        "def load_merit_probs(filename):\n",
        "  merit_df = pd.read_excel(\n",
        "      filename,\n",
        "      sheet_name='MeritProbs',\n",
        "      ## skiprows=3,\n",
        "      converters={'ResourceId':str}\n",
        "      )\n",
        "  return merit_df\n",
        "MERIT_PROBS = load_merit_probs(f'{base_dir}/{file_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_exog_info(filename):\n",
        "  exog_info_df = pd.read_excel(\n",
        "    filename,\n",
        "    sheet_name='ExogInfo2',\n",
        "    skiprows=6,\n",
        "    ## converters={'ResourceId':str}\n",
        "    )\n",
        "  return exog_info_df\n",
        "EXOG_INFO = load_exog_info(f'{base_dir}/{file_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Acquire 'popular times' data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "## generate/update 'popular times' data\n",
        "# if the busyness data exists in shift_scheduler_data.xlsx,\n",
        "    # delete the data\n",
        "    # move the heading(s) for popular times up higher (temporarily)\n",
        "# https://outscraper.com/pricing/\n",
        "    # seems like I can use this approach for one-of queries\n",
        "    # I did signup, but did not provide any credit card info\n",
        "# click on free plan\n",
        "# fill out as in outscraper_query_example.png\n",
        "# submit the query\n",
        "# goto 'Tasks' in left panel //https://app.outscraper.com/tasks\n",
        "# download the results\n",
        "# open the excel file\n",
        "# goto the 'popular_times' column\n",
        "# copy the value from this column to the right of the '=' in the next cell\n",
        "# goto the 'place_id' column and copy its value\n",
        "    # optional, maybe handy in future, when the popular times have to be updated,\n",
        "    # to query by this number, however, would need a google api key:\n",
        "        # ! curl -X POST -d '{\"textQuery\" : \"Spicy Vegetarian Food in Sydney, Australia\"}' \\\n",
        "        # -H 'Content-Type: application/json' -H 'X-Goog-Api-Key: API_KEY' \\\n",
        "        # -H 'X-Goog-FieldMask: places.id,places.displayName,places.formattedAddress' \\\n",
        "        # 'https://places.googleapis.com/v1/places:searchText'    \n",
        "# run the rest of this section until PopularTimes.xlsx has been saved\n",
        "# copy the 3 columns from PopularTimes.xlsx and paste into the ExogInfo2 tab of \n",
        "    # shift_scheduler_data.xlsx\n",
        "# make sure the alignment is good\n",
        "# delete the 'hour' and 'day' columns from the paste\n",
        "# rename the 'percentage' column to 'busyness'\n",
        "# load the exog info again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "## data_popular_times = [{\"day\": 7, \"popular_times\": [{\"hour\": 6, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 7, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 8, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 9, \"percentage\": 0, \"title\": \"\", \"time\": \"9am\"}, {\"hour\": 10, \"percentage\": 0, \"title\": \"\", \"time\": \"9am\"}, {\"hour\": 11, \"percentage\": 54, \"title\": \"Usually a little busy\", \"time\": \"9am\"}, {\"hour\": 12, \"percentage\": 75, \"title\": \"Usually a little busy\", \"time\": \"12pm\"}, {\"hour\": 13, \"percentage\": 91, \"title\": \"Usually as busy as it gets\", \"time\": \"12pm\"}, {\"hour\": 14, \"percentage\": 100, \"title\": \"Usually as busy as it gets\", \"time\": \"12pm\"}, {\"hour\": 15, \"percentage\": 87, \"title\": \"Usually as busy as it gets\", \"time\": \"3pm\"}, {\"hour\": 16, \"percentage\": 65, \"title\": \"Usually a little busy\", \"time\": \"3pm\"}, {\"hour\": 17, \"percentage\": 0, \"title\": \"\", \"time\": \"3pm\"}, {\"hour\": 18, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 19, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 20, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 21, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 22, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 23, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}]}, {\"day\": 1, \"popular_times\": [{\"hour\": 6, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 7, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 8, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 9, \"percentage\": 0, \"title\": \"\", \"time\": \"9am\"}, {\"hour\": 10, \"percentage\": 14, \"title\": \"Usually not busy\", \"time\": \"9am\"}, {\"hour\": 11, \"percentage\": 25, \"title\": \"Usually not too busy\", \"time\": \"9am\"}, {\"hour\": 12, \"percentage\": 33, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 13, \"percentage\": 29, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 14, \"percentage\": 33, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 15, \"percentage\": 34, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 16, \"percentage\": 29, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 17, \"percentage\": 18, \"title\": \"Usually not busy\", \"time\": \"3pm\"}, {\"hour\": 18, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 19, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 20, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 21, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 22, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 23, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}]}, {\"day\": 2, \"popular_times\": [{\"hour\": 6, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 7, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 8, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 9, \"percentage\": 0, \"title\": \"\", \"time\": \"9am\"}, {\"hour\": 10, \"percentage\": 7, \"title\": \"Usually not busy\", \"time\": \"9am\"}, {\"hour\": 11, \"percentage\": 18, \"title\": \"Usually not busy\", \"time\": \"9am\"}, {\"hour\": 12, \"percentage\": 20, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 13, \"percentage\": 23, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 14, \"percentage\": 19, \"title\": \"Usually not busy\", \"time\": \"12pm\"}, {\"hour\": 15, \"percentage\": 20, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 16, \"percentage\": 17, \"title\": \"Usually not busy\", \"time\": \"3pm\"}, {\"hour\": 17, \"percentage\": 20, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 18, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 19, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 20, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 21, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 22, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 23, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}]}, {\"day\": 3, \"popular_times\": [{\"hour\": 6, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 7, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 8, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 9, \"percentage\": 0, \"title\": \"\", \"time\": \"9am\"}, {\"hour\": 10, \"percentage\": 19, \"title\": \"Usually not busy\", \"time\": \"9am\"}, {\"hour\": 11, \"percentage\": 24, \"title\": \"Usually not too busy\", \"time\": \"9am\"}, {\"hour\": 12, \"percentage\": 29, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 13, \"percentage\": 27, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 14, \"percentage\": 27, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 15, \"percentage\": 23, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 16, \"percentage\": 27, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 17, \"percentage\": 20, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 18, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 19, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 20, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 21, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 22, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 23, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}]}, {\"day\": 4, \"popular_times\": [{\"hour\": 6, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 7, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 8, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 9, \"percentage\": 0, \"title\": \"\", \"time\": \"9am\"}, {\"hour\": 10, \"percentage\": 1, \"title\": \"Usually not busy\", \"time\": \"9am\"}, {\"hour\": 11, \"percentage\": 7, \"title\": \"Usually not busy\", \"time\": \"9am\"}, {\"hour\": 12, \"percentage\": 17, \"title\": \"Usually not busy\", \"time\": \"12pm\"}, {\"hour\": 13, \"percentage\": 25, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 14, \"percentage\": 24, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 15, \"percentage\": 23, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 16, \"percentage\": 17, \"title\": \"Usually not busy\", \"time\": \"3pm\"}, {\"hour\": 17, \"percentage\": 18, \"title\": \"Usually not busy\", \"time\": \"3pm\"}, {\"hour\": 18, \"percentage\": 14, \"title\": \"Usually not busy\", \"time\": \"6pm\"}, {\"hour\": 19, \"percentage\": 16, \"title\": \"Usually not busy\", \"time\": \"6pm\"}, {\"hour\": 20, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 21, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 22, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 23, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}]}, {\"day\": 5, \"popular_times\": [{\"hour\": 6, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 7, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 8, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 9, \"percentage\": 0, \"title\": \"\", \"time\": \"9am\"}, {\"hour\": 10, \"percentage\": 14, \"title\": \"Usually not busy\", \"time\": \"9am\"}, {\"hour\": 11, \"percentage\": 27, \"title\": \"Usually not too busy\", \"time\": \"9am\"}, {\"hour\": 12, \"percentage\": 33, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 13, \"percentage\": 32, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 14, \"percentage\": 27, \"title\": \"Usually not too busy\", \"time\": \"12pm\"}, {\"hour\": 15, \"percentage\": 27, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 16, \"percentage\": 29, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 17, \"percentage\": 32, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 18, \"percentage\": 28, \"title\": \"Usually not too busy\", \"time\": \"6pm\"}, {\"hour\": 19, \"percentage\": 22, \"title\": \"Usually not too busy\", \"time\": \"6pm\"}, {\"hour\": 20, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 21, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 22, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 23, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}]}, {\"day\": 6, \"popular_times\": [{\"hour\": 6, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 7, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 8, \"percentage\": 0, \"title\": \"\", \"time\": \"6am\"}, {\"hour\": 9, \"percentage\": 0, \"title\": \"\", \"time\": \"9am\"}, {\"hour\": 10, \"percentage\": 25, \"title\": \"Usually not too busy\", \"time\": \"9am\"}, {\"hour\": 11, \"percentage\": 44, \"title\": \"Usually not too busy\", \"time\": \"9am\"}, {\"hour\": 12, \"percentage\": 61, \"title\": \"Usually a little busy\", \"time\": \"12pm\"}, {\"hour\": 13, \"percentage\": 76, \"title\": \"Usually a little busy\", \"time\": \"12pm\"}, {\"hour\": 14, \"percentage\": 96, \"title\": \"Usually as busy as it gets\", \"time\": \"12pm\"}, {\"hour\": 15, \"percentage\": 95, \"title\": \"Usually as busy as it gets\", \"time\": \"3pm\"}, {\"hour\": 16, \"percentage\": 79, \"title\": \"Usually a little busy\", \"time\": \"3pm\"}, {\"hour\": 17, \"percentage\": 48, \"title\": \"Usually not too busy\", \"time\": \"3pm\"}, {\"hour\": 18, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 19, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 20, \"percentage\": 0, \"title\": \"\", \"time\": \"6pm\"}, {\"hour\": 21, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 22, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}, {\"hour\": 23, \"percentage\": 0, \"title\": \"\", \"time\": \"9pm\"}]}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "## df_popular_times = pd.json_normalize(\n",
        "#     data_popular_times,\n",
        "#     \"popular_times\", [\"day\"] ## day1 to day7 is Monday to Sunday\n",
        "# )\n",
        "# df_popular_times['day'] = df_popular_times['day'].apply(lambda x: x - 1) ##adjust DOW to match other data\n",
        "# df_popular_times = df_popular_times[['hour', 'percentage', 'day']] ##select used columns\n",
        "# df_popular_times[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "## \n",
        "# EXOG_INFO = pd.merge(EXOG_INFO, df_popular_times, how='left', left_on=['DOW', 'HOD'], right_on=['day', 'hour'])\n",
        "# EXOG_INFO['hour'].fillna(EXOG_INFO['HOD'], inplace=True)\n",
        "# EXOG_INFO['day'].fillna(EXOG_INFO['DOW'], inplace=True)\n",
        "# EXOG_INFO['percentage'].fillna(0, inplace=True)\n",
        "# EXOG_INFO = EXOG_INFO.astype({'hour':'int32', 'percentage':'int32', 'day':'int32'})\n",
        "# EXOG_INFO[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## copy from this file and paste into ExogInfo tab of shift_scheduler_data.xlsx\n",
        "# EXOG_INFO.to_excel('PopularTimes.xlsx', columns=['hour', 'percentage', 'day'], index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## load again\n",
        "# EXOG_INFO = load_exog_info(f'{base_dir}/{file_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "## EXOG_INFO.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlIoV43xtB6U"
      },
      "source": [
        "We will have the *learnable* parameters:\n",
        "\n",
        "$$(\\theta^{CumShifts}, \\theta^{SickProb}, \\theta^{CumMerits}, \\theta^{Select})$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3wUvUHl6dwc",
        "outputId": "13cedaff-2829-4dfa-f6f4-3b06762f5d61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "len(RESOURCE_TYPES)=3\n",
            "['Manager', 'AssistMngr', 'RetailAssoc']\n",
            "\n",
            "len(TYPES)=13\n",
            "['Manager', 'AssistMngr', 'AssistMngr', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc']\n",
            "len(aNAMES)=13\n",
            "['Manager_Matt', 'AssistMngr_Mike', 'AssistMngr_Tanner', 'RetailAssoc_Jake', 'RetailAssoc_James', 'RetailAssoc_Jane', 'RetailAssoc_John', 'RetailAssoc_Jim', 'RetailAssoc_Jenny', 'RetailAssoc_Jeremy', 'RetailAssoc_Judy', 'RetailAssoc_Julie', 'RetailAssoc_Jeffrey']\n",
            "\n",
            "len(bNAMES)=3\n",
            "['Manager', 'AssistMngr', 'RetailAssoc']\n",
            "\n",
            "len(abNAMES)=13\n",
            "['Manager_Matt___Manager', 'AssistMngr_Mike___AssistMngr', 'AssistMngr_Tanner___AssistMngr', 'RetailAssoc_Jake___RetailAssoc', 'RetailAssoc_James___RetailAssoc', 'RetailAssoc_Jane___RetailAssoc', 'RetailAssoc_John___RetailAssoc', 'RetailAssoc_Jim___RetailAssoc', 'RetailAssoc_Jenny___RetailAssoc', 'RetailAssoc_Jeremy___RetailAssoc', 'RetailAssoc_Judy___RetailAssoc', 'RetailAssoc_Julie___RetailAssoc', 'RetailAssoc_Jeffrey___RetailAssoc']\n",
            "\n",
            "len(thNAMES)=5\n",
            "thNAMES=['thCumSlots', 'thSickProb', 'thCumMerits', 'thContSlots', 'thSelect']\n"
          ]
        }
      ],
      "source": [
        "## PARAMETERS\n",
        "# MODES = ['LEARN']\n",
        "# MODES = ['TRAIN']\n",
        "# MODES = ['TRAIN', 'EVALU']\n",
        "# MODES = ['TRAIN', 'EVALU', 'APPLY'] \n",
        "# or # MODES = ['TRAIN', 'EVALU', 'INFER']\n",
        "# or # MODES = ['TRAIN', 'EVALU', 'SERVE']\n",
        "# MODES = ['EVALU', 'APPLY']\n",
        "MODES = ['APPLY']\n",
        "## for 'APPLY'/'INFER'/'SERVE'\n",
        "BEST_THETA_Alloc = (0, 0, 0, 1, 'random') #will be written/read eventually\n",
        "\n",
        "## SNAMES = [ #state variable names\n",
        "#     'RAvail_t', #available resource\n",
        "#     'R_t',      #resource\n",
        "#     'D_t',      #demand\n",
        "# ]\n",
        "## xNAMES = ['x_t'] #decision variable names\n",
        "\n",
        "MAX_RESOURCE_TYPES = 3\n",
        "MAX_RESOURCE_IDS = 13\n",
        "\n",
        "## RESOURCE_TYPES = ['Courtesy', 'Stocker', 'Cleaner', 'Curbsider'] ## <<< ========= INPUT ==============\n",
        "RESOURCE_TYPES = ['Manager', 'AssistMngr', 'RetailAssoc'] ## <<< ========= INPUT ==============\n",
        "\n",
        "RESOURCE_TYPE_COUNTS = [1, 2, 10] ## <<< ========= INPUT ==============\n",
        "assert len(RESOURCE_TYPES) == len(RESOURCE_TYPE_COUNTS)\n",
        "assert len(RESOURCE_TYPES) <= MAX_RESOURCE_TYPES\n",
        "print(f'\\n{len(RESOURCE_TYPES)=}')\n",
        "print(RESOURCE_TYPES)\n",
        "\n",
        "## TYPES = ['Courtesy']*7 + ['Stocker']*3 + ['Cleaner']*2 + ['Curbsider']*4\n",
        "TYPES = []\n",
        "for i in range(len(RESOURCE_TYPES)):\n",
        "  additional_types = [RESOURCE_TYPES[i]]*RESOURCE_TYPE_COUNTS[i]\n",
        "  for item in additional_types:\n",
        "    TYPES.append(item)\n",
        "print(f'\\n{len(TYPES)=}')\n",
        "print(TYPES)\n",
        "\n",
        "RESOURCE_IDS = [ ## <<< ========= INPUT ==============\n",
        "  'Matt', \n",
        "  'Mike', 'Tanner', \n",
        "  'Jake', 'James', 'Jane', 'John', 'Jim', 'Jenny', 'Jeremy', 'Judy', 'Julie', 'Jeffrey']\n",
        "assert len(RESOURCE_IDS) == len(TYPES)\n",
        "assert len(RESOURCE_IDS) <= MAX_RESOURCE_IDS\n",
        "\n",
        "## eventually learn, call thBusyRate\n",
        "## demand/busyness ## <<< ========= INPUT ==============\n",
        "## add demands of 0 up to these values as busyness varies from 0 to 100%\n",
        "# BUSYNESS_RATES = [.5, .8, 5]\n",
        "DEMANDS_PER_BUSYNESS = [.5, .8, 5]\n",
        "# BUSYNESS_RATE = {e: BUSYNESS_RATES[i] for i,e in enumerate(RESOURCE_TYPES)}\n",
        "DEMAND_PER_BUSYNESS = {e: DEMANDS_PER_BUSYNESS[i] for i,e in enumerate(RESOURCE_TYPES)}\n",
        "# assert len(BUSYNESS_RATES) == len(RESOURCE_TYPES)\n",
        "assert len(DEMANDS_PER_BUSYNESS) == len(RESOURCE_TYPES)\n",
        "\n",
        "RESOURCE_EXPENSES = [25.00, 20.00, 18.00] ## <<< ========= INPUT ==============\n",
        "RESOURCE_EXPENSE = {e: RESOURCE_EXPENSES[i] for i,e in enumerate(RESOURCE_TYPES)}\n",
        "assert len(RESOURCE_EXPENSES) == len(RESOURCE_TYPES)\n",
        "\n",
        "## does not make a whole lot of sense, rather use:\n",
        "  ## REVENUE_PER_BUSYNESS (PER HOUR) or\n",
        "  ## REVENUE_PER_VOLUME (PER HOUR)\n",
        "## RESOURCE_REVENUES = [0.00, 0.00, 400.00] ## <<< ========= INPUT ==============\n",
        "## RESOURCE_REVENUE = {e: RESOURCE_REVENUES[i] for i,e in enumerate(RESOURCE_TYPES)}\n",
        "## assert len(RESOURCE_REVENUES) == len(RESOURCE_TYPES)\n",
        "REVENUE_PER_BUSYNESS = 1000 ##dollars ## <<< ========= INPUT ==============\n",
        "## REVENUE_PER_VOLUME = 100 ##dollars ## <<< ========= INPUT ==============\n",
        "\n",
        "## *resource* attribute vectors\n",
        "aNAMES = [tup[0]+'_'+tup[1] for tup in zip(TYPES, RESOURCE_IDS)]\n",
        "print(f'{len(aNAMES)=}')\n",
        "print(aNAMES)\n",
        "\n",
        "## *demand* attribute vectors\n",
        "bNAMES = RESOURCE_TYPES\n",
        "print(f'\\n{len(bNAMES)=}')\n",
        "print(bNAMES)\n",
        "\n",
        "## *decision* 'attribute' vectors\n",
        "abNAMES = [] ##to DEMAND b\n",
        "for a in aNAMES:\n",
        "  a0,a1 = a.split('_')\n",
        "  for b in bNAMES:\n",
        "    if(a0==b):\n",
        "      abn = (a + '___' + b)\n",
        "      abNAMES.append(abn)\n",
        "print(f'\\n{len(abNAMES)=}')\n",
        "print(abNAMES)\n",
        "\n",
        "piNAMES = ['X__Alloc'] ##policy names\n",
        "thNAMES = [ ##theta names\n",
        "  'thCumSlots',\n",
        "  'thSickProb',\n",
        "  'thCumMerits',\n",
        "  'thContSlots',\n",
        "  'thSelect'\n",
        "  ## 'thBusyRate' ##later\n",
        "]\n",
        "print(f'\\n{len(thNAMES)=}')\n",
        "print(f'{thNAMES=}')\n",
        "\n",
        "RESOLUTION = 'HOUR' ## 'BLOCK_8_HOUR', 'HOUR', 'QUARTER_HOUR', \n",
        "if RESOLUTION == 'QUARTER_HOUR':\n",
        "  SLOTS_PER_DAY = 96\n",
        "  DATE_TIME_DELTA = '15min'\n",
        "elif RESOLUTION == 'HOUR':\n",
        "  SLOTS_PER_DAY = 24\n",
        "  DATE_TIME_DELTA = '1H'\n",
        "elif RESOLUTION == 'BLOCK_8_HOUR':\n",
        "  SLOTS_PER_DAY = 3\n",
        "  DATE_TIME_DELTA = '8H'\n",
        "  ## DATE_TIME_DELTA = {0: '6H', 1: '10H', 2: '8H'} ##maybe in future?\n",
        "else:\n",
        "  print(f'ERROR: Invalid RESOLUTION: {RESOLUTION}')\n",
        "\n",
        "BLOCK_START_HOUR = {0: 0, 1: 8, 2:16}\n",
        "\n",
        "## ///////////////////////////\n",
        "# SLOTS_PER_DAY = {\n",
        "#     'QUARTER_HOUR': 96,\n",
        "#     'HOUR': 24,\n",
        "#     'BLOCK_8_HOUR': 3\n",
        "#     # 'BLOCK_8_HOUR': {0: '6H', 1: '10H', 2: '8H'}\n",
        "# }\n",
        "# DATE_TIME_DELTA = {\n",
        "#     'QUARTER_HOUR': '15min',\n",
        "#     'HOUR': '1H',\n",
        "#     'BLOCK_8_HOUR': '8H'\n",
        "#     # 'BLOCK_8_HOUR': {0: '6H', 1: '10H', 2: '8H'}\n",
        "# }\n",
        "## \\\\\\\\\\\\\\\\\\\\\n",
        "\n",
        "def get_availabilities(dt):\n",
        "  avails = \\\n",
        "    EXOG_INFO.loc[\n",
        "      EXOG_INFO['Date']==dt,\n",
        "      [col for col in EXOG_INFO.columns if col in [f'A_{a}' for a in range(len(RESOURCE_IDS))]]\n",
        "    ].iloc[0]\n",
        "  avails.reset_index(drop=True, inplace=True) ##to start index at 0\n",
        "  return avails\n",
        "\n",
        "def get_dow_qod_capacities(dow):\n",
        "  capacities = \\\n",
        "    EXOG_INFO.loc[\n",
        "      (EXOG_INFO['DOW']==dow),\n",
        "      [col for col in EXOG_INFO.columns if col in [f'A_{a}' for a in range(len(RESOURCE_IDS))]]\n",
        "    ].sum(axis=0) ##total daily capacity\n",
        "  capacities.reset_index(drop=True, inplace=True)\n",
        "  return capacities\n",
        "\n",
        "def get_dow_hod_capacities(dow):\n",
        "  capacities = \\\n",
        "    EXOG_INFO.loc[\n",
        "      (EXOG_INFO['DOW']==dow),\n",
        "    ].groupby(['HOD']).first()\n",
        "  capacities = capacities[[col for col in EXOG_INFO.columns if col in [f'A_{a}' for a in range(len(RESOURCE_IDS))]]]\n",
        "  capacities = capacities.sum(axis=0) ##total daily capacity\n",
        "  capacities.reset_index(drop=True, inplace=True)\n",
        "  return capacities\n",
        "\n",
        "def get_dow_bod_capacities(dow):\n",
        "  capacities = \\\n",
        "    EXOG_INFO.loc[\n",
        "      (EXOG_INFO['DOW']==dow),\n",
        "    ].groupby(['BOD']).first()\n",
        "  capacities = capacities[[col for col in EXOG_INFO.columns if col in [f'A_{a}' for a in range(len(RESOURCE_IDS))]]]\n",
        "  capacities = capacities.sum(axis=0) ##total daily capacity\n",
        "  capacities.reset_index(drop=True, inplace=True)\n",
        "  return capacities\n",
        "\n",
        "def get_capacities(dow):\n",
        "  if RESOLUTION == 'QUARTER_HOUR':\n",
        "    return get_dow_qod_capacities(dow)\n",
        "  elif RESOLUTION == 'HOUR':\n",
        "    return get_dow_hod_capacities(dow)\n",
        "  elif RESOLUTION == 'BLOCK_8_HOUR':\n",
        "    return get_dow_bod_capacities(dow)\n",
        "  else:\n",
        "    print(f'ERROR: Invalid RESOLUTION: {RESOLUTION}')\n",
        "    return None\n",
        "\n",
        "SEED_TRAIN = 77777777\n",
        "SEED_EVALU = 88888888\n",
        "## N_SAMPLEPATHS = 100; L = N_SAMPLEPATHS\n",
        "## N_TRANSITIONS = 100; T = N_TRANSITIONS\n",
        "\n",
        "TH_CumSlots_SPEC = (0, 1, .2)\n",
        "TH_SickProb_SPEC = (0, 1, .2)\n",
        "TH_CumMerits_SPEC = (0, 1, .2)\n",
        "TH_ContSlots_SPEC = (0, 1, .2)\n",
        "## TH_Select_SPEC = ('random', 'ranked_CumMerits')\n",
        "TH_Select_SPEC = ('random',)\n",
        "## TH_Select_SPEC = ('ranked_CumMerits',)\n",
        "\n",
        "## SIM_T = 60\n",
        "# ## SIM_MU_D = {bNAMES[0]: 4, bNAMES[1]: 2}\n",
        "# SIM_MU_D = {bNAMES[0]: 4, bNAMES[1]: 2, bNAMES[2]: 2}\n",
        "# print(f'\\n{SIM_MU_D=}')\n",
        "# assert len(SIM_MU_D.items())==len(bNAMES)\n",
        "\n",
        "# ## SIM_EVENT_TIME_D = {bNAMES[0]: None, bNAMES[1]: None, bNAMES[2]: None, bNAMES[3]: None}\n",
        "# ## SIM_EVENT_TIME_D = {bNAMES[0]: None, bNAMES[1]: None}\n",
        "# SIM_EVENT_TIME_D = {bNAMES[0]: None, bNAMES[1]: None, bNAMES[2]: None}\n",
        "# print(f'\\n{SIM_EVENT_TIME_D=}')\n",
        "# assert len(SIM_EVENT_TIME_D.items())==len(bNAMES)\n",
        "\n",
        "# ## SIM_MU_DELTA_D = {bNAMES[0]: None, bNAMES[1]: None, bNAMES[2]: None, bNAMES[3]: None}\n",
        "# SIM_MU_DELTA_D = {bNAMES[0]: None, bNAMES[1]: None, bNAMES[2]: None}\n",
        "# print(f'\\n{SIM_MU_DELTA_D=}')\n",
        "# assert len(SIM_MU_DELTA_D.items())==len(bNAMES)\n",
        "\n",
        "START_DATE_TIME = '2023-12-04'\n",
        "## START_DATE_TIME = '2023-10-30T22:00' ##works too\n",
        "sd = pd.to_datetime(START_DATE_TIME)\n",
        "assert sd.strftime('%a')=='Mon'\n",
        "\n",
        "MAX_DAILY_SLOT_RUN = 8 #8\n",
        "assert MAX_DAILY_SLOT_RUN<=SLOTS_PER_DAY\n",
        "\n",
        "CONTIGUOUS_REWARD = 1\n",
        "\n",
        "GOV_UTIL_THESH = 0.40\n",
        "\n",
        "## math parameters use 'math/small case' (as opposed to code parameters):\n",
        "\n",
        "## CONTRIB_MATRIX = {}\n",
        "# for an in aNAMES:\n",
        "#     contribs = {}\n",
        "#     for bn in bNAMES:\n",
        "#       contribs[bn] = contribution(an, bn)\n",
        "#     CONTRIB_MATRIX[an] = contribs\n",
        "# CONTRIB_MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oM-qqvouJ50-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: anvil-uplink in /opt/conda/lib/python3.8/site-packages (0.4.2)\n",
            "Collecting argparse (from anvil-uplink)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /opt/conda/lib/python3.8/site-packages (from anvil-uplink) (0.18.3)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from anvil-uplink) (1.16.0)\n",
            "Requirement already satisfied: ws4py in /opt/conda/lib/python3.8/site-packages (from anvil-uplink) (0.5.1)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "## for deployment\n",
        "if 'APPLY' in MODES:\n",
        "  !pip install anvil-uplink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "G5KOD22CJ8d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Debug for kobus78@gmail.com\" as SERVER\n"
          ]
        }
      ],
      "source": [
        "## for deployment\n",
        "if 'APPLY' in MODES:\n",
        "  import anvil.server\n",
        "  # anvil.server.connect(\"server_3XW6GGHGVKXPOSSQIURTQXNU-V4VIE5KV6JAVBBAU\")\n",
        "  # anvil.server.connect(\"server_RQUG55QCBAUR4ONLXVEZZYPN-V4VIE5KV6JAVBBAU\")\n",
        "  anvil.server.connect(\"server_3XW6GGHGVKXPOSSQIURTQXNU-V4VIE5KV6JAVBBAU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8K3S75Vx6doR"
      },
      "outputs": [],
      "source": [
        "## class DemandSimulator():\n",
        "#   def __init__(self,\n",
        "#     T__sim=SIM_T,\n",
        "#     muD=SIM_MU_D,\n",
        "#     eventTimeD=SIM_EVENT_TIME_D,\n",
        "#     muDeltaD=SIM_MU_DELTA_D,\n",
        "#     seed=None):\n",
        "#     self.time = 0\n",
        "#     self.T__sim = SIM_T\n",
        "#     self.muD = SIM_MU_D\n",
        "#     self.eventTimeD = SIM_EVENT_TIME_D\n",
        "#     self.muDeltaD = SIM_MU_DELTA_D\n",
        "#     self.prng = np.random.RandomState(seed)\n",
        "\n",
        "#   def simulate(self):\n",
        "#     if self.time > self.T__sim - 1:\n",
        "#       self.time = 0\n",
        "#     D_tt1 = {}\n",
        "#     for bn in bNAMES:\n",
        "#       if self.eventTimeD[bn] and self.time > self.eventTimeD[bn]: ##event for entity\n",
        "#         D_tt1[bn] = self.muDeltaD[bn] + self.prng.poisson(self.muD[bn]) ##after event\n",
        "#       else:\n",
        "#         D_tt1[bn] = self.prng.poisson(self.muD[bn])\n",
        "#     self.time += 1\n",
        "#     return {bn: max(0, D_tt1[bn]) for bn in bNAMES} ##always positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "6nP-6vCP6dbJ",
        "outputId": "b46dcb44-40aa-4f8f-aa88-874f6308123e"
      },
      "outputs": [],
      "source": [
        "## dem_sim = DemandSimulator(seed=1234)\n",
        "# DemandData = []\n",
        "# for i in range(SIM_T):\n",
        "#   d = list(dem_sim.simulate().values())\n",
        "#   DemandData.append(d)\n",
        "# labels = [f'{bn}_dem' for bn in bNAMES]\n",
        "# df = pd.DataFrame.from_records(data=DemandData, columns=labels); df[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "itgAVDW-Iu5S"
      },
      "outputs": [],
      "source": [
        "# ## PUT BACK: COMMENTED OUT TO BE FASTER\n",
        "# import random\n",
        "# def plot_output(df1, df2):\n",
        "#   n_charts = len(bNAMES)\n",
        "#   ylabelsize = 16\n",
        "#   mpl.rcParams['lines.linewidth'] = 1.2\n",
        "#   default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "#   fig, axs = plt.subplots(n_charts, sharex=True)\n",
        "#   fig.set_figwidth(13); fig.set_figheight(9)\n",
        "#   fig.suptitle('Demand Simulation', fontsize=20)\n",
        "\n",
        "#   for i,bn in enumerate(bNAMES):\n",
        "#     axs[i].set_title(f'Demanded {bn}')\n",
        "#     axs[i].set_ylim(auto=True); axs[i].spines['top'].set_visible(False); axs[i].spines['right'].set_visible(True); axs[i].spines['bottom'].set_visible(False)\n",
        "#     axs[i].step(df1[f'{bn}_dem'], 'r-')\n",
        "#     ## axs[i].axhline(y=dem_sim.muD[e], color='k', linestyle=':')\n",
        "#     axs[i].axhline(y=0, color='k', linestyle=':')\n",
        "\n",
        "#   axs[i].set_xlabel('$t\\ \\mathrm{[hourly\\ windows]}$', rotation=0, ha='center', va='center', fontweight='bold', size=ylabelsize)\n",
        "# plot_output(df, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gZt03jXl7ZS-"
      },
      "outputs": [],
      "source": [
        "# ## copy from the generated file and paste into ExogInfo tab of shift_scheduler_data.xlsx\n",
        "# class MeritSimulator():\n",
        "#   def __init__(self, seed=None):\n",
        "#     self.prng = np.random.RandomState(seed)\n",
        "\n",
        "#   def simulate(self):\n",
        "#     M_tt1 = {}\n",
        "#     for an in aNAMES:\n",
        "#       resourceId,_ = an.split('_')\n",
        "#       a,b = MERIT_PROBS.loc[\n",
        "#         MERIT_PROBS['ResourceId'] == resourceId,\n",
        "#         ['MeritProb', 'DemeritProb']\n",
        "#       ].values[0]\n",
        "#       if np.random.uniform() < a: merit = 1\n",
        "#       else: merit = 0\n",
        "#       if np.random.uniform() < b: demerit = 1\n",
        "#       else: demerit = 0\n",
        "#       M_tt1[an] = merit - demerit ##net merit\n",
        "#     return M_tt1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "mTtozO6P4TYW",
        "outputId": "926b2a1f-8932-45aa-f896-d4f166d2777b"
      },
      "outputs": [],
      "source": [
        "## copy from the generated file and paste into ExogInfo tab of shift_scheduler_data.xlsx\n",
        "# mer_sim = MeritSimulator(seed=1234)\n",
        "# MeritData = []\n",
        "# # for i in range(100):\n",
        "# for i in range(672):\n",
        "#   mer = list(mer_sim.simulate().values())\n",
        "#   MeritData.append(mer)\n",
        "# labels = [f'{an}_merit' for an in aNAMES]\n",
        "# df = pd.DataFrame.from_records(data=MeritData, columns=labels); df[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "## copy from this file and paste into ExogInfo tab of shift_scheduler_data.xlsx\n",
        "## df.to_excel('merits.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yAfaULLkEOEt"
      },
      "outputs": [],
      "source": [
        "# ## PUT BACK: COMMENTED OUT TO BE FASTER\n",
        "# import random\n",
        "# def plot_output(df1, df2):\n",
        "#   n_charts = len(aNAMES)\n",
        "#   ylabelsize = 16\n",
        "#   mpl.rcParams['lines.linewidth'] = 1.2\n",
        "#   default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "#   fig, axs = plt.subplots(n_charts, sharex=True)\n",
        "#   fig.set_figwidth(13); fig.set_figheight(9)\n",
        "#   fig.suptitle('Merit Simulation', fontsize=20)\n",
        "\n",
        "#   for i,an in enumerate(aNAMES):\n",
        "#     axs[i].set_title(f'Merits for {an}')\n",
        "#     axs[i].set_ylim(-1, 1); axs[i].spines['top'].set_visible(False); axs[i].spines['right'].set_visible(True); axs[i].spines['bottom'].set_visible(False)\n",
        "#     axs[i].step(df1[f'{an}_merit'], 'r-')\n",
        "#     ## axs[i].axhline(y=dem_sim.muD[e], color='k', linestyle=':')\n",
        "#     axs[i].axhline(y=0, color='k', linestyle=':')\n",
        "#   axs[i].set_xlabel('$t\\ \\mathrm{[hourly\\ windows]}$', rotation=0, ha='center', va='center', fontweight='bold', size=ylabelsize)\n",
        "# plot_output(df, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkvQ6n1my80e"
      },
      "source": [
        "## 3 DATA PREPARATION\n",
        "\n",
        "We will use the data provided by the simulator directly. There is no need to perform additional data preparation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z3sGG4yyux7"
      },
      "source": [
        "## 4 MODELING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwQ25pjWC0Y7"
      },
      "source": [
        "### 4.1 Narrative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGnYO_bFyf7y"
      },
      "source": [
        "Please review the narrative in section 1. The next figure is a representation of the solution to the problem:\n",
        "\n",
        "![AIShiftScheduler1](AIShiftScheduler1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZGUp8vTIfTa"
      },
      "source": [
        "### 4.2 Core Elements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SibntzRdsDGq"
      },
      "source": [
        "This section attempts to answer three important questions:\n",
        "\n",
        "- What metrics are we going to track?\n",
        "- What decisions do we intend to make?\n",
        "- What are the sources of uncertainty?\n",
        "\n",
        "For this problem, the only metric we are interested in is the cumulative reward after each horizon. The only source of uncertainty is the levels of demand and the merits/demerits for each of the resource types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCLpaG7WC_ZW"
      },
      "source": [
        "### 4.3 Mathematical Model | SUS Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGnWr46Ehwe"
      },
      "source": [
        "A Python class is used to implement the model for the SUS (System Under Steer):\n",
        "\n",
        "```\n",
        "class Model():\n",
        "  def __init__(self, S_0_info):\n",
        "    ...\n",
        "    ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNuN57TWsw6w"
      },
      "source": [
        "#### 4.3.1 State variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rl-ri-4tcbS"
      },
      "source": [
        "The *state variables* represent *what we need to know*.\n",
        "\n",
        "- $R^{Avail}_t = (R^{Avail}_{ta})_{a \\in \\cal A}$ where $\\cal{A} = \\{\\alpha_1, \\alpha_2, ... \\alpha_{10}\\}$\n",
        "  - $R^{Avail}_{ta}$ = Boolean indicator for whether this resource (with attribute $a$), is available at $t$ for rental\n",
        "  - $\\alpha_1$ = 1_Courtesy\n",
        "  - $\\alpha_2$ = 2_Courtesy\n",
        "  - $\\alpha_3$ = 3_Courtesy\n",
        "  - ...\n",
        "  - $\\alpha_{15}$ = 9_Stocker\n",
        "  - $\\alpha_{16}$ = 10_Stocker\n",
        "- $R^{CumShifts}_t = (R^{CumShifts}_{ta})_{a \\in \\cal A}$ where $\\cal{A} = \\{\\alpha_1, \\alpha_2, ... \\alpha_{10}\\}$\n",
        "  - $R^{CumShifts}_{ta}$ = Number of shifts this resource (with attribute $a$), has worked at $t$\n",
        "  - $\\alpha_1$ = 1_Courtesy\n",
        "  - $\\alpha_2$ = 2_Courtesy\n",
        "  - $\\alpha_3$ = 3_Courtesy\n",
        "  - ...\n",
        "  - $\\alpha_{15}$ = 9_Stocker\n",
        "  - $\\alpha_{16}$ = 10_Stocker\n",
        "- $R^{CumMerits}_t = (R^{CumMerits}_{ta})_{a \\in \\cal A}$ where $\\cal{A} = \\{\\alpha_1, \\alpha_2, ... \\alpha_{10}\\}$\n",
        "  - $R^{CumMerits}_{ta}$ = Number of net merits this resource (with attribute $a$), has gained at $t$\n",
        "  - $\\alpha_1$ = 1_Courtesy\n",
        "  - $\\alpha_2$ = 2_Courtesy\n",
        "  - $\\alpha_3$ = 3_Courtesy\n",
        "  - ...\n",
        "  - $\\alpha_{15}$ = 9_Stocker\n",
        "  - $\\alpha_{16}$ = 10_Stocker  \n",
        "- $D^{Shift}_t = (D^{Shift}_{tb})_{b \\in \\cal B}$ where $\\cal{B} = \\{\\beta_1, \\beta_2\\}$\n",
        "  - $D^{Shift}_{tb}$ = Number of demands for this resource (with attribute $b$), at $t$\n",
        "  - $\\beta_1$ = Courtesy\n",
        "  - $\\beta_1$ = Stocker\n",
        "- $n^{Merits}_t = (n^{Merits}_{tb})_{b \\in \\cal B}$ where $\\cal{B} = \\{\\beta_1, \\beta_2\\}$\n",
        "  - $n^{Merits}_{tb}$ = Number of merits for this resource (with attribute $b$), at $t$\n",
        "  - $\\beta_1$ = Courtesy\n",
        "  - $\\beta_1$ = Stocker  \n",
        "\n",
        "The state is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "S_t &= (R^{Avail}_t, R^{CumShifts}_t, R^{CumMerits}_t, D^{Shift}_t, n^{Merits}_t)\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwbW1BD0s53i"
      },
      "source": [
        "#### 4.3.2 Decision variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbBU0JXa-3jd"
      },
      "source": [
        "The *decision variables* represent *what we control*.\n",
        "\n",
        "The decision vector is given by:\n",
        "\n",
        "- $x_t = (x_{tab})_{a\\in \\cal A, b\\in \\cal B}$ where\n",
        "  - $\\cal{A} = \\{\\alpha_1, \\alpha_2, ... \\alpha_{10}\\}$\n",
        "  - $\\cal{B} = \\{\\beta_1, \\beta_2\\}$\n",
        "  - $x_{tab}$ is a boolean vector that indicates whether a specific resource is to be allocated to a demand\n",
        "\n",
        "- Decisions are made with a policy (TBD below):\n",
        "  - $X^{\\pi}(S_t)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw7gDN1es5yF"
      },
      "source": [
        "#### 4.3.3 Exogenous information variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzGxWTQzDBU8"
      },
      "source": [
        "The *exogenous information variables* represent *what we did not know (when we made a decision)*. These are the variables that we cannot control directly. The information in these variables become available *after* we make the decision $x_t$.\n",
        "\n",
        "When we assume that the demand in each time period is revealed, without any model to predict the demand based on past demands, we have, using approach 1:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "D_{t+1} &= W_{t+1} \\\\\n",
        "        &= \\hat{D}_{t+1}\n",
        "\\end{aligned}         \n",
        "$$\n",
        "\n",
        "Alternatively, when we assume that we observe the *change* in demand $\\hat{D}_{t+1}=p_{t+1}-p_{t}$, we have, using approach 2:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "D_{t+1} &= D_t + W_{t+1} \\\\\n",
        "        &= D_t + \\hat{D}_{t+1}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "We will make use of approach 1 which means that the exogenous information, $W_{t+1}$, is the directly observed demands of the resources.\n",
        "\n",
        "Similarly, for the earned merits, we have\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "n_{t+1} &= W_{t+1} \\\\\n",
        "        &= \\hat{n}_{t+1}\n",
        "\\end{aligned}         \n",
        "$$\n",
        "\n",
        "The exogenous information is obtained by calls to\n",
        "\n",
        "`DemandSimulator.simulate(...)`\n",
        "\n",
        "`MeritSimulator.simulate(...)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtX_whk-s5rD"
      },
      "source": [
        "#### 4.3.4 Transition function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH-C0dbEDJee"
      },
      "source": [
        "The *transition function* describe how the state variables evolve over time. We have the equations:\n",
        "\n",
        "$$\n",
        "R^{Avail}_{t+1} =\n",
        "\\begin{cases}\n",
        "  1 & \\text{if resource with attribute $a$ has not been allocated} \\\\\n",
        "  0 & \\text{if resource with attribute $a$ has been allocated  }\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "$$\n",
        "R^{CumShifts}_{t+1} =\n",
        "\\begin{cases}\n",
        "  R^{CumShifts}_{t} + 1 & \\text{if resource was allocated} \\\\\n",
        "  R^{CumShifts}_{t} & \\text{if resource was not allocated  }\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "$$\n",
        "R^{CumMerits}_{t+1} = R^{CumMerits}_{t} + n^{Merits}_t\n",
        "$$\n",
        "\n",
        "Collectively, they represent the general transition function:\n",
        "\n",
        "$$\n",
        "S_{t+1} = S^M(S_t,X^{\\pi}(S_t))\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnq5fa_ns5fV"
      },
      "source": [
        "#### 4.3.5 Objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyQNktyCDXBr"
      },
      "source": [
        "The *objective function* captures the performance metrics of the solution to the problem.\n",
        "\n",
        "We can write the state-dependant reward (also called contribution due to the allocation of a resource with attribute $b$):\n",
        "\n",
        "$$\n",
        "C(S_t,x_t) =\n",
        "\\begin{cases}\n",
        "  1 & \\text{if resource was allocated} \\\\\n",
        "  -1 & \\text{if resource was not allocated  }\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "We have the objective function:\n",
        "\n",
        "$$\n",
        "\\max_{\\pi}\\mathbb{E}\\{\\sum_{t=0}^{T}C(S_t,x_t,W_{t+1}) \\}\n",
        "$$\n",
        "\n",
        "The learned parameters are:\n",
        "\n",
        "$$(\\theta^{CumShifts}, \\theta^{SickProb}, \\theta^{CumMerits}, \\theta^{Select})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1RdpXhn-t5U"
      },
      "source": [
        "#### 4.3.6 Implementation of the System Under Steer (SUS) Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Wk5naQar6t0m"
      },
      "outputs": [],
      "source": [
        "class Model():\n",
        "  def __init__(self, W_fn=None, S__M_fn=None, C_fn=None):\n",
        "    self.S_t = {\n",
        "      'R_t': pd.DataFrame({\n",
        "        'ResourceId': RESOURCE_IDS,\n",
        "        'Type': TYPES,\n",
        "        'RAvail_t': get_availabilities(pd.to_datetime(START_DATE_TIME)),\n",
        "        'RCumSlots_t': [0]*len(TYPES), ##cumulative allocs (for T)\n",
        "        # /////////////////////\n",
        "        ## 'RMonthCumSlots_t': [0]*len(TYPES),\n",
        "        ## 'RWeekCumSlots_t': [0]*len(TYPES),\n",
        "        ## 'RUtil_t': [0]*len(TYPES),\n",
        "        # \\\\\\\\\\\\\\\\\\\n",
        "        'RCumMerits_t': [0]*len(TYPES),\n",
        "        'RComplete_t': [0]*len(TYPES), ## 1/0: daily slot-run complete or not\n",
        "      }),\n",
        "      'D_t': pd.DataFrame({\n",
        "        'Type': RESOURCE_TYPES,\n",
        "        'DSlot_t': [1]*len(RESOURCE_TYPES), ##why 1?\n",
        "        'DBusy_t': [0]*len(RESOURCE_TYPES),\n",
        "      }),\n",
        "      'M_t': pd.DataFrame({\n",
        "        'ResourceId': RESOURCE_IDS,\n",
        "        'Type': TYPES,\n",
        "        'nMerits_t': [0]*len(TYPES),\n",
        "      }),\n",
        "      'B_t': pd.DataFrame({\n",
        "        'Busy_t': [0],\n",
        "      }),      \n",
        "      'xAlloc_t_1': pd.DataFrame({ ##previous allocation\n",
        "        'Comb': abNAMES, ##Combination\n",
        "        'Allocd_t': [False]*len(abNAMES), ##Allocated\n",
        "      }),\n",
        "    }\n",
        "    self.x_t = {\n",
        "      'xAlloc_t': pd.DataFrame({\n",
        "        'Comb': abNAMES, ##Combination\n",
        "        'Allocd_t': [False]*len(abNAMES), ##Allocated\n",
        "      }),\n",
        "    }\n",
        "    self.Ccum_CumSlots = 0.0\n",
        "    self.Ccum_SickProb = 0.0\n",
        "    self.Ccum_CumMerits = 0.0\n",
        "    self.Ccum_ContSlots = 0.0\n",
        "    self.Ccum = 0.0 ##cumulative reward\n",
        "\n",
        "    self.Ucum_Total = 0 ##cumulative unallocated/unmet demands\n",
        "    ##cumulative unallocated/unmet demands\n",
        "    self.Ucum = {rt: 0 for rt in RESOURCE_TYPES}\n",
        "    self.W_tt1 = {}\n",
        "\n",
        "  ## def reset(self):\n",
        "  #   self.Ccum = 0.0\n",
        "  #   self.Ucum = 0\n",
        "\n",
        "  ## exogenous information\n",
        "  def W_fn(self, t, dt):\n",
        "    return {\n",
        "      ## 'demands': DEM.simulate(),\n",
        "      ## 'demands': {'Courtesy': 2, 'Stocker': 1},\n",
        "      'demands': { ## TAB function\n",
        "        RESOURCE_TYPES[int(col.split('_')[1])]: EXOG_INFO.loc[EXOG_INFO['Date'] == dt, col].squeeze() \n",
        "        for col in [f'D_{d}' for d in range(len(RESOURCE_TYPES))]\n",
        "      },\n",
        "      ## 'merits': MER.simulate(),\n",
        "      'merits': { ## TAB function\n",
        "        aNAMES[int(col.split('_')[1])]: EXOG_INFO.loc[EXOG_INFO['Date'] == dt, col].squeeze() \n",
        "        for col in [f'M_{m}' for m in range(len(RESOURCE_IDS))]\n",
        "      },\n",
        "      'availabilities': get_availabilities(dt), ## TAB function\n",
        "      'busyness': EXOG_INFO.loc[EXOG_INFO['Date'] == dt, 'busyness'].squeeze()\n",
        "    }\n",
        "\n",
        "  def update_Ccum(self, t, dt, S_t, x_t, theta):\n",
        "    ## dow, hod = ((t + 1)//24)%7, (t + 1)%24; ##print(f'{dow=}, {hod=}')\n",
        "    ## dow, qod = ((t + 1)//96)%7, (t + 1)%96; ##print(f'{dow=}, {qod=}')\n",
        "    dow, sod = ((t + 1)//SLOTS_PER_DAY)%7, (t + 1)%SLOTS_PER_DAY; ##print(f'{dow=}, {sod=}')\n",
        "    m1 = \\\n",
        "      x_t['xAlloc_t'].merge(\n",
        "      S_t['R_t']\\\n",
        "       [['RCumSlots_t', 'RAvail_t', 'RCumMerits_t']],\n",
        "       left_index=True, right_index=True)\n",
        "\n",
        "    ## merge in previous allocations\n",
        "    m1a = \\\n",
        "      S_t['xAlloc_t_1'].merge(\n",
        "      m1[['Allocd_t', 'RCumSlots_t', 'RAvail_t', 'RCumMerits_t']],\n",
        "      left_index=True, right_index=True)\n",
        "    m1a.rename(columns={'Allocd_t_x': 'Allocd_t_1', 'Allocd_t_y': 'Allocd_t'}, inplace=True)\n",
        "\n",
        "    m2 = \\\n",
        "      m1a.merge(\n",
        "      SICK_PROBS[[dt.month_name()]],\n",
        "      left_index=True, right_index=True)\n",
        "    m2.rename(columns={dt.month_name(): 'SickProb'}, inplace=True)\n",
        "\n",
        "    m2['Capacity'] = pd.DataFrame({'Capacity': get_capacities(dow)})\n",
        "    m2['Ccum_CumSlots'] = -(m2['RCumSlots_t'] - m2['Capacity'])\n",
        "\n",
        "    ## m2['Ccum_SickProb'] = -100*m2['SickProb']\n",
        "    ## m2['Ccum_SickProb'] = -100*(m2['SickProb'] - m2['SickProb'].mean()) ##100 makes values more comparable with other component of Ccum\n",
        "    m2['Ccum_SickProb'] = -1*(m2['SickProb'] - m2['SickProb'].mean()) ##100 makes values more comparable with other component of Ccum\n",
        "\n",
        "    m2['Ccum_CumMerits'] = m2['RCumMerits_t']\n",
        "\n",
        "    m2.loc[ ## contiguous slots\n",
        "      (m2['Allocd_t'] == True) & \\\n",
        "      (m2['Allocd_t'] == m2['Allocd_t_1']),\n",
        "      ['Ccum_ContSlots']\n",
        "    ] = CONTIGUOUS_REWARD ## reward if shift is continued without interuption\n",
        "\n",
        "    summables = m2.loc[\n",
        "      m2['Allocd_t'] == True,\n",
        "      ['Ccum_CumSlots', 'Ccum_SickProb', 'Ccum_CumMerits', 'Ccum_ContSlots'],\n",
        "    ]\n",
        "    Ccum_CumSlots, Ccum_SickProb, Ccum_CumMerits, Ccum_ContSlots = summables.sum(axis=0)\n",
        "    Ccum = \\\n",
        "      theta.thCumSlots*Ccum_CumSlots + \\\n",
        "      theta.thSickProb*Ccum_SickProb + \\\n",
        "      theta.thCumMerits*Ccum_CumMerits + \\\n",
        "      theta.thContSlots*Ccum_ContSlots\n",
        "    self.Ccum_CumSlots += Ccum_CumSlots\n",
        "    self.Ccum_SickProb += Ccum_SickProb\n",
        "    self.Ccum_CumMerits += Ccum_CumMerits\n",
        "    self.Ccum_ContSlots += Ccum_ContSlots\n",
        "    self.Ccum += Ccum\n",
        "\n",
        "    ##resource expense & revenue\n",
        "    tmp = x_t['xAlloc_t'].loc[\n",
        "      x_t['xAlloc_t']['Allocd_t'] == True,\n",
        "    ]\n",
        "    tmp = tmp.copy()\n",
        "    tmp['type'] = tmp.apply(lambda row: row.Comb.split('_')[0], axis=1)\n",
        "    tmp['expense'] = tmp.apply(lambda row: RESOURCE_EXPENSE[row.type], axis=1)\n",
        "    ## tmp['revenue'] = tmp.apply(lambda row: RESOURCE_REVENUE[row.type], axis=1)\n",
        "    expense = tmp['expense'].sum()\n",
        "    self.Ccum -= expense\n",
        "    ## revenue = tmp['revenue'].sum()\n",
        "    ## self.Ccum += revenue\n",
        "    \n",
        "    ## busyness revenue\n",
        "    busyness = self.W_tt1['busyness']\n",
        "    # revenue = REVENUE_PER_BUSYNESS_PER_HOUR*0.01*busyness ##busyness varies from 0 to 100\n",
        "    revenue = REVENUE_PER_BUSYNESS*0.01*busyness ##busyness varies from 0 to 100\n",
        "    self.Ccum += revenue\n",
        "\n",
        "  def performAllocDecision(self, S_t, x_t, theta):\n",
        "    ## find list of ResourceIds for allocs from x_t\n",
        "    resourceIds = x_t['xAlloc_t'].loc[\n",
        "      x_t['xAlloc_t']['Allocd_t']==True,\n",
        "      ['Comb']\n",
        "    ]['Comb'].str.split('_').str[1:2].tolist(); ##print(f'{resourceIds=}')\n",
        "    resourceIds_flat = [e[0] for e in resourceIds]; ##print(f'{resourceIds_flat=}')\n",
        "\n",
        "    ## update state of allocs\n",
        "    S_t['R_t'].loc[\n",
        "      S_t['R_t']['ResourceId'].isin(resourceIds_flat),\n",
        "      ['RAvail_t']\n",
        "    ] = 0\n",
        "    S_t['R_t'].loc[\n",
        "      S_t['R_t']['ResourceId'].isin(resourceIds_flat),\n",
        "      ['RCumSlots_t']\n",
        "    ] += 1\n",
        "\n",
        "    ## update Ccum with allocations\n",
        "    ## self.Ccum += len(resourceIds_flat) #number of allocations\n",
        "\n",
        "  def S__M_fn(self, t, dt, S_t, x_t, W_tt1, theta):\n",
        "    ## dow, hod = ((t + 1)//24)%7, (t + 1)%24; ##print(f'{dow=}, {hod=}')\n",
        "    ## dow, qod = ((t + 1)//96)%7, (t + 1)%96; ##print(f'{dow=}, {qod=}')\n",
        "    dow, sod = ((t + 1)//SLOTS_PER_DAY)%7, (t + 1)%SLOTS_PER_DAY; ##print(f'{dow=}, {sod=}')\n",
        "\n",
        "    ## perform decision taken this morning\n",
        "    self.performAllocDecision(S_t, x_t, theta)\n",
        "\n",
        "    ## Update state from exogenous information\n",
        "    for rt in RESOURCE_TYPES:\n",
        "      rt_demands = W_tt1['demands'][rt]\n",
        "      S_t['D_t'].loc[S_t['D_t']['Type'] == rt, 'DSlot_t'] = rt_demands\n",
        "    for an in aNAMES:\n",
        "      resId = an.split('_')[1]\n",
        "      merits = W_tt1['merits'][an]\n",
        "      S_t['M_t'].loc[S_t['M_t']['ResourceId'] == resId, 'nMerits_t'] = merits\n",
        "    S_t['R_t']['RAvail_t'] = W_tt1['availabilities']\n",
        "    busyness = W_tt1['busyness']\n",
        "    S_t['B_t']['Busy_t'] = busyness\n",
        "    for rt in RESOURCE_TYPES:\n",
        "      # rt_demands = BUSYNESS_RATE[rt]*0.01*busyness ##busyness varies from 0 to 100\n",
        "      rt_demands = DEMAND_PER_BUSYNESS[rt]*0.01*busyness ##busyness varies from 0 to 100\n",
        "      S_t['D_t'].loc[S_t['D_t']['Type'] == rt, 'DBusy_t'] = rt_demands\n",
        "\n",
        "    ## Update cumulative merits of all resources\n",
        "    S_t['R_t']['RCumMerits_t'] += S_t['M_t']['nMerits_t']\n",
        "\n",
        "    ## Update RComplete_t\n",
        "    m1 = \\\n",
        "      S_t['xAlloc_t_1'].merge(\n",
        "      x_t['xAlloc_t'],\n",
        "      left_index=True, right_index=True)\n",
        "    m1.rename(columns={'Comb_x': 'Comb', 'Allocd_t_x': 'Allocd_t_1', 'Allocd_t_y': 'Allocd_t'}, inplace=True)\n",
        "    m1.drop('Comb_y', inplace=True, axis=1)\n",
        "    m2 = m1.loc[(m1['Allocd_t_1'] == True) & (m1['Allocd_t'] == False)]\n",
        "    resourceIds = m2.loc[\n",
        "      (m2['Allocd_t_1'] == True) & (m2['Allocd_t'] == False),\n",
        "      ['Comb']\n",
        "    ]['Comb'].str.split('_').str[1:2].tolist(); ##print(f'{resourceIds=}')\n",
        "    resourceIds_flat = [e[0] for e in resourceIds]; ##print(f'{resourceIds_flat=}')\n",
        "    S_t['R_t'].loc[\n",
        "      S_t['R_t']['ResourceId'].isin(resourceIds_flat),\n",
        "      ['RComplete_t']\n",
        "    ] = 1\n",
        "\n",
        "    ## Update 'xAlloc_t_1'\n",
        "    S_t['xAlloc_t_1'] = copy(x_t['xAlloc_t']) ## SG\n",
        "\n",
        "    # ## Reset for new month\n",
        "    # if dt.is_month_start:\n",
        "    #   S_t['R_t']['RMonthCumSlots_t'] = 0\n",
        "\n",
        "    # ## Reset for new week\n",
        "    # if dow == 0:\n",
        "    #   S_t['R_t']['RMonthCumSlots_t'] += S_t['R_t']['RWeekCumSlots_t']\n",
        "    #   S_t['R_t']['RWeekCumSlots_t'] = 0\n",
        "\n",
        "    ## Reset for new day\n",
        "    if sod == 0: ## slot-of-day\n",
        "      S_t['R_t']['RCumSlots_t'] = 0; ##print(f'%%% Resetting RCumSlots_t ...')\n",
        "      ## S_t['R_t']['RWeekCumSlots_t'] += S_t['R_t']['RCumSlots_t']\n",
        "      ## S_t['R_t']['RCumSlots_t'] = 0; ##print(f'%%% Resetting RCumSlots_t ...')\n",
        "\n",
        "      S_t['R_t']['RComplete_t'] = 0\n",
        "      self.Ucum = {rt: 0 for rt in RESOURCE_TYPES}\n",
        "      self.Ucum_Total = 0\n",
        "      self.Ccum_CumSlots = 0.0\n",
        "      ## self.Ccum_SickProb = 0.0\n",
        "      ## self.Ccum_CumMerits = 0.0\n",
        "      self.Ccum_ContSlots = 0.0\n",
        "      ## self.Ccum = 0.0\n",
        "\n",
        "    record_t = [t, dt] + \\\n",
        "      list(S_t['R_t']['RAvail_t']) + \\\n",
        "      list(S_t['R_t']['RCumSlots_t']) + \\\n",
        "      list(S_t['R_t']['RCumMerits_t']) + \\\n",
        "      list(S_t['R_t']['RComplete_t']) + \\\n",
        "      list(S_t['D_t']['DSlot_t']) + \\\n",
        "      list(S_t['D_t']['DBusy_t']) + \\\n",
        "      [S_t['B_t']['Busy_t']] + \\\n",
        "      [self.Ucum[rt] for rt in RESOURCE_TYPES] + \\\n",
        "      [self.Ucum_Total] + \\\n",
        "      [self.Ccum_CumSlots] + \\\n",
        "      [self.Ccum_SickProb] + \\\n",
        "      [self.Ccum_CumMerits] + \\\n",
        "      [self.Ccum_ContSlots] + \\\n",
        "      [self.Ccum] + \\\n",
        "      list(x_t['xAlloc_t']['Allocd_t'])\n",
        "    return record_t\n",
        "\n",
        "  def C_fn(self, S_t, x_t, W_tt1, theta):\n",
        "    return\n",
        "\n",
        "  def step(self, t, dt, theta):\n",
        "    ## IND = '\\t\\t'\n",
        "    ## print(f\"{IND}..... M. step() .....\\n{t=}\\n{theta=}\")\n",
        "    self.W_tt1 = self.W_fn(t, dt); ##print(f'%%% {W_tt1=}')\n",
        "\n",
        "    ## update state & reward\n",
        "    record_t = self.S__M_fn(t, dt, self.S_t, self.x_t, self.W_tt1, theta)\n",
        "    return record_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwfuUIAoNRoD"
      },
      "source": [
        "### 4.4 Uncertainty Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it1VtgVQPssJ"
      },
      "source": [
        "We will simulate the shift demand vector $D^{Shift}_{t+1}$, and number of merits vector $n^{Merits}_{t+1}$ as described in section 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL3DjamdYYss"
      },
      "source": [
        "### 4.5 Policy Design\n",
        "There are two main meta-classes of policy design. Each of these has two subclasses:\n",
        "- Policy Search\n",
        "  - Policy Function Approximations (PFAs)\n",
        "  - Cost Function Approximations (CFAs)\n",
        "- Lookahead\n",
        "  - Value Function Approximations (VFAs)\n",
        "  - Direct Lookaheads (DLAs)\n",
        "\n",
        "In this project we will only use one approach:\n",
        "- A simple allocate parameterized policy (from the PFA class), called `X__Alloc`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARYO_gl6NNJC"
      },
      "source": [
        "#### 4.5.1 Implementation of Policy Design"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "@ray.remote\n",
        "def parallel_run_grid_sample_paths(pol, theta, piName):\n",
        "    CcumIomega__lI = []\n",
        "    record = []\n",
        "    for l in range(1, L + 1): ## for each sample-path\n",
        "        print(f'\\t%%% {l=}')\n",
        "        M = Model()\n",
        "        pol.model = M\n",
        "        record_l = [piName, theta, l]\n",
        "        dt = pd.to_datetime(START_DATE_TIME)\n",
        "        dt_delta = pd.Timedelta(DATE_TIME_DELTA)\n",
        "        for t in range(T): ## for each transition/step\n",
        "            ## print(f'\\t%%% {t=}')\n",
        "            ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "            ## Lookup new (today's) decision\n",
        "            getattr(pol, piName)(t, dt, pol.model.S_t, pol.model.x_t, theta)\n",
        "\n",
        "            ## sit in post-decision state until end of cycle (evening),\n",
        "            ## waiting for exog info to arrive\n",
        "\n",
        "            ## Change from today to tomorrow\n",
        "            ## S_t, Ccum, x_t = self.model.step(t, x_t, theta)\n",
        "            record_t = pol.model.step(t, dt, theta)\n",
        "            ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "            record.append(record_l + record_t)\n",
        "            dt = dt + dt_delta\n",
        "        CcumIomega__lI.append(pol.model.Ccum) ##just above (SDAM-eq2.9)\n",
        "    return (CcumIomega__lI, record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ogYhzyGffq3F"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "class Policy():\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "    self.Policy = namedtuple('Policy', piNAMES) ## 'class'\n",
        "    self.Theta = namedtuple('Theta', thNAMES) ## 'class'\n",
        "\n",
        "  def build_policy(self, info):\n",
        "    return self.Policy(*[info[pin] for pin in piNAMES])\n",
        "\n",
        "  def build_theta(self, info):\n",
        "    return self.Theta(*[info[thn] for thn in thNAMES])\n",
        "\n",
        "  def X__Alloc(self, t, dt, S_t, x_t, theta):\n",
        "    ## print(f\"\\n..... Policy.X__Alloc() .....\\n{t=}, {dt=}\")\n",
        "    demandsToService = []\n",
        "    for rt in RESOURCE_TYPES:\n",
        "      number = S_t['D_t'].loc[\n",
        "        S_t['D_t']['Type']==rt,\n",
        "        ['DSlot_t', 'DBusy_t']\n",
        "      ].sum(axis=1).squeeze() ##add the contributions of each demand: due to D_n & busyness\n",
        "      demandsToService.append((rt, round(number))) ##whole number of resources\n",
        "    ## print(f\"demandsToService:\\n{demandsToService}\")\n",
        "    for demand in demandsToService:\n",
        "      resourceType, number = demand; ##print(f'{resourceType=}, {number=}')\n",
        "      candidates_avail = S_t['R_t'].loc[\n",
        "        (S_t['R_t']['Type'] == resourceType) & \\\n",
        "        (S_t['R_t']['RAvail_t'] == 1) & \\\n",
        "        (S_t['R_t']['RComplete_t'] == 0) & \\\n",
        "        (S_t['R_t']['RCumSlots_t'] < MAX_DAILY_SLOT_RUN),\n",
        "        ## (S_t['R_t']['RUtil_t'] < GOV_UTIL_THRESH) & \\\n",
        "        ['ResourceId', 'Type', 'RAvail_t', 'RComplete_t', 'RCumSlots_t', 'RCumMerits_t']\n",
        "      ]; ## print(f'candidates_avail BEFORE arrangement for selection=\\n{candidates_avail}')\n",
        "      ## merge with previous allocations to enhance contiguous allocs\n",
        "      candidates = \\\n",
        "        S_t['xAlloc_t_1']\\\n",
        "        .merge(candidates_avail, left_index=True, right_index=True)\\\n",
        "        .sort_values(by='Allocd_t', ascending=False)\n",
        "      candidates.rename(columns={'Allocd_t': 'Allocd_t_1'}, inplace=True)\n",
        "      if len(candidates) > 0 and number > 0:\n",
        "        if theta.thSelect == 'random':\n",
        "          candidates = candidates.sample(frac = 1) ## shuffle rows; now opt/non have different x's\n",
        "          candidates = candidates.sort_values(by=['Allocd_t_1'], ascending=False)\n",
        "        elif theta.thSelect == 'ranked_CumMerits':\n",
        "          candidates = candidates.sort_values(by=['Allocd_t_1','RCumMerits_t'], ascending=False)\n",
        "        else:\n",
        "          print(f'ERROR: Invalid value for theta.thSelect: {theta.thSelect}')\n",
        "        ## print(f'candidates AFTER arrangement for selection=\\n{candidates}')\n",
        "        if len(candidates) >= number:\n",
        "          allocs = candidates.iloc[0:number, :]; ##print(f'allocs=\\n{allocs}') #pick first 'number' avails\n",
        "        elif len(candidates) < number:\n",
        "          ##print('%%% NOT ENOUGH candidates')\n",
        "          allocs = copy(candidates); ##print(f'allocs=\\n{allocs}') ##pick all candidates\n",
        "          unallocated_demands = number - len(candidates) ##unmet demands\n",
        "          ## self.model.Ccum -= unallocated_demands\n",
        "          self.model.Ucum_Total += unallocated_demands\n",
        "          self.model.Ucum[resourceType] += unallocated_demands\n",
        "        if len(allocs) == 0:\n",
        "          x_t['xAlloc_t'].loc[\n",
        "            x_t['xAlloc_t']['Comb'].map(lambda e: e.split('_')[0]==resourceType),\n",
        "            ['Allocd_t']\n",
        "          ] = False\n",
        "        else:\n",
        "          x_t['xAlloc_t'].loc[ ##remove all allocs before adding new allocs\n",
        "            x_t['xAlloc_t']['Comb'].map(lambda e: e.split('_')[0]==resourceType),\n",
        "            ['Allocd_t']\n",
        "          ] = False\n",
        "          x_t['xAlloc_t'].loc[\n",
        "            x_t['xAlloc_t']['Comb'].apply(lambda x: x.split(\"_\")[1]).isin(allocs['ResourceId']),\n",
        "            ['Allocd_t']\n",
        "          ] = True\n",
        "          ## TODO: update utilizations\n",
        "        self.model.update_Ccum(t, dt, S_t, x_t, theta)\n",
        "      else:\n",
        "        ## print(f'%%% Shift has no resource for demand {demand}, or demand is 0.')\n",
        "        x_t['xAlloc_t'].loc[\n",
        "          x_t['xAlloc_t']['Comb'].map(lambda e: e.split('_')[0]==resourceType),\n",
        "          ['Allocd_t']\n",
        "        ] = False\n",
        "      ## print(f\"x_t['xAlloc_t']:\\n{x_t['xAlloc_t']}\")\n",
        "\n",
        "  def run_grid_sample_paths(self, theta, piName, record):\n",
        "    CcumIomega__lI = []\n",
        "    for l in range(1, L + 1): ## for each sample-path\n",
        "      print(f'\\t%%% {l=}')\n",
        "      M = Model()\n",
        "      ## P = Policy(M) ## SG, NO!, overwrite existing global P\n",
        "      self.model = M\n",
        "      record_l = [piName, theta, l]\n",
        "      dt = pd.to_datetime(START_DATE_TIME)\n",
        "      dt_delta = pd.Timedelta(DATE_TIME_DELTA)\n",
        "      for t in range(T): ## for each transition/step\n",
        "        ## print(f'\\t%%% {t=}')\n",
        "        ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "        ## Lookup new (today's) decision\n",
        "        getattr(self, piName)(t, dt, self.model.S_t, self.model.x_t, theta)\n",
        "\n",
        "        ## sit in post-decision state until end of cycle (evening),\n",
        "        ## waiting for exog info to arrive\n",
        "\n",
        "        ## Change from today to tomorrow\n",
        "        ## S_t, Ccum, x_t = self.model.step(t, x_t, theta)\n",
        "        record_t = self.model.step(t, dt, theta)\n",
        "        ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "        record.append(record_l + record_t)\n",
        "        dt = dt + dt_delta\n",
        "      CcumIomega__lI.append(self.model.Ccum) ##just above (SDAM-eq2.9)\n",
        "    return CcumIomega__lI\n",
        "\n",
        "  def perform_grid_search_sample_paths(self, piName, thetas):\n",
        "    Cbarcum = defaultdict(float)\n",
        "    Ctilcum = defaultdict(float)\n",
        "    expCbarcum = defaultdict(float)\n",
        "    expCtilcum = defaultdict(float)\n",
        "    numThetas = len(thetas)\n",
        "    record = []\n",
        "    print(f'{numThetas=:,}')\n",
        "    nth = 1\n",
        "    i = 0; print(f'... printing every {nth}th theta (if considered) ...')\n",
        "    for theta in thetas:\n",
        "      if True: ##in case relationships between thetas can be exploited\n",
        "        ## a dict cannot be used as a key, so we define theta_key, e.g.\n",
        "        ## theta_key = ((168.0, 72.0), (200.0, 90.0)):\n",
        "        ## theta_key = tuple(tuple(itm.values()) for itm in theta)\n",
        "        theta_key = theta ##if theta is not a dict\n",
        "\n",
        "        ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "        CcumIomega__lI = self.run_grid_sample_paths(theta, piName, record)\n",
        "        ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "        Cbarcum_tmp = np.array(CcumIomega__lI).mean() #(SDAM-eq2.9)\n",
        "        Ctilcum_tmp = np.sum(np.square(np.array(CcumIomega__lI) - Cbarcum_tmp))/(L - 1)\n",
        "\n",
        "        Cbarcum[theta_key] = Cbarcum_tmp\n",
        "        Ctilcum[theta_key] = np.sqrt(Ctilcum_tmp/L)\n",
        "\n",
        "        expCbarcum_tmp = pd.Series(CcumIomega__lI).expanding().mean()\n",
        "        expCbarcum[theta_key] = expCbarcum_tmp\n",
        "\n",
        "        expCtilcum_tmp = pd.Series(CcumIomega__lI).expanding().std()\n",
        "        expCtilcum[theta_key] = expCtilcum_tmp\n",
        "        if i%nth == 0: print(f'{i:,}/{(numThetas-1):,}, {Cbarcum[theta_key]:,.0f}, {theta}')\n",
        "        i += 1\n",
        "      ##endif\n",
        "    best_theta = max(Cbarcum, key=Cbarcum.get)\n",
        "    worst_theta = min(Cbarcum, key=Cbarcum.get)\n",
        "\n",
        "    best_Cbarcum = Cbarcum[best_theta]\n",
        "    best_Ctilcum = Ctilcum[best_theta]\n",
        "\n",
        "    worst_Cbarcum = Cbarcum[worst_theta]\n",
        "    worst_Ctilcum = Ctilcum[worst_theta]\n",
        "\n",
        "    thetaStar_expCbarcum = expCbarcum[best_theta]\n",
        "    thetaStar_expCtilcum = expCtilcum[best_theta]\n",
        "    thetaStar_expCtilcum[0] = 0 ##set NaN to 0\n",
        "\n",
        "    ## best_theta_w_names = tuple((\n",
        "    #   ({\n",
        "    #     a1NAMES[0]: subvec[0],\n",
        "    #     a1NAMES[1]: subvec[1]\n",
        "    #   })) for subvec in best_theta)\n",
        "    ## best_theta_n = self.build_theta({'thAdj': best_theta_w_names[0]})\n",
        "    ## best_theta_n = self.build_theta({'thAdj1': best_theta_w_names[0], 'thAdj3': best_theta_w_names[1]})\n",
        "    ## print(f'best_theta_n:\\n{best_theta_n}\\n{best_Cbarcum=:.2f}\\n{best_Ctilcum=:.2f}')\n",
        "\n",
        "    ## worst_theta_w_names = tuple((\n",
        "    #   ({\n",
        "    #     a1NAMES[0]: subvec[0],\n",
        "    #     a1NAMES[1]: subvec[1]})) for subvec in worst_theta)\n",
        "    ## worst_theta_n = self.build_theta({'thAdj': worst_theta_w_names[0]})\n",
        "    ## worst_theta_n = self.build_theta({'thAdj1': worst_theta_w_names[0], 'thAdj3': worst_theta_w_names[1]})\n",
        "    ## print(f'worst_theta_n:\\n{worst_theta_n}\\n{worst_Cbarcum=:.2f}\\n{worst_Ctilcum=:.2f}')\n",
        "\n",
        "    return \\\n",
        "      thetaStar_expCbarcum, thetaStar_expCtilcum, \\\n",
        "      Cbarcum, Ctilcum, \\\n",
        "      best_theta, worst_theta, \\\n",
        "      best_Cbarcum, worst_Cbarcum, \\\n",
        "      best_Ctilcum, worst_Ctilcum, \\\n",
        "      record\n",
        "\n",
        "  ## def parallel_run_grid_sample_paths(...) is a function above this class\n",
        "\n",
        "  def parallel_perform_grid_search_sample_paths(self, piName, thetas):\n",
        "      Cbarcum = defaultdict(float)\n",
        "      Ctilcum = defaultdict(float)\n",
        "      expCbarcum = defaultdict(float)\n",
        "      expCtilcum = defaultdict(float)\n",
        "      numThetas = len(thetas)\n",
        "      record = []\n",
        "      print(f'{numThetas=:,}')\n",
        "      nth = 1\n",
        "      i = 0; print(f'... printing every {nth}th theta (if considered) ...')\n",
        "      \n",
        "      ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "      ## THIS BREAKS:\n",
        "      ## futures = [self.parallel_run_grid_sample_paths.remote(theta, piName) for theta in thetas]\n",
        "      futures = [parallel_run_grid_sample_paths.remote(self, theta, piName) for theta in thetas]\n",
        "      result = ray.get(futures)\n",
        "      ## return result ##handy to debug\n",
        "      ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "      for j,theta in enumerate(thetas):\n",
        "          ## if True: ##in case relationships between thetas can be exploited\n",
        "          ## a dict cannot be used as a key, so we define theta_key, e.g.\n",
        "          ## theta_key = ((168.0, 72.0), (200.0, 90.0)):\n",
        "          ## theta_key = tuple(tuple(itm.values()) for itm in theta)\n",
        "          theta_key = theta ##if theta is not a dict\n",
        "\n",
        "          ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "          ## CcumIomega__lI = self.run_grid_sample_paths(theta, piName, record)\n",
        "          ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "          ## Cbarcum_tmp = np.array(CcumIomega__lI).mean() #(SDAM-eq2.9)\n",
        "          Cbarcum_tmp = np.array(result[j][0]).mean() #(SDAM-eq2.9)\n",
        "          ## Ctilcum_tmp = np.sum(np.square(np.array(CcumIomega__lI) - Cbarcum_tmp))/(L - 1)\n",
        "          Ctilcum_tmp = np.sum(np.square(np.array(result[j][0]) - Cbarcum_tmp))/(L - 1)\n",
        "\n",
        "          Cbarcum[theta_key] = Cbarcum_tmp\n",
        "          Ctilcum[theta_key] = np.sqrt(Ctilcum_tmp/L)\n",
        "\n",
        "          ## expCbarcum_tmp = pd.Series(CcumIomega__lI).expanding().mean()\n",
        "          expCbarcum_tmp = pd.Series(result[j][0]).expanding().mean()\n",
        "          expCbarcum[theta_key] = expCbarcum_tmp\n",
        "\n",
        "          ## expCtilcum_tmp = pd.Series(CcumIomega__lI).expanding().std()\n",
        "          expCtilcum_tmp = pd.Series(result[j][0]).expanding().std()\n",
        "          expCtilcum[theta_key] = expCtilcum_tmp\n",
        "          if i%nth == 0: print(f'{i:,}/{(numThetas-1):,}, {Cbarcum[theta_key]:,.0f}, {theta}')\n",
        "          i += 1\n",
        "          ##endif\n",
        "          next_th = result[j][1]\n",
        "          for e in next_th:\n",
        "              record.append(e)\n",
        "      best_theta = max(Cbarcum, key=Cbarcum.get)\n",
        "      worst_theta = min(Cbarcum, key=Cbarcum.get)\n",
        "\n",
        "      best_Cbarcum = Cbarcum[best_theta]\n",
        "      best_Ctilcum = Ctilcum[best_theta]\n",
        "\n",
        "      worst_Cbarcum = Cbarcum[worst_theta]\n",
        "      worst_Ctilcum = Ctilcum[worst_theta]\n",
        "\n",
        "      thetaStar_expCbarcum = expCbarcum[best_theta]\n",
        "      thetaStar_expCtilcum = expCtilcum[best_theta]\n",
        "      thetaStar_expCtilcum[0] = 0 ##set NaN to 0\n",
        "\n",
        "      return \\\n",
        "        thetaStar_expCbarcum, thetaStar_expCtilcum, \\\n",
        "        Cbarcum, Ctilcum, \\\n",
        "        best_theta, worst_theta, \\\n",
        "        best_Cbarcum, worst_Cbarcum, \\\n",
        "        best_Ctilcum, worst_Ctilcum, \\\n",
        "        record\n",
        "\n",
        "  ## EXAMPLE:\n",
        "  ## thetasA: Buy\n",
        "  ## thetasA_name: 'thBuy'\n",
        "  ## names: ELA\n",
        "  ## 1_1: 1 theta sub-vectors, each having 1 theta\n",
        "  ## thetas = grid_search_thetas_1_2(thetasBuy 'thBuy', CAR_TYPES)\n",
        "  def grid_search_thetas_1_1(self, thetasA, thetasA_name, names):\n",
        "    thetas = [\n",
        "    self.build_theta({thetasA_name: {names[0]: thA0}})\n",
        "    for thA0 in thetasA[names[0]]\n",
        "    ]\n",
        "    return thetas\n",
        "\n",
        "  ## EXAMPLE:\n",
        "  ## thetasA: Buy\n",
        "  ## thetasA_name: 'thBuy'\n",
        "  ## names: ELA, SON\n",
        "  ## 1_2: 1 theta sub-vectors, each having 2 thetas\n",
        "  ## thetas = grid_search_thetas_1_2(thetasBuy 'thBuy', CAR_TYPES)\n",
        "  def grid_search_thetas_1_2(self, thetasA, thetasA_name, names):\n",
        "    thetas = [\n",
        "    self.build_theta({thetasA_name: {names[0]: thA0, names[1]: thA1}})\n",
        "    for thA0 in thetasA[names[0]]\n",
        "      for thA1 in thetasA[names[1]]\n",
        "    ]\n",
        "    return thetas\n",
        "\n",
        "  ## EXAMPLE:\n",
        "  ## thetasA: Adj\n",
        "  ## thetasA_name: 'thAdj'\n",
        "  ## names: ELA, SON\n",
        "  ## 1_4: 1 theta sub-vectors, each having 4 thetas\n",
        "  ## thetas = grid_search_thetas_1_4(thetasBuy 'thAdj', bNAMES)\n",
        "  def grid_search_thetas_1_4(self, thetasA, thetasA_name, names):\n",
        "    thetas = [\n",
        "    self.build_theta({thetasA_name: {names[0]: thA0, names[1]: thA1, names[2]: thA2, names[3]: thA3}})\n",
        "    for thA0 in thetasA[names[0]]\n",
        "      for thA1 in thetasA[names[1]]\n",
        "        for thA2 in thetasA[names[2]]\n",
        "          for thA3 in thetasA[names[3]]\n",
        "    ]\n",
        "    return thetas\n",
        "\n",
        "  ## EXAMPLE:\n",
        "  ## thetasA: Buy\n",
        "  ## thetasB: Max\n",
        "  ## thetasA_name: 'thBuy'\n",
        "  ## thetasB_name: 'thMax'\n",
        "  ## names: ELA\n",
        "  ## 2_1: 2 theta sub-vectors, each having 1 theta\n",
        "  ## thetas = grid_search_thetas_2_1(thetasBuy, thetasMax, 'thBuy', 'thMax', CAR_TYPES)\n",
        "  def grid_search_thetas_2_1(self, thetasA, thetasB, thetasA_name, thetasB_name, names):\n",
        "    thetas = [\n",
        "    self.build_theta({thetasA_name: {names[0]: thA0}, thetasB_name: {names[0]: thB0}})\n",
        "    for thA0 in thetasA[names[0]]\n",
        "      for thB0 in thetasB[names[0]]\n",
        "    ]\n",
        "    return thetas\n",
        "\n",
        "  ## EXAMPLE:\n",
        "  ## thetasA: Buy\n",
        "  ## thetasB: Max\n",
        "  ## thetasA_name: 'thBuy'\n",
        "  ## thetasB_name: 'thMax'\n",
        "  ## names: ELA, SON\n",
        "  ## 2_2: 2 theta sub-vectors, each having 2 thetas\n",
        "  ## thetas = grid_search_thetas_4(thetasBuy, thetasMax, 'thBuy', 'thMax', CAR_TYPES)\n",
        "  def grid_search_thetas_2_2(self, thetasA, thetasB, thetasA_name, thetasB_name, names):\n",
        "    thetas = [\n",
        "    self.build_theta({thetasA_name: {names[0]: thA0, names[1]: thA1}, thetasB_name: {names[0]: thB0, names[1]: thB1}})\n",
        "    for thA0 in thetasA[names[0]]\n",
        "      for thA1 in thetasA[names[1]]\n",
        "        for thB0 in thetasB[names[0]]\n",
        "          for thB1 in thetasB[names[1]]\n",
        "    ]\n",
        "    return thetas\n",
        "\n",
        "\n",
        "  ############################################################################\n",
        "  ### PLOTTING\n",
        "  ############################################################################\n",
        "  def round_theta(self, complex_theta):\n",
        "    thetas_rounded = []\n",
        "    for theta in complex_theta:\n",
        "      evalues_rounded = []\n",
        "      for _, evalue in theta.items():\n",
        "        evalues_rounded.append(float(f\"{evalue:f}\"))\n",
        "      thetas_rounded.append(tuple(evalues_rounded))\n",
        "    return str(tuple(thetas_rounded))\n",
        "\n",
        "  def plot_Fhat_map_2(self,\n",
        "      FhatI_theta_I,\n",
        "      thetasX, thetasY, labelX, labelY, title):\n",
        "      Fhat_values = [\n",
        "        FhatI_theta_I[\n",
        "          (thetaX,thetaY)\n",
        "          ## ((thetaX,),(thetaY,))\n",
        "        ]\n",
        "          for thetaY in thetasY for thetaX in thetasX\n",
        "      ]\n",
        "      Fhats = np.array(Fhat_values)\n",
        "      increment_count = len(thetasX)\n",
        "      Fhats = np.reshape(Fhats, (-1, increment_count))#.\n",
        "\n",
        "      fig, ax = plt.subplots()\n",
        "      im = ax.imshow(Fhats, cmap='hot', origin='lower', aspect='auto')\n",
        "      ## create colorbar\n",
        "      cbar = ax.figure.colorbar(im, ax=ax)\n",
        "      ## cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
        "\n",
        "      ax.set_xticks(np.arange(0, len(thetasX), 5))#.\n",
        "      ## ax.set_xticks(np.arange(len(thetasX)))\n",
        "\n",
        "      ax.set_yticks(np.arange(0, len(thetasY), 5))#.\n",
        "      ## ax.set_yticks(np.arange(len(thetasY)))\n",
        "\n",
        "      ## NOTE: round tick labels, else very messy\n",
        "      ## function round() does not work, have to do this way\n",
        "      thetasX_form = [f'{th:.0f}' for th in thetasX]\n",
        "      thetasY_form = [f'{th:.0f}' for th in thetasY]\n",
        "\n",
        "      ax.set_xticklabels(thetasX[::5])\n",
        "      ## ax.set_xticklabels(thetasX); ax.set_xticklabels(thetasX_form)\n",
        "\n",
        "      ax.set_yticklabels(thetasY[::5])\n",
        "      ## ax.set_yticklabels(thetasY); ax.set_yticklabels(thetasY_form)\n",
        "\n",
        "      ## rotate the tick labels and set their alignment.\n",
        "      ## plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "\n",
        "      ax.set_title(title)\n",
        "      ax.set_xlabel(labelX)\n",
        "      ax.set_ylabel(labelY)\n",
        "\n",
        "      ## fig.tight_layout()\n",
        "      plt.show()\n",
        "      return True\n",
        "\n",
        "  def plot_Fhat_map_3(self,\n",
        "      FhatI_theta_I,\n",
        "      thetasX, thetasY, labelX, labelY, title,\n",
        "      thetaFixed1):\n",
        "      ## Fhat_values = [FhatI_theta_I[(thetaX,thetaY)] for thetaY in thetasY for thetaX in thetasX]\n",
        "      Fhat_values = [\n",
        "        FhatI_theta_I[(thetaX,thetaY, thetaFixed1)]\n",
        "        for thetaY in thetasY\n",
        "          for thetaX in thetasX]\n",
        "      Fhats = np.array(Fhat_values)\n",
        "      increment_count = len(thetasX)\n",
        "      Fhats = np.reshape(Fhats, (-1, increment_count))#.\n",
        "\n",
        "      fig, ax = plt.subplots()\n",
        "      im = ax.imshow(Fhats, cmap='hot', origin='lower', aspect='auto')\n",
        "      ## create colorbar\n",
        "      cbar = ax.figure.colorbar(im, ax=ax)\n",
        "      ## cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
        "\n",
        "      ax.set_xticks(np.arange(0, len(thetasX), 5))#.\n",
        "      ## ax.set_xticks(np.arange(len(thetasX)))\n",
        "\n",
        "      ax.set_yticks(np.arange(0, len(thetasY), 5))#.\n",
        "      ## ax.set_yticks(np.arange(len(thetasY)))\n",
        "\n",
        "      ## NOTE: round tick labels, else very messy\n",
        "      ## function round() does not work, have to do this way\n",
        "      ## thetasX_form = [f'{th:.1f}' for th in thetasX]\n",
        "      ## thetasY_form = [f'{th:.1f}' for th in thetasY]\n",
        "\n",
        "      ax.set_xticklabels(thetasX[::5])#.\n",
        "      ## ax.set_xticklabels(thetasX)\n",
        "      ## ax.set_xticklabels(thetasX_form)\n",
        "\n",
        "      ax.set_yticklabels(thetasY[::5])#.\n",
        "      ## ax.set_yticklabels(thetasY)\n",
        "      ## ax.set_yticklabels(thetasY_form)\n",
        "\n",
        "      ## rotate the tick labels and set their alignment.\n",
        "      ## plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "\n",
        "      ax.set_title(title)\n",
        "      ax.set_xlabel(labelX)\n",
        "      ax.set_ylabel(labelY)\n",
        "\n",
        "      ## fig.tight_layout()\n",
        "      plt.show()\n",
        "      return True\n",
        "\n",
        "  ## def plot_Fhat_map_4(self, ## sub-vectors\n",
        "  #     FhatI_theta_I,\n",
        "  #     thetasX, thetasY, labelX, labelY, title,\n",
        "  #     thetaFixed1, thetaFixed2):\n",
        "  #     ## Fhat_values = [FhatI_theta_I[(thetaX,thetaY)] for thetaY in thetasY for thetaX in thetasX]\n",
        "  #     Fhat_values = [\n",
        "  #       FhatI_theta_I[((thetaX,thetaY), (thetaFixed1,thetaFixed2))]\n",
        "  #       for thetaY in thetasY\n",
        "  #         for thetaX in thetasX]\n",
        "  #     Fhats = np.array(Fhat_values)\n",
        "  #     increment_count = len(thetasX)\n",
        "  #     Fhats = np.reshape(Fhats, (-1, increment_count))#.\n",
        "\n",
        "  #     fig, ax = plt.subplots()\n",
        "  #     im = ax.imshow(Fhats, cmap='hot', origin='lower', aspect='auto')\n",
        "  #     ## create colorbar\n",
        "  #     cbar = ax.figure.colorbar(im, ax=ax)\n",
        "  #     ## cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
        "\n",
        "  #     ax.set_xticks(np.arange(0, len(thetasX), 5))#.\n",
        "  #     ## ax.set_xticks(np.arange(len(thetasX)))\n",
        "\n",
        "  #     ax.set_yticks(np.arange(0, len(thetasY), 5))#.\n",
        "  #     ## ax.set_yticks(np.arange(len(thetasY)))\n",
        "\n",
        "  #     ## NOTE: round tick labels, else very messy\n",
        "  #     ## function round() does not work, have to do this way\n",
        "  #     ## thetasX_form = [f'{th:.1f}' for th in thetasX]\n",
        "  #     ## thetasY_form = [f'{th:.1f}' for th in thetasY]\n",
        "\n",
        "  #     ax.set_xticklabels(thetasX[::5])#.\n",
        "  #     ## ax.set_xticklabels(thetasX)\n",
        "  #     ## ax.set_xticklabels(thetasX_form)\n",
        "\n",
        "  #     ax.set_yticklabels(thetasY[::5])#.\n",
        "  #     ## ax.set_yticklabels(thetasY)\n",
        "  #     ## ax.set_yticklabels(thetasY_form)\n",
        "\n",
        "  #     ## rotate the tick labels and set their alignment.\n",
        "  #     ## plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "\n",
        "  #     ax.set_title(title)\n",
        "  #     ax.set_xlabel(labelX)\n",
        "  #     ax.set_ylabel(labelY)\n",
        "\n",
        "  #     ## fig.tight_layout()\n",
        "  #     plt.show()\n",
        "  #     return True\n",
        "\n",
        "  def plot_Fhat_map_4(self,  ## no sub-vectors\n",
        "      FhatI_theta_I,\n",
        "      thetasX, thetasY, labelX, labelY, title,\n",
        "      thetaFixed1, thetaFixed2):\n",
        "      ## Fhat_values = [FhatI_theta_I[(thetaX,thetaY)] for thetaY in thetasY for thetaX in thetasX]\n",
        "      Fhat_values = [\n",
        "        FhatI_theta_I[(thetaX,thetaY, thetaFixed1,thetaFixed2)]\n",
        "        for thetaY in thetasY\n",
        "          for thetaX in thetasX]\n",
        "      Fhats = np.array(Fhat_values)\n",
        "      increment_count = len(thetasX)\n",
        "      Fhats = np.reshape(Fhats, (-1, increment_count))#.\n",
        "\n",
        "      fig, ax = plt.subplots()\n",
        "      im = ax.imshow(Fhats, cmap='hot', origin='lower', aspect='auto')\n",
        "      ## create colorbar\n",
        "      cbar = ax.figure.colorbar(im, ax=ax)\n",
        "      ## cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
        "\n",
        "      ax.set_xticks(np.arange(0, len(thetasX), 5))#.\n",
        "      ## ax.set_xticks(np.arange(len(thetasX)))\n",
        "\n",
        "      ax.set_yticks(np.arange(0, len(thetasY), 5))#.\n",
        "      ## ax.set_yticks(np.arange(len(thetasY)))\n",
        "\n",
        "      ## NOTE: round tick labels, else very messy\n",
        "      ## function round() does not work, have to do this way\n",
        "      ## thetasX_form = [f'{th:.1f}' for th in thetasX]\n",
        "      ## thetasY_form = [f'{th:.1f}' for th in thetasY]\n",
        "\n",
        "      ax.set_xticklabels(thetasX[::5])#.\n",
        "      ## ax.set_xticklabels(thetasX)\n",
        "      ## ax.set_xticklabels(thetasX_form)\n",
        "\n",
        "      ax.set_yticklabels(thetasY[::5])#.\n",
        "      ## ax.set_yticklabels(thetasY)\n",
        "      ## ax.set_yticklabels(thetasY_form)\n",
        "\n",
        "      ## rotate the tick labels and set their alignment.\n",
        "      ## plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "\n",
        "      ax.set_title(title)\n",
        "      ax.set_xlabel(labelX)\n",
        "      ax.set_ylabel(labelY)\n",
        "\n",
        "      ## fig.tight_layout()\n",
        "      plt.show()\n",
        "      return True\n",
        "\n",
        "  def plot_Fhat_map_5(self, ## no sub-vectors\n",
        "      FhatI_theta_I,\n",
        "      thetasX, thetasY, labelX, labelY, title,\n",
        "      thetaFixed1, thetaFixed2, thetaFixed3):\n",
        "      ## Fhat_values = [FhatI_theta_I[(thetaX,thetaY)] for thetaY in thetasY for thetaX in thetasX]\n",
        "      Fhat_values = [\n",
        "        FhatI_theta_I[(thetaX,thetaY, thetaFixed1,thetaFixed2,thetaFixed3)]\n",
        "        for thetaY in thetasY\n",
        "          for thetaX in thetasX]\n",
        "      Fhats = np.array(Fhat_values)\n",
        "      increment_count = len(thetasX)\n",
        "      Fhats = np.reshape(Fhats, (-1, increment_count))#.\n",
        "\n",
        "      fig, ax = plt.subplots()\n",
        "      im = ax.imshow(Fhats, cmap='hot', origin='lower', aspect='auto')\n",
        "      ## create colorbar\n",
        "      cbar = ax.figure.colorbar(im, ax=ax)\n",
        "      ## cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
        "\n",
        "      ax.set_xticks(np.arange(0, len(thetasX), 5))#.\n",
        "      ## ax.set_xticks(np.arange(len(thetasX)))\n",
        "\n",
        "      ax.set_yticks(np.arange(0, len(thetasY), 5))#.\n",
        "      ## ax.set_yticks(np.arange(len(thetasY)))\n",
        "\n",
        "      ## NOTE: round tick labels, else very messy\n",
        "      ## function round() does not work, have to do this way\n",
        "      ## thetasX_form = [f'{th:.1f}' for th in thetasX]\n",
        "      ## thetasY_form = [f'{th:.1f}' for th in thetasY]\n",
        "\n",
        "      ax.set_xticklabels(thetasX[::5])#.\n",
        "      ## ax.set_xticklabels(thetasX)\n",
        "      ## ax.set_xticklabels(thetasX_form)\n",
        "\n",
        "      ax.set_yticklabels(thetasY[::5])#.\n",
        "      ## ax.set_yticklabels(thetasY)\n",
        "      ## ax.set_yticklabels(thetasY_form)\n",
        "\n",
        "      ## rotate the tick labels and set their alignment.\n",
        "      ## plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "\n",
        "      ax.set_title(title)\n",
        "      ax.set_xlabel(labelX)\n",
        "      ax.set_ylabel(labelY)\n",
        "\n",
        "      ## fig.tight_layout()\n",
        "      plt.show()\n",
        "      return True\n",
        "\n",
        "  ## color_style examples: 'r-', 'b:', 'g--'\n",
        "  def plot_Fhat_chart(self, FhatI_theta_I, thetasX, labelX, labelY, title, color_style, thetaStar):\n",
        "      mpl.rcParams['lines.linewidth'] = 1.2\n",
        "      xylabelsize = 16\n",
        "      ## plt.figure(figsize=(13, 9))\n",
        "      plt.figure(figsize=(13, 4))\n",
        "      plt.title(title, fontsize=20)\n",
        "      Fhats = FhatI_theta_I.values()\n",
        "      plt.plot(thetasX, Fhats, color_style)\n",
        "      plt.axvline(x=thetaStar, color='k', linestyle=':')\n",
        "      plt.xlabel(labelX, rotation=0, labelpad=10, ha='right', va='center', fontweight='bold', size=xylabelsize)\n",
        "      plt.ylabel(labelY, rotation=0, labelpad=1, ha='right', va='center', fontweight='normal', size=xylabelsize)\n",
        "      plt.show()\n",
        "\n",
        "  ## expanding Fhat chart\n",
        "  def plot_expFhat_chart(self, df, labelX, labelY, title, color_style):\n",
        "    mpl.rcParams['lines.linewidth'] = 1.2\n",
        "    xylabelsize = 16\n",
        "    plt.figure(figsize=(13, 4))\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.plot(df, color_style)\n",
        "    plt.xlabel(labelX, rotation=0, labelpad=10, ha='right', va='center', fontweight='bold', size=xylabelsize)\n",
        "    plt.ylabel(labelY, rotation=0, labelpad=1, ha='right', va='center', fontweight='normal', size=xylabelsize)\n",
        "    plt.show()\n",
        "\n",
        "  ## expanding Fhat charts\n",
        "  def plot_expFhat_charts(self, means, stdvs, labelX, labelY, suptitle, pars=defaultdict(str)):\n",
        "    n_charts = 2\n",
        "    xlabelsize = 14\n",
        "    ylabelsize = 14\n",
        "    mpl.rcParams['lines.linewidth'] = 1.2\n",
        "    default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "    fig, axs = plt.subplots(n_charts, sharex=True)\n",
        "    fig.set_figwidth(13); fig.set_figheight(9)\n",
        "    fig.suptitle(suptitle, fontsize=18)\n",
        "\n",
        "    xi = 0\n",
        "    legendlabels = []\n",
        "    axs[xi].set_title(r\"$exp\\bar{C}^{cum}(\\theta^*)$\", loc='right', fontsize=16)\n",
        "    for i,itm in enumerate(means.items()):\n",
        "      axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "      leg = axs[xi].plot(itm[1], color=pars['colors'][i])\n",
        "      legendlabels.append(itm[0])\n",
        "    axs[xi].set_ylabel(labelY, rotation=0, ha='right', va='center', fontweight='normal', size=ylabelsize)\n",
        "\n",
        "    xi = 1\n",
        "    axs[xi].set_title(r\"$exp\\tilde{C}^{cum}(\\theta^*)$\", loc='right', fontsize=16)\n",
        "    for i,itm in enumerate(stdvs.items()):\n",
        "      axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "      ## leg = axs[xi].plot(itm[1], default_colors[i], linestyle='--')\n",
        "      leg = axs[xi].plot(itm[1], pars['colors'][i], linestyle='--')\n",
        "    axs[xi].set_ylabel(labelY, rotation=0, ha='right', va='center', fontweight='normal', size=ylabelsize)\n",
        "\n",
        "    fig.legend(\n",
        "      ## [leg],\n",
        "      labels=legendlabels,\n",
        "      title=\"Policies\",\n",
        "      loc='upper right',\n",
        "      fancybox=True,\n",
        "      shadow=True,\n",
        "      ncol=1)\n",
        "    plt.xlabel(labelX, rotation=0, labelpad=10, ha='right', va='center', fontweight='normal', size=xlabelsize)\n",
        "    plt.show()\n",
        "\n",
        "  def plot_records(self, df, df_non, pars=defaultdict(str)):\n",
        "    ## add capacities\n",
        "    df = copy(df)\n",
        "    df['dow'] = df['dt'].dt.day_of_week\n",
        "    for i,an in enumerate(aNAMES):\n",
        "      df[f'cap_{an}'] = \\\n",
        "        df.apply(lambda row: \\\n",
        "          get_capacities(dow=row['dow'])[i], axis=1)\n",
        "\n",
        "    n_a = len(aNAMES)\n",
        "    n_b = len(bNAMES)\n",
        "    n_ab = len(abNAMES)\n",
        "    n_x = 1\n",
        "    n_charts = n_ab + n_b + n_a + n_b + 1 + 1 + 4 + 1\n",
        "    ylabelsize = 14\n",
        "    mpl.rcParams['lines.linewidth'] = 1.2\n",
        "    mycolors = ['g', 'b']\n",
        "    fig, axs = plt.subplots(n_charts, sharex=True)\n",
        "    # ///////////////////////////////\n",
        "    # /////////// TODO: TRY /////////\n",
        "    # fig, axs = plt.subplots(n_charts, sharex=True, figsize(13, 20))\n",
        "    # \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
        "    ## fig.set_figwidth(13); fig.set_figheight(9)\n",
        "    fig.set_figwidth(13); fig.set_figheight(25)\n",
        "    fig.suptitle(pars['suptitle'], fontsize=14)\n",
        "    WHERE = 'post' ## pre or post\n",
        "\n",
        "    xi = 0\n",
        "    for i,ab in enumerate(abNAMES):\n",
        "      axs[xi+i].set_ylim(0, 1); axs[xi+i].spines['top'].set_visible(False); axs[xi+i].spines['right'].set_visible(True); axs[xi+i].spines['bottom'].set_visible(False)\n",
        "      axs[xi+i].step(df[f'Allocd_t_{ab}'], 'm-', where=WHERE)\n",
        "      axs[xi+i].step(0.5*df[f\"RAvail_t_{ab.split('___')[0]}\"], 'g:', where=WHERE)\n",
        "      axs[xi+i].step(0.7*df[f\"RComplete_t_{ab.split('___')[0]}\"], 'r:', where=WHERE)\n",
        "      if not df_non is None: axs[xi+i].step(df_non[f'Allocd_t_{ab}'], 'c-.', where=WHERE)\n",
        "      axs[xi+i].axhline(y=0, color='k', linestyle=':')\n",
        "      abl = ab.split(\"___\")\n",
        "      al = abl[0].split('_'); al = al[0]+'\\_'+al[1]; bl = abl[1]\n",
        "      y1ab = '$x^{Allocd}_{t,'+f'{\",\".join([al, bl])}'+'}$'\n",
        "      axs[xi+i].set_ylabel(y1ab, rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize)\n",
        "      for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi+i].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "      for j in range(df.shape[0]//T): axs[xi+i].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab\n",
        "    for i,b in enumerate(bNAMES):\n",
        "      y1ab = '$D^{Slot}_{t,'+f'{b}'+'}$'\n",
        "      axs[xi+i].set_ylim(auto=True); axs[xi+i].spines['top'].set_visible(False); axs[xi+i].spines['right'].set_visible(True); axs[xi+i].spines['bottom'].set_visible(False)\n",
        "      axs[xi+i].step(df[f'DSlot_t_{b}'], 'orange', linestyle=':', where=WHERE)\n",
        "      axs[xi+i].step(df[f'DBusy_t_{b}'], 'green', linestyle=':', where=WHERE)\n",
        "      axs[xi+i].step(df[f'DSlot_t_{b}']+df[f'DBusy_t_{b}'], 'orange', linestyle='-', where=WHERE)\n",
        "      ## if not df_non is None: axs[xi+i].step(df_non[f'DSlot_t_{b}'], 'c-.', where=WHERE)\n",
        "      ## axs[xi+i].axhline(y=DEM.muD[b], color='k', linestyle=':')\n",
        "      axs[xi+i].axhline(y=0, color='k', linestyle=':')\n",
        "      axs[xi+i].set_ylabel(y1ab, rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize)\n",
        "      for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi+i].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "      for j in range(df.shape[0]//T): axs[xi+i].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab + n_b\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df['B_t'], 'g-', where=WHERE)\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    axs[xi].axhline(y=100, color='k', linestyle=':') ## perc of 'as busy as it gets'\n",
        "    axs[xi].set_ylabel('$B_t$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "    for j in range(df.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab + n_b + 1\n",
        "    for i,a in enumerate(aNAMES):\n",
        "      axs[xi+i].set_ylim(auto=True); axs[xi+i].spines['top'].set_visible(False); axs[xi+i].spines['right'].set_visible(True); axs[xi+i].spines['bottom'].set_visible(False)\n",
        "      axs[xi+i].step(df[f'RCumSlots_t_{a}'], 'm-', where=WHERE)\n",
        "      ## axs[xi+i].step(df[f'RCumMerits_t_{a}'], 'b:', where=WHERE)\n",
        "      ## if not df_non is None: axs[xi+i].step(df_non[f'RAvail_t_{a}'], 'c-.', where=WHERE)\n",
        "      if not df_non is None: axs[xi+i].step(df_non[f'RCumSlots_t_{a}'], 'c-.', where=WHERE)\n",
        "      axs[xi+i].axhline(y=0, color='k', linestyle=':')\n",
        "      cap = df[f'cap_{a}']\n",
        "      axs[xi+i].step(df[f'cap_{a}'], 'r:', where=WHERE)\n",
        "      al = a.split('_'); al = al[0]+'\\_'+al[1]; y1ab = '$R^{CumSlots}_{t,'+f'{al}'+'}$'\n",
        "      axs[xi+i].set_ylabel(y1ab, rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize)\n",
        "      for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi+i].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "      for j in range(df.shape[0]//T): axs[xi+i].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab + n_b + 1 + n_a\n",
        "    Ucum_cols = ['Ucum_'+bn for bn in bNAMES]\n",
        "    ymax = max(list(df[Ucum_cols].max()))\n",
        "    for i,b in enumerate(bNAMES):\n",
        "      y1ab = '$U^{cum}_{'+f'{b}'+'}$'\n",
        "      axs[xi+i].set_ylim(0, ymax); axs[xi+i].spines['top'].set_visible(False); axs[xi+i].spines['right'].set_visible(True); axs[xi+i].spines['bottom'].set_visible(False)\n",
        "      axs[xi+i].step(df[f'Ucum_{b}'], 'r-', where=WHERE)\n",
        "      if not df_non is None: axs[xi+i].step(df_non[f'Ucum_{b}'], 'c-.', where=WHERE)\n",
        "      axs[xi+i].axhline(y=ymax, color='r', linestyle=':')\n",
        "      axs[xi+i].set_ylabel(y1ab, rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize)\n",
        "      for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi+i].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "      for j in range(df.shape[0]//T): axs[xi+i].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab + n_b + 1 + n_a + n_b\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df['Ucum_Total'], 'k-', where=WHERE)\n",
        "    if not df_non is None: axs[xi].step(df_non['Ucum_Total'], 'c-.', where=WHERE)\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    axs[xi].set_ylabel('$U^{cum}_{Total}$'+'\\n'+''+'$\\mathrm{[Allocs]}$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "    for j in range(df.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab + n_b + 1 + n_a + n_b + 1\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df['Ccum_CumSlots'], 'm-', where=WHERE)\n",
        "    if not df_non is None: axs[xi].step(df_non['Ccum_CumSlots'], 'c-.', where=WHERE)\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    axs[xi].set_ylabel('$C^{cum}_{CumSlots}$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "    for j in range(df.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab + n_b + 1 + n_a + n_b + 2\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df['Ccum_SickProb'], 'm-', where=WHERE)\n",
        "    if not df_non is None: axs[xi].step(df_non['Ccum_SickProb'], 'c-.', where=WHERE)\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    axs[xi].set_ylabel('$C^{cum}_{SickProb}$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "    for j in range(df.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab + n_b + 1 + n_a + n_b + 3\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df['Ccum_CumMerits'], 'm-', where=WHERE)\n",
        "    if not df_non is None: axs[xi].step(df_non['Ccum_CumMerits'], 'c-.', where=WHERE)\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    axs[xi].set_ylabel('$C^{cum}_{CumMerits}$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "    for j in range(df.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab + n_b + 1 + n_a + n_b + 4\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df['Ccum_ContSlots'], 'm-', where=WHERE)\n",
        "    if not df_non is None: axs[xi].step(df_non['Ccum_ContSlots'], 'c-.', where=WHERE)\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    axs[xi].set_ylabel('$C^{cum}_{ContSlots}$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "    for j in range(df.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_ab + n_b + 1 + n_a + n_b + 5\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df['Ccum'], 'm-', where=WHERE)\n",
        "    ## axs[xi].step(df['Ucum_Total'], 'k-', where=WHERE)\n",
        "    if not df_non is None: axs[xi].step(df_non['Ccum'], 'c-.', where=WHERE)\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    axs[xi].set_ylabel('$C^{cum}$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "    for j in range(df.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    axs[xi].set_xlabel(pars['xlabel'], rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    if(pars['legendLabels']): fig.legend(labels=pars['legendLabels'], loc='lower left', fontsize=16)\n",
        "\n",
        "  def plot_popular_times(self, df, pars=defaultdict(str)):\n",
        "    n_b = len(bNAMES)\n",
        "    n_charts = n_b + 1\n",
        "    ylabelsize = 14\n",
        "    mpl.rcParams['lines.linewidth'] = 1.2\n",
        "    mycolors = ['g', 'b']\n",
        "    fig, axs = plt.subplots(n_charts, sharex=True)\n",
        "    fig.set_figwidth(13); fig.set_figheight(9)\n",
        "    fig.suptitle(pars['suptitle'], fontsize=14)\n",
        "    WHERE = 'post' #'pre' #'post'\n",
        "\n",
        "    xi = 0\n",
        "    for i,b in enumerate(bNAMES):\n",
        "      y1ab = '$D^{Slot}_{t,'+f'{b}'+'}$'\n",
        "      axs[xi+i].set_ylim(auto=True); axs[xi+i].spines['top'].set_visible(False); axs[xi+i].spines['right'].set_visible(True); axs[xi+i].spines['bottom'].set_visible(False)\n",
        "      axs[xi+i].step(df[f'DSlot_t_{b}'], 'orange', linestyle=':', where=WHERE)\n",
        "      axs[xi+i].step(df[f'DBusy_t_{b}'], 'green', linestyle=':', where=WHERE)\n",
        "      axs[xi+i].step(df[f'DSlot_t_{b}']+df[f'DBusy_t_{b}'], 'orange', linestyle='-', where=WHERE)\n",
        "      ## axs[xi+i].axhline(y=DEM.muD[b], color='k', linestyle=':')\n",
        "      axs[xi+i].axhline(y=0, color='k', linestyle=':')\n",
        "      axs[xi+i].set_ylabel(y1ab, rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize)\n",
        "      for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi+i].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "      for j in range(df.shape[0]//T): axs[xi+i].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    xi = n_b\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df['B_t'], 'g-', where=WHERE)\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    axs[xi].axhline(y=100, color='k', linestyle=':') ## perc of 'as busy as it gets'\n",
        "    axs[xi].set_ylabel('$B_t$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    for j in range(df.shape[0]//SLOTS_PER_DAY): axs[xi].axvline(x=(j+1)*SLOTS_PER_DAY, color='grey', ls=':')\n",
        "    for j in range(df.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='black', ls='-.')\n",
        "\n",
        "    axs[xi].set_xlabel(pars['xlabel'], rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    if(pars['legendLabels']): fig.legend(labels=pars['legendLabels'], loc='lower left', fontsize=16)\n",
        "\n",
        "  def plot_evalu_comparison(self, df1, df2, df3, pars=defaultdict(str)):\n",
        "    legendlabels = ['X__BuyBelow', 'X__Bellman']\n",
        "    n_charts = 5\n",
        "    ylabelsize = 14\n",
        "    mpl.rcParams['lines.linewidth'] = 1.2\n",
        "    fig, axs = plt.subplots(n_charts, sharex=True)\n",
        "    fig.set_figwidth(13); fig.set_figheight(9)\n",
        "    thetaStarStr = []\n",
        "    for cmp in pars[\"thetaStar\"]: thetaStarStr.append(f'{cmp:.1f}')\n",
        "    thetaStarStr = '(' + ', '.join(thetaStarStr) + ')'\n",
        "    fig.suptitle(pars['suptitle'], fontsize=14)\n",
        "\n",
        "    xi = 0\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df1[f'x_t'], 'r-', where='post')\n",
        "    axs[xi].step(df2[f'x_t'], 'g-.', where='post')\n",
        "    axs[xi].step(df3[f'x_t'], 'b:', where='post')\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    y1ab = '$x_{t}$'\n",
        "    axs[xi].set_ylabel(y1ab, rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize)\n",
        "    for j in range(df1.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='grey', ls=':')\n",
        "\n",
        "    xi = 1\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df1[f'R_t'], 'r-', where='post')\n",
        "    axs[xi].step(df2[f'R_t'], 'g-.', where='post')\n",
        "    axs[xi].step(df3[f'R_t'], 'b:', where='post')\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    y1ab = '$R_{t}$'\n",
        "    axs[xi].set_ylabel(y1ab, rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize)\n",
        "    for j in range(df1.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='grey', ls=':')\n",
        "\n",
        "    xi = 2\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df1[f'p_t'], 'r-', where='post')\n",
        "    axs[xi].step(df2[f'p_t'], 'g-.', where='post')\n",
        "    axs[xi].step(df3[f'p_t'], 'b:', where='post')\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "\n",
        "    if(pars['lower_non']): axs[xi].text(-4, pars['lower_non'], r'$\\theta^{lower}$' + f\"={pars['lower_non']:.1f}\", size=10, color='c')\n",
        "    if(pars['lower_non']): axs[xi].axhline(y=pars['lower_non'], color='c', linestyle=':')\n",
        "\n",
        "    if(pars['upper_non']): axs[xi].text(-4, pars['upper_non'], r'$\\theta^{upper}$' + f\"={pars['upper_non']:.1f}\", size=10, color='c')\n",
        "    if(pars['upper_non']): axs[xi].axhline(y=pars['upper_non'], color='c', linestyle=':')\n",
        "\n",
        "    if(pars['lower']): axs[xi].text(-4, pars['lower'], r'$\\theta^{lower}$' + f\"={pars['lower']:.1f}\", size=10, color='m')\n",
        "    if(pars['lower']): axs[xi].axhline(y=pars['lower'], color='m', linestyle=':')\n",
        "\n",
        "    if(pars['upper']): axs[xi].text(-4, pars['upper'], r'$\\theta^{upper}$' + f\"={pars['upper']:.1f}\", size=10, color='m')\n",
        "    if(pars['upper']): axs[xi].axhline(y=pars['upper'], color='m', linestyle=':')\n",
        "\n",
        "    if(pars['alpha_non']): axs[xi].text(-4, pars['alpha_non'], r'$\\theta^{alpha}$' + f\"={pars['alpha_non']:.1f}\", size=10, color='c')\n",
        "    if(pars['alpha_non']): axs[xi].axhline(y=pars['alpha_non'], color='c', linestyle=':')\n",
        "\n",
        "    if(pars['trackSignal_non']): axs[xi].text(-4, pars['trackSignal_non'], r'$\\theta^{trackSignal}$' + f\"={pars['trackSignal_non']:.1f}\", size=10, color='c')\n",
        "    if(pars['trackSignal_non']): axs[xi].axhline(y=pars['trackSignal_non'], color='c', linestyle=':')\n",
        "\n",
        "    if(pars['alpha']): axs[xi].text(-4, pars['alpha'], r'$\\theta^{alpha}$' + f\"={pars['alpha']:.1f}\", size=10, color='m')\n",
        "    if(pars['alpha']): axs[xi].axhline(y=pars['alpha'], color='m', linestyle=':')\n",
        "\n",
        "    if(pars['trackSignal']): axs[xi].text(-4, pars['trackSignal'], r'$\\theta^{trackSignal}$' + f\"={pars['trackSignal']:.1f}\", size=10, color='m')\n",
        "    if(pars['trackSignal']): axs[xi].axhline(y=pars['trackSignal'], color='m', linestyle=':')\n",
        "\n",
        "    y1ab = '$p_{t}$'\n",
        "    axs[xi].set_ylabel(y1ab, rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize)\n",
        "    for j in range(df1.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='grey', ls=':')\n",
        "\n",
        "    xi = 3\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df1['b_t_val'], 'r-', where='post')\n",
        "    axs[xi].step(df2['b_t_val'], 'g-.', where='post')\n",
        "    axs[xi].step(df3['b_t_val'], 'b:', where='post')\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    y1ab = '$b_{t,val}$'\n",
        "    axs[xi].set_ylabel(y1ab, rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize)\n",
        "    for j in range(df1.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='grey', ls=':')\n",
        "\n",
        "    xi = 4\n",
        "    axs[xi].set_ylim(auto=True); axs[xi].spines['top'].set_visible(False); axs[xi].spines['right'].set_visible(True); axs[xi].spines['bottom'].set_visible(False)\n",
        "    axs[xi].step(df1['Ccum'], 'r-', where='post')\n",
        "    axs[xi].step(df2['Ccum'], 'g-.', where='post')\n",
        "    axs[xi].step(df3['Ccum'], 'b:', where='post')\n",
        "    axs[xi].axhline(y=0, color='k', linestyle=':')\n",
        "    axs[xi].set_ylabel('$\\mathrm{cumC}$'+'\\n'+'$\\mathrm{(Profit)}$'+'\\n'+''+'$\\mathrm{[\\$]}$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    axs[xi].set_xlabel('$t\\ \\mathrm{[decision\\ windows]}$', rotation=0, ha='right', va='center', fontweight='bold', size=ylabelsize);\n",
        "    for j in range(df1.shape[0]//T): axs[xi].axvline(x=(j+1)*T, color='grey', ls=':')\n",
        "\n",
        "    fig.legend(\n",
        "      ## [leg],\n",
        "      labels=legendlabels,\n",
        "      title=\"Policies\",\n",
        "      loc='upper right',\n",
        "      fontsize=16,\n",
        "      fancybox=True,\n",
        "      shadow=True,\n",
        "      ncol=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMEUIRUj-6X-"
      },
      "source": [
        "### 4.6 Policy Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRWeulcOj3hH"
      },
      "source": [
        "#### 4.6.1 Training/Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4nbDucdegyLf"
      },
      "outputs": [],
      "source": [
        "## setup labels to plot info\n",
        "def setup_plot_labels():\n",
        "    RAvail_t_labels = ['RAvail_t_'+an for an in aNAMES]\n",
        "    RCumSlots_t_labels = ['RCumSlots_t_'+an for an in aNAMES]\n",
        "    RCumMerits_t_labels = ['RCumMerits_t_'+an for an in aNAMES]\n",
        "    ## RContSlots_t_labels = ['RContSlots_t_'+an for an in aNAMES]\n",
        "    RComplete_t_labels = ['RComplete_t_'+an for an in aNAMES]\n",
        "    DSlot_t_labels = ['DSlot_t_'+rt for rt in RESOURCE_TYPES]\n",
        "    DBusy_t_labels = ['DBusy_t_'+rt for rt in RESOURCE_TYPES]\n",
        "    B_t_label = ['B_t']\n",
        "    xAlloc_t_labels = ['Allocd_t_'+abn for abn in abNAMES]\n",
        "    labels = ['piName', 'theta', 'l'] + \\\n",
        "      ['t', 'dt'] + \\\n",
        "      RAvail_t_labels + RCumSlots_t_labels + RCumMerits_t_labels + RComplete_t_labels + \\\n",
        "      DSlot_t_labels + \\\n",
        "      DBusy_t_labels + \\\n",
        "      B_t_label + \\\n",
        "      ['Ucum_'+rt for rt in RESOURCE_TYPES] + \\\n",
        "      ['Ucum_Total'] + \\\n",
        "      ['Ccum_CumSlots'] + \\\n",
        "      ['Ccum_SickProb'] + \\\n",
        "      ['Ccum_CumMerits'] + \\\n",
        "      ['Ccum_ContSlots'] + \\\n",
        "      ['Ccum'] + \\\n",
        "      xAlloc_t_labels\n",
        "    return labels\n",
        "Labels = setup_plot_labels()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "z6dP-tNJUOgj"
      },
      "outputs": [],
      "source": [
        "# # hide\n",
        "# # QUICK STEP\n",
        "# def print_S_t():\n",
        "#   print(f'M.S_t[\"R_t\"]=\\n{M.S_t[\"R_t\"]}')\n",
        "#   print(f'M.S_t[\"D_t\"]=\\n{M.S_t[\"D_t\"]}')\n",
        "\n",
        "# def print_x_t():\n",
        "#   # print(f'x_t.x_t= {x_t.x_t}')\n",
        "#   print(f'M.x_t[\"xAlloc_t\"]=\\n{M.x_t[\"xAlloc_t\"]}')\n",
        "\n",
        "# record = []\n",
        "# l = 1\n",
        "# M = Model()\n",
        "# P = Policy(M)\n",
        "# ## DEM = DemandSimulator(seed=SEED_TRAIN); print(f'{DEM.simulate()=}')\n",
        "# ## MER = MeritSimulator(seed=SEED_TRAIN); print(f'{MER.simulate()=}')\n",
        "\n",
        "# theta_test = P.build_theta({\n",
        "#   'thCumSlots': .1,\n",
        "#   'thSickProb': .3,\n",
        "#   'thCumMerits': .2,\n",
        "#   'thContSlots': 1 - (.6),\n",
        "#   'thSelect': 'random'\n",
        "# })\n",
        "# record_l = [piNAMES[0], theta_test, l]; print(f'{record_l=}')\n",
        "# print_S_t()\n",
        "# print_x_t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BEDQzj0grQdL"
      },
      "outputs": [],
      "source": [
        "# # hide\n",
        "# # T = 7*24\n",
        "# # T = 2*24\n",
        "# T = 3\n",
        "# # T = 1*SLOTS_PER_DAY\n",
        "# # T = 2*SLOTS_PER_DAY\n",
        "# dt = pd.to_datetime(START_DATE_TIME)\n",
        "# dt_delta = pd.Timedelta(DATE_TIME_DELTA)\n",
        "# for t in range(T):\n",
        "#   print(f'\\n################# t={t}, dt={dt} #################')\n",
        "#   # getattr(P, 'X__AllocBelow')(t, M.S_t, M.x_t, theta_test); #print(f'{x_t=}')\n",
        "#   getattr(P, 'X__Alloc')(t, dt, M.S_t, M.x_t, theta_test); #print(f'{x_t=}')\n",
        "#   print_S_t()\n",
        "#   print_x_t()\n",
        "\n",
        "#   # record_t = M.step(t, theta_test)\n",
        "#   record_t = M.step(t, dt, theta_test)\n",
        "#   print(f'\\nAFTER STEP:')\n",
        "#   record.append(record_l + record_t); #print(f'{record=}')\n",
        "#   dt = dt + dt_delta\n",
        "#   # print_S_t()\n",
        "#   # print(f'{M.Ccum=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "c_g4t9cerQUA"
      },
      "outputs": [],
      "source": [
        "# ## hide\n",
        "# df_test_n_t = pd.DataFrame.from_records(record, columns=Labels)\n",
        "# df_test_n_t.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "42PGK1DZepfC"
      },
      "outputs": [],
      "source": [
        "# ## hide\n",
        "# P.plot_records(\n",
        "#   df=df_test_n_t,\n",
        "#   df_non=None,\n",
        "#   pars=defaultdict(str, {\n",
        "#     # 'thetaAdj1': {a1n: theta_test.thAdj1[a1n] for a1n in a1NAMES},\n",
        "#     # 'thetaAdj3': {a1n: theta_test.thAdj3[a1n] for a1n in a1NAMES},\n",
        "#     # 'suptitle': f'TRAINING OF X__AdjBelow POLICY'+'\\n'+f'(first {first_n_t} records)'+'\\n'+ \\\n",
        "#     # f'L = {L}, T = {T}, '+ \\\n",
        "#     # r'$\\theta^*=$'+f'{P.round_theta(best_theta_AdjBelow)}',\n",
        "#   }),\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rWKpWY2M_AOJ"
      },
      "outputs": [],
      "source": [
        "## def grid_search_thetas(thetas1, thetas2, thetas1_name, thetas2_name):\n",
        "#   thetas = [\n",
        "#     P.build_theta({thetas1_name: thA0, thetas2_name: thB0})\n",
        "#     for thA0 in thetas1\n",
        "#       for thB0 in thetas2\n",
        "#   ]\n",
        "#   return thetas\n",
        "\n",
        "## def grid_search_thetas(thetas1, thetas1_name):\n",
        "#   thetas = [\n",
        "#     P.build_theta({thetas1_name: thA0})\n",
        "#     for thA0 in thetas1\n",
        "#   ]\n",
        "#   return thetas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# /// OVERRIDES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "bp9_cGh56gjY"
      },
      "outputs": [],
      "source": [
        "## OVERRIDES\n",
        "# MODES = ['LEARN']\n",
        "# MODES = ['TRAIN']\n",
        "# MODES = ['TRAIN', 'EVALU']\n",
        "# MODES = ['TRAIN', 'EVALU', 'APPLY']\n",
        "# MODES = ['EVALU', 'APPLY']\n",
        "# MODES = ['APPLY']\n",
        "# MODES = ['LEARN', 'APPLY']\n",
        "\n",
        "# BEST_THETA_Alloc = (0, 0, 0, 1, 'random') #will be written/read eventually\n",
        "\n",
        "# RESOLUTION = 'HOUR' ## 'BLOCK_8_HOUR', 'HOUR', 'QUARTER_HOUR', \n",
        "# if RESOLUTION == 'QUARTER_HOUR':\n",
        "#   SLOTS_PER_DAY = 96\n",
        "#   DATE_TIME_DELTA = '15min'\n",
        "# elif RESOLUTION == 'HOUR':\n",
        "#   SLOTS_PER_DAY = 24\n",
        "#   DATE_TIME_DELTA = '1H'\n",
        "# elif RESOLUTION == 'BLOCK_8_HOUR':\n",
        "#   SLOTS_PER_DAY = 3\n",
        "#   DATE_TIME_DELTA = '8H'\n",
        "# else:\n",
        "#   print(f'ERROR: Invalid RESOLUTION: {RESOLUTION}')\n",
        "\n",
        "# BLOCK_START_HOUR = 22\n",
        "# BLOCK_START_HOUR = {0: 8, 1: 16, 2:0}\n",
        "# BLOCK_START_HOUR = {0: 0, 1: 8, 2:16}\n",
        "\n",
        "# TH_CumSlots_SPEC = (0, 1, .5)\n",
        "# TH_CumSlots_SPEC = (0, 1, .2)\n",
        "# TH_CumSlots_SPEC = (0, 1, .1)\n",
        "# TH_CumSlots_SPEC = (0,)\n",
        "\n",
        "# TH_SickProb_SPEC = (0, 1, .5)\n",
        "# TH_SickProb_SPEC = (0, 1, .2)\n",
        "# TH_SickProb_SPEC = (0, 1, .1)\n",
        "# TH_SickProb_SPEC = (0,) #|||\n",
        "\n",
        "# TH_CumMerits_SPEC = (0, 1, .5)\n",
        "# TH_CumMerits_SPEC = (0, 1, .2)\n",
        "# TH_CumMerits_SPEC = (0, 1, .1)\n",
        "# TH_CumMerits_SPEC = (0,)\n",
        "\n",
        "## BALANCE/REMAINING \n",
        "# TH_ContSlots_SPEC = (0, 1, .5)\n",
        "# TH_ContSlots_SPEC = (0, 1, .2)\n",
        "# TH_ContSlots_SPEC = (0, 1, .1)\n",
        "# TH_ContSlots_SPEC = (0,)\n",
        "\n",
        "# TH_Select_SPEC = ('ranked_CumMerits',)\n",
        "# TH_Select_SPEC = ('random',)\n",
        "# TH_Select_SPEC = ('random', 'ranked_CumMerits')\n",
        "\n",
        "# START_DATE_TIME = '2023-10-30'\n",
        "# START_DATE_TIME = '2023-10-30T22:00'\n",
        "# sd = pd.to_datetime(START_DATE_TIME)\n",
        "# assert sd.strftime('%a')=='Mon'\n",
        "\n",
        "# MAX_DAILY_SHIFT_LENGTH = 8*4 ## 32 quarters or 8 hours\n",
        "# MAX_DAILY_SLOT_RUN = 8 #1 #8 #32\n",
        "# assert MAX_DAILY_SLOT_RUN<=SLOTS_PER_DAY #|||\n",
        "\n",
        "# CONTIGUOUS_REWARD = 100\n",
        "# CONTIGUOUS_REWARD = 10\n",
        "# CONTIGUOUS_REWARD = 1\n",
        "\n",
        "# BUSYNESS_RATE = { #demand/busyness\n",
        "#   'Manager': .5,\n",
        "#   'AssistMngr': .8,\n",
        "#   'RetailAssoc': 5\n",
        "# }\n",
        "## demand/busyness ## <<< ========= INPUT ==============\n",
        "## add demands of 0 up to these values as busyness varies from 0 to 100%\n",
        "# BUSYNESS_RATES = [1.1, 1.6, 10.2]\n",
        "# BUSYNESS_RATES = [.5, .8, 5]\n",
        "# BUSYNESS_RATES = [.2, .4, 2]\n",
        "# BUSYNESS_RATE = {e: BUSYNESS_RATES[i] for i,e in enumerate(RESOURCE_TYPES)}\n",
        "# assert len(BUSYNESS_RATES) == len(RESOURCE_TYPES)\n",
        "\n",
        "# REVENUE_PER_BUSYNESS = 2000 ##dollars ## <<< ========= INPUT ==============\n",
        "# REVENUE_PER_BUSYNESS = 1000 ##dollars ## <<< ========= INPUT ==============\n",
        "# REVENUE_PER_BUSYNESS = 100 ##dollars ## <<< ========= INPUT ==============\n",
        "## REVENUE_PER_VOLUME = 100 ##dollars ## <<< ========= INPUT =============="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UoCxzziox-5i"
      },
      "outputs": [],
      "source": [
        "def do_train():\n",
        "  global DEM, MER, Df_first_n_t, Df_last_n_t, ThetasCumSlots, \\\n",
        "  ThetasSickProb, ThetasCumMerits, ThetasContSlots, ThetasSelect, \\\n",
        "  ThetaStar_expCbarcum_Alloc, ThetaStar_expCtilcum_Alloc, \\\n",
        "  Cbarcum_Alloc, Ctilcum_Alloc, Best_theta_Alloc, Worst_theta_Alloc, \\\n",
        "  Best_Cbarcum_Alloc, Worst_Cbarcum_Alloc, \\\n",
        "  Best_Ctilcum_Alloc, Worst_Ctilcum_Alloc, \\\n",
        "  Record_Alloc, First_n_t, Last_n_t, \\\n",
        "  Thetas # Thetas #for parallelization\n",
        "\n",
        "  M = Model()\n",
        "  P = Policy(M)\n",
        "  ## DEM = DemandSimulator(seed=SEED_TRAIN)\n",
        "  ## MER = MeritSimulator(seed=SEED_TRAIN)\n",
        "\n",
        "  ThetasCumSlots = np.arange(TH_CumSlots_SPEC[0], TH_CumSlots_SPEC[1], TH_CumSlots_SPEC[2])\n",
        "  ## ThetasCumSlots = TH_CumSlots_SPEC\n",
        "\n",
        "  ## ThetasSickProb = np.arange(TH_SickProb_SPEC[0], TH_SickProb_SPEC[1], TH_SickProb_SPEC[2])\n",
        "  ThetasSickProb = TH_SickProb_SPEC\n",
        "\n",
        "  ThetasCumMerits = np.arange(TH_CumMerits_SPEC[0], TH_CumMerits_SPEC[1], TH_CumMerits_SPEC[2])\n",
        "  ## ThetasCumMerits = TH_CumMerits_SPEC\n",
        "\n",
        "  ## BALANCE/REMAINING \n",
        "  ## ThetasContSlots = np.arange(TH_ContSlots_SPEC[0], TH_ContSlots_SPEC[1], TH_ContSlots_SPEC[2])\n",
        "  ## ThetasContSlots = TH_ContSlots_SPEC\n",
        "\n",
        "  ThetasSelect = TH_Select_SPEC\n",
        "\n",
        "  thetas_list = [\n",
        "    ( round(th0,2), round(th1,2), round(th2,2), round(1-(th0+th1+th2),2), th4 )\n",
        "    for th0 in ThetasCumSlots\n",
        "      for th1 in ThetasSickProb\n",
        "        for th2 in ThetasCumMerits if (th0 + th1 + th2) <= 1.0\n",
        "          for th4 in ThetasSelect\n",
        "  ]\n",
        "  Thetas = [\n",
        "    ## P.build_theta({'thCumSlots': tup[0], 'thSickProb': tup[1], 'thCumMerits': tup[2], 'thSelect': tup[3]})\n",
        "    P.build_theta({\n",
        "      'thCumSlots': tup[0], \n",
        "      'thSickProb': tup[1], \n",
        "      'thCumMerits': tup[2], \n",
        "      'thContSlots': tup[3], \n",
        "      'thSelect': tup[4]\n",
        "      })\n",
        "    for tup in thetas_list\n",
        "  ]\n",
        "  ThetaStar_expCbarcum_Alloc, ThetaStar_expCtilcum_Alloc, \\\n",
        "  Cbarcum_Alloc, Ctilcum_Alloc, \\\n",
        "  Best_theta_Alloc, Worst_theta_Alloc, \\\n",
        "  Best_Cbarcum_Alloc, Worst_Cbarcum_Alloc, \\\n",
        "  Best_Ctilcum_Alloc, Worst_Ctilcum_Alloc, \\\n",
        "  Record_Alloc = \\\n",
        "    P.parallel_perform_grid_search_sample_paths('X__Alloc', Thetas)\n",
        "  f'{ThetaStar_expCbarcum_Alloc.iloc[-1]=:.2f}'\n",
        "  Df_first_n_t = pd.DataFrame.from_records(Record_Alloc[:First_n_t], columns=Labels)\n",
        "  Df_last_n_t = pd.DataFrame.from_records(Record_Alloc[-Last_n_t:], columns=Labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3 s, sys: 0 ns, total: 3 s\n",
            "Wall time: 6.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if 'LEARN' in MODES:\n",
        "  ray.shutdown()\n",
        "  ray.init()\n",
        "\n",
        "  L = 5 #2 #20 #10 #5 #2 #3 #2db #10pub\n",
        "  T = 7*SLOTS_PER_DAY #5 #7*96\n",
        "  First_n_t = int(1.2*T)\n",
        "  Last_n_t = int(1*T) ##make whole multiple of T to look better in chart\n",
        "  do_train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcsSZ-hHfNHU",
        "outputId": "a7620efd-1004-4903-ec23-4ba1f75163cd"
      },
      "outputs": [],
      "source": [
        "# Theta(thCumSlots=0.8, thSickProb=0.0, thCumMerits=0.0, thContSlots=0.2, thSelect='random')\n",
        "# Theta(thCumSlots=0.8, thSickProb=0.0, thCumMerits=0.0, thContSlots=0.2, thSelect='random')\n",
        "# Theta(thCumSlots=0.8, thSickProb=0.0, thCumMerits=0.2, thContSlots=0.0, thSelect='random')\n",
        "# Theta(thCumSlots=0.9, thSickProb=0.0, thCumMerits=0.1, thContSlots=0.0, thSelect='random')\n",
        "# Theta(thCumSlots=0.9, thSickProb=0, thCumMerits=0.1, thContSlots=0.0, thSelect='random')\n",
        "# Theta(thCumSlots=0.5, thSickProb=0.0, thCumMerits=0.5, thContSlots=0.0, thSelect='ranked_CumMerits')\n",
        "# Theta(thCumSlots=0.2, thSickProb=0, thCumMerits=0.8, thContSlots=0.0, thSelect='random')\n",
        "# Theta(thCumSlots=0.4, thSickProb=0, thCumMerits=0.6, thContSlots=0.0, thSelect='random')\n",
        "if 'LEARN' in MODES: print(Best_theta_Alloc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "p_GUAP8S2GNs",
        "outputId": "039dd92a-b487-408f-efa5-047efd8ae438"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  ## P.plot_Fhat_map_5(\n",
        "  Policy(None).plot_Fhat_map_4(\n",
        "    FhatI_theta_I=Cbarcum_Alloc,\n",
        "\n",
        "    ## thetasX=thetasCumSlots,\n",
        "    thetasX=ThetasSickProb,\n",
        "    thetasY=ThetasCumMerits,\n",
        "\n",
        "    ## labelX=r'$\\theta^{CumSlots}$',\n",
        "    labelX=r'$\\theta^{SickProb}$',\n",
        "    labelY=r'$\\theta^{CumMerits}$',\n",
        "\n",
        "    title=\"Sample mean of the cumulative reward\"+f\"\\n $L={L}, T={T}$, \"+ \\\n",
        "      r\"$\\theta^* =$(\"+ \\\n",
        "        str(f'{Best_theta_Alloc[0]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[1]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[2]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[3]:,.2f}')+\", \"+ \\\n",
        "        f'{Best_theta_Alloc[4]}'+\"), \" \\\n",
        "      r\"$\\bar{C}^{cum}(\\theta^*) =$\"+f\"{Best_Cbarcum_Alloc:,.0f}\\n\",\n",
        "    ## thetaFixed1=best_theta_Alloc.thCumMerits,\n",
        "    ## thetaFixed1=best_theta_Alloc.thSickProb,\n",
        "    ## thetaFixed1=best_theta_Alloc.thCumSlots,\n",
        "    thetaFixed1=Best_theta_Alloc.thContSlots,\n",
        "    thetaFixed2=Best_theta_Alloc.thSelect,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "Rf1veB9IF7Ha",
        "outputId": "dfad20df-c40c-4afa-99e3-e2dc5e8d069a"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  Policy(None).plot_expFhat_chart(\n",
        "    df=ThetaStar_expCbarcum_Alloc,\n",
        "    labelX=r'$\\ell$',\n",
        "    labelY=r\"$exp\\bar{C}^{cum}(\\theta^*)$\"+\"\\n(Profit)\\n[$]\",\n",
        "    title=\"Expanding sample mean of the cumulative reward\"+f\"\\n $L={L}, T={T}$, \"+ \\\n",
        "      r\"$\\theta^* =$(\"+ \\\n",
        "        str(f'{Best_theta_Alloc[0]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[1]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[2]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[3]:,.2f}')+\", \"+\n",
        "        f'{Best_theta_Alloc[4]}'+\"), \" \\\n",
        "      r\"$\\bar{C}^{cum}(\\theta^*) =$\"+f\"{Best_Cbarcum_Alloc:,.0f}\\n\",\n",
        "    color_style='b-'\n",
        "  )\n",
        "  print()\n",
        "  Policy(None).plot_expFhat_chart(\n",
        "    df=ThetaStar_expCtilcum_Alloc,\n",
        "    labelX=r'$\\ell$',\n",
        "    labelY=r\"$exp\\bar{C}^{cum}(\\theta^*)$\"+\"\\n(Profit)\\n[$]\",\n",
        "    title=\"Expanding standard error of the cumulative reward\"+f\"\\n $L={L}, T={T}$, \"+ \\\n",
        "      r\"$\\theta^* =$(\"+ \\\n",
        "        str(f'{Best_theta_Alloc[0]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[1]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[2]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[3]:,.2f}')+\", \"+\n",
        "        f'{Best_theta_Alloc[4]}'+\"), \" \\\n",
        "      r\"$\\tilde{C}^{cum}(\\theta^*) =$\"+f\"{Best_Ctilcum_Alloc:,.0f}\\n\",\n",
        "    color_style='b--'\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR2UXVd6n0Ar",
        "outputId": "e291d67e-01ac-453d-c31b-5b6bca6a2517"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES: print(f'{len(Record_Alloc):,}', L, T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMTgL7MvkEWY",
        "outputId": "cc45fdb2-0637-4bce-c3a9-c624fc62467e"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES: print(Best_theta_Alloc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  Policy(None).plot_records(\n",
        "  # plot_records(  \n",
        "    df=Df_first_n_t,\n",
        "    df_non=None,\n",
        "    pars=defaultdict(str, {\n",
        "      'xlabel': \"$t\\ \\mathrm{[\"+f\"{DATE_TIME_DELTA}\"+\"\\ decision\\ windows]}$\",\n",
        "      'thCumSlots': Best_theta_Alloc.thCumSlots,\n",
        "      'thSickProb': Best_theta_Alloc.thSickProb,\n",
        "      ## 'legendLabels': [r'$\\mathrm{opt}$', r'$\\mathrm{non}$'],\n",
        "      'suptitle': f'TRAINING OF X__Alloc POLICY'+'\\n'+f'(first {First_n_t} records)'+'\\n'+ \\\n",
        "      f'L = {L}, T = {T}, '+ \\\n",
        "      r\"$\\theta^* =$(\"+ \\\n",
        "        str(f'{Best_theta_Alloc[0]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[1]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[2]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[3]:,.2f}')+\", \"+\n",
        "        f'{Best_theta_Alloc[4]}'+\"), \" \\\n",
        "    }),\n",
        "  );"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  Policy(None).plot_popular_times(\n",
        "  # plot_popular_times(\n",
        "    df=Df_first_n_t,\n",
        "    pars=defaultdict(str, {\n",
        "      'xlabel': \"$t\\ \\mathrm{[\"+f\"{DATE_TIME_DELTA}\"+\"\\ decision\\ windows]}$\",\n",
        "      'suptitle': f'Demand functions'+'\\n'+f'(first {First_n_t} records)'+'\\n'+ \\\n",
        "      f'L = {L}, T = {T}, '+ \\\n",
        "      r\"$\\theta^* =$(\"+ \\\n",
        "        str(f'{Best_theta_Alloc[0]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[1]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[2]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[3]:,.2f}')+\", \"+\n",
        "        f'{Best_theta_Alloc[4]}'+\"), \" \\\n",
        "    }),\n",
        "  );"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES: print(T,SLOTS_PER_DAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  Policy(None).plot_records(\n",
        "  # plot_records(    \n",
        "    df=Df_last_n_t,\n",
        "    df_non=None,\n",
        "    pars=defaultdict(str, {\n",
        "      'thCumSlots': Best_theta_Alloc.thCumSlots,\n",
        "      'thSickProb': Best_theta_Alloc.thSickProb,\n",
        "      ## 'legendLabels': [r'$\\mathrm{opt}$', r'$\\mathrm{non}$'],\n",
        "      'xlabel': \"$t\\ \\mathrm{[\"+f\"{DATE_TIME_DELTA}\"+\"\\ decision\\ windows]}$\",\n",
        "      'suptitle': f'TRAINING OF X__Alloc POLICY'+'\\n'+f'(last {Last_n_t} records)'+'\\n'+ \\\n",
        "      f'L = {L}, T = {T}, '+ \\\n",
        "      r\"$\\theta^* =$(\"+ \\\n",
        "        str(f'{Best_theta_Alloc[0]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[1]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[2]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc[3]:,.2f}')+\", \"+\n",
        "        f'{Best_theta_Alloc[4]}'+\"), \" \\\n",
        "    }),\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7yUBAo9mewq"
      },
      "source": [
        "#### 4.6.1.2 Comparison of Policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "pU4g9WO6mry7"
      },
      "outputs": [],
      "source": [
        "## hide\n",
        "## last_n_l = int(.95*L)\n",
        "## P.plot_expFhat_charts(\n",
        "#   means={\n",
        "#       'HighLow': thetaStar_expCbarcum_HighLow[-last_n_l:],\n",
        "#       'SellLow': thetaStar_expCbarcum_SellLow[-last_n_l:],\n",
        "#       'Track': thetaStar_expCbarcum_Track[-last_n_l:]\n",
        "#   },\n",
        "#   stdvs={\n",
        "#       'HighLow': thetaStar_expCtilcum_HighLow[-last_n_l:],\n",
        "#       'SellLow': thetaStar_expCtilcum_SellLow[-last_n_l:],\n",
        "#       'Track': thetaStar_expCtilcum_Track[-last_n_l:]\n",
        "#   },\n",
        "#   labelX='Sample paths, ' + r'$\\ell$',\n",
        "#   labelY='Profit\\n[$]',\n",
        "#   suptitle=f\"Comparison of Policies after Training\\n \\\n",
        "#     L = {L}, T = {T}\\n \\\n",
        "#     last {last_n_l} records\\n \\\n",
        "#     ('exp' refers to expanding)\",\n",
        "#   pars=defaultdict(str, {\n",
        "#     'colors': ['r', 'g', 'b']\n",
        "#   }),\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-DpKcyhQToP"
      },
      "source": [
        "#### 4.6.2 Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKyBjitn80B_"
      },
      "source": [
        "##### 4.6.2.1 X__AllocBelow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H_vmbJYZVc6",
        "outputId": "61912895-98e3-4230-f014-411174dc4380"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES: print(Best_theta_Alloc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2g41h9Vr77_",
        "outputId": "5ed53b03-dbc1-4fa5-811a-029bf53942b9"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES: print(Worst_theta_Alloc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "FePkejTt9DbK"
      },
      "outputs": [],
      "source": [
        "def do_evalu():\n",
        "  global DEM, MER, \\\n",
        "  ThetaStar_expCbarcum_Alloc_evalu_opt, ThetaStar_expCtilcum_Alloc_evalu_opt, \\\n",
        "  Best_theta_Alloc_evalu_opt, Worst_theta_Alloc_evalu_opt, \\\n",
        "  Record_Alloc_evalu_opt, Df_Alloc_evalu_opt, \\\n",
        "  ThetaStar_expCbarcum_Alloc_evalu_non, ThetaStar_expCtilcum_Alloc_evalu_non, \\\n",
        "  Best_theta_Alloc_evalu_non, Worst_theta_Alloc_evalu_non, \\\n",
        "  Record_Alloc_evalu_non, Df_Alloc_evalu_non\n",
        "\n",
        "  M = Model()\n",
        "  P = Policy(M)\n",
        "  ## DEM = DemandSimulator(seed=SEED_EVALU)\n",
        "  ## MER = MeritSimulator(seed=SEED_EVALU)\n",
        "  thetasOpt = []; thetasOpt.append(Best_theta_Alloc)\n",
        "  ThetaStar_expCbarcum_Alloc_evalu_opt, ThetaStar_expCtilcum_Alloc_evalu_opt, \\\n",
        "  _, _, \\\n",
        "  Best_theta_Alloc_evalu_opt, Worst_theta_Alloc_evalu_opt, \\\n",
        "  _, _, \\\n",
        "  _, _, \\\n",
        "  Record_Alloc_evalu_opt = \\\n",
        "    P.perform_grid_search_sample_paths('X__Alloc', thetasOpt)\n",
        "  Df_Alloc_evalu_opt = pd.DataFrame.from_records(\n",
        "      Record_Alloc_evalu_opt[:First_n_t], columns=Labels)\n",
        "\n",
        "  M = Model()\n",
        "  P = Policy(M)\n",
        "  ## DEM = DemandSimulator(seed=SEED_EVALU)\n",
        "  ## MER = MeritSimulator(seed=SEED_EVALU)\n",
        "  thetasNon = []; thetasNon.append(Worst_theta_Alloc)\n",
        "  ## thetasNon = []; thetasNon.append(\n",
        "  ##   P.build_theta(\n",
        "  ##     {'thCumShifts': 1.0, 'thSickProb': 1.0}\n",
        "  ##   )\n",
        "  ## )\n",
        "  ThetaStar_expCbarcum_Alloc_evalu_non, ThetaStar_expCtilcum_Alloc_evalu_non, \\\n",
        "  _, _, \\\n",
        "  Best_theta_Alloc_evalu_non, Worst_theta_Alloc_evalu_non, \\\n",
        "  _, _, \\\n",
        "  _, _, \\\n",
        "  Record_Alloc_evalu_non = \\\n",
        "    P.perform_grid_search_sample_paths('X__Alloc', thetasNon)\n",
        "  Df_Alloc_evalu_non = pd.DataFrame.from_records(\n",
        "      Record_Alloc_evalu_non[:First_n_t], columns=Labels)\n",
        "\n",
        "  print(\n",
        "    f'{ThetaStar_expCbarcum_Alloc_evalu_opt.iloc[-1]=:.2f}, \\\n",
        "      {ThetaStar_expCbarcum_Alloc_evalu_non.iloc[-1]=:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxtDFe7TKoU5",
        "outputId": "e876043b-e23d-4269-fe37-3c14b4fe448a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2 s, sys: 0 ns, total: 2 s\n",
            "Wall time: 4.77 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "## Wall time: 3min 13s [colab]\n",
        "## Wall time: 2min 1s [mac mini]\n",
        "## It is the thetas that are done in parallel, so no parallel speedup here (actually a bit longer\n",
        "## due to the ray shutdown and init).\n",
        "## There is a SINGLE theta for each of the 2 cases.\n",
        "## During training, where there are multiple thetas, there will be a speedup.\n",
        "if 'LEARN' in MODES:\n",
        "  L = 2 #20 #5 #2 #2db #10pub #!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  T = 7*SLOTS_PER_DAY #=672\n",
        "  First_n_t = int(.11*L*T)\n",
        "  do_evalu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  Policy(None).plot_records(\n",
        "  # plot_records(\n",
        "    df=Df_Alloc_evalu_opt,\n",
        "    df_non=Df_Alloc_evalu_non,\n",
        "    pars=defaultdict(str, {\n",
        "      'thCumSlots': Best_theta_Alloc_evalu_opt.thCumSlots,\n",
        "      'thSickProb': Best_theta_Alloc_evalu_opt.thSickProb,\n",
        "      'thCumSlotsNon': Best_theta_Alloc_evalu_non.thCumSlots,\n",
        "      'thSickProbNon': Best_theta_Alloc_evalu_non.thSickProb,\n",
        "      'legendLabels': [r'$\\mathrm{opt}$', r'$\\mathrm{non}$'],\n",
        "      'xlabel': \"$t\\ \\mathrm{[\"+f\"{DATE_TIME_DELTA}\"+\"\\ decision\\ windows]}$\",\n",
        "      'suptitle': f'EVALUATION OF X__Alloc POLICY'+'\\n'+f'(first {First_n_t} records)'+'\\n'+ \\\n",
        "      f'L = {L}, T = {T}, '+ \\\n",
        "      r\"$\\theta^* =$(\"+ \\\n",
        "        str(f'{Best_theta_Alloc_evalu_opt[0]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc_evalu_opt[1]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc_evalu_opt[2]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc_evalu_opt[3]:,.2f}')+\", \"+\n",
        "        f'{Best_theta_Alloc_evalu_opt[4]}'+\"), \" \\\n",
        "    }),\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "KH2urmmEKBrt",
        "outputId": "ca63568f-9b5c-41c6-80e7-a9691361bcb1"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  ## last_n_l = int(.99*L)\n",
        "  Last_n_l = int(1.0*L)\n",
        "  Policy(None).plot_expFhat_charts(\n",
        "    means={\n",
        "        'AllocBelow optimal': ThetaStar_expCbarcum_Alloc_evalu_opt[-Last_n_l:],\n",
        "        'AllocBelow non-optimal': ThetaStar_expCbarcum_Alloc_evalu_non[-Last_n_l:],\n",
        "    },\n",
        "    stdvs={\n",
        "        'AllocBelow optimal': ThetaStar_expCtilcum_Alloc_evalu_opt[-Last_n_l:],\n",
        "        'AllocBelow non-optimal': ThetaStar_expCtilcum_Alloc_evalu_non[-Last_n_l:],\n",
        "    },\n",
        "    labelX='Sample paths, ' + r'$\\ell$',\n",
        "    ## labelY='Profit\\n[Allocs]',\n",
        "    labelY='',\n",
        "    suptitle=f\"Comparison of Optimal/Non-optimal Policies after Evaluation\\n \\\n",
        "      L = {L}, T = {T}\\n \\\n",
        "      last {Last_n_l} records\\n \\\n",
        "      ('exp' refers to expanding)\",\n",
        "    pars=defaultdict(str, {\n",
        "      'colors': ['m', 'c']\n",
        "    }),\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs2nvn6OMLPV"
      },
      "source": [
        "Next, we evaluate with a single sample-path:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cId2si2XhcnJ",
        "outputId": "d943c1a9-0341-4b0d-e02a-ac6ea48fb06e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2 s, sys: 1 s, total: 3 s\n",
            "Wall time: 4.53 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "## will show error due to division by 0 because L=1; OK for our purposes\n",
        "## 1min 31s [colab]\n",
        "## 1min 5s  [mac mini]\n",
        "if 'LEARN' in MODES:\n",
        "  L = 1\n",
        "  T = 7*SLOTS_PER_DAY\n",
        "  First_n_t = int(1*L*T)\n",
        "  do_evalu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Pmb74EMrXn",
        "outputId": "2a6a1ea4-6df2-40bf-88c1-b4fff4057e2b"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES: print(L, T, RESOLUTION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  Policy(None).plot_records(\n",
        "  # plot_records(  \n",
        "    df=Df_Alloc_evalu_opt,\n",
        "    df_non=Df_Alloc_evalu_non, \n",
        "    # df_non=None, #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    pars=defaultdict(str, {\n",
        "      'thCumSlots': Best_theta_Alloc_evalu_opt.thCumSlots,\n",
        "      'thSickProb': Best_theta_Alloc_evalu_opt.thSickProb,\n",
        "      'thCumSlotsNon': Best_theta_Alloc_evalu_non.thCumSlots,\n",
        "      'thSickProbNon': Best_theta_Alloc_evalu_non.thSickProb,\n",
        "      'legendLabels': [r'$\\mathrm{opt}$', r'$\\mathrm{non}$'],\n",
        "      'xlabel': \"$t\\ \\mathrm{[\"+f\"{DATE_TIME_DELTA}\"+\"\\ decision\\ windows]}$\",\n",
        "      'suptitle': f'EVALUATION OF X__Alloc POLICY'+'\\n'+f'(first {First_n_t} records)'+'\\n'+ \\\n",
        "      f'L = {L}, T = {T}, '+ \\\n",
        "      r\"$\\theta^* =$(\"+ \\\n",
        "        str(f'{Best_theta_Alloc_evalu_opt[0]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc_evalu_opt[1]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc_evalu_opt[2]:,.2f}')+\", \"+ \\\n",
        "        str(f'{Best_theta_Alloc_evalu_opt[3]:,.2f}')+\", \"+\n",
        "        f'{Best_theta_Alloc_evalu_opt[4]}'+\"), \" \\\n",
        "    }),\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mEXVKOpOBze",
        "outputId": "db8ba7d5-b9f7-4c0b-8b0c-086ca6ea245f"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  print(Df_Alloc_evalu_opt[Df_Alloc_evalu_opt['t']==T-1][['Ccum']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_blrj0E3OBo8",
        "outputId": "fce5293b-26dc-48a3-bb23-e7e7f76a41ec"
      },
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  print(Df_Alloc_evalu_non[Df_Alloc_evalu_non['t']==T-1][['Ccum']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vFT55RDQb-q"
      },
      "source": [
        "From the `Ccum` plot we see that the cumulative reward for the optimal policy keeps on rising. The non-optimal policy does not do as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWMpHM5NOtk7"
      },
      "source": [
        "#### 4.6.3 Comparison of Optimized Policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "5SPgHH9gOA4p"
      },
      "outputs": [],
      "source": [
        "## hide\n",
        "## P.plot_evalu_comparison(\n",
        "#   df1=df_BuyBelow_evalu_opt,\n",
        "#   df2=df_Bellman_evalu_opt,\n",
        "#   df3=None,\n",
        "#   pars= defaultdict(str, {\n",
        "#     'suptitle': f'EVALUATION OF ALL POLICIES (first {first_n_t} records)\\n \\\n",
        "#     L={L}, T={T}',\n",
        "#   }),\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGxf2RD26KON"
      },
      "source": [
        "## 5 EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "0ZXU6MqXoZcz"
      },
      "outputs": [],
      "source": [
        "def print_schedule_shifts(df):\n",
        "  mask = df.columns.str.contains('Allocd_t')\n",
        "  resource_allocs = list(df.columns[mask])\n",
        "  sched = copy(df)\n",
        "  schedule = sched[['dt']+resource_allocs]\n",
        "\n",
        "  print(f\"SCHEDULE SHIFTS:\")\n",
        "  print(f\"===============\")\n",
        "  for res_alloc in resource_allocs:\n",
        "    _,_,id,resType,_,_,_ = res_alloc.split('_')\n",
        "    resName = id+'_'+resType\n",
        "    print(f'\\n************** {resName}:')\n",
        "    sched_list = list(schedule.loc[\n",
        "      schedule[res_alloc] == True,\n",
        "      ['dt', res_alloc]\n",
        "    ]['dt'])\n",
        "    if len(sched_list) > 0:\n",
        "      ts_1 = sched_list[0]\n",
        "      dow_1 = sched_list[0].day_of_week\n",
        "      print(f\"{(sched_list[0]-pd.Timedelta(DATE_TIME_DELTA)).strftime('%a %b %d %Hh%M')}\")\n",
        "      for ts in sched_list:\n",
        "        dow = ts.day_of_week\n",
        "        if dow != dow_1:\n",
        "          print(f\"{(ts_1).strftime('%a %b %d %Hh%M')}\\n\")\n",
        "          print(f\"{(ts-pd.Timedelta(DATE_TIME_DELTA)).strftime('%a %b %d %Hh%M')}\")\n",
        "        dow_1 = dow\n",
        "        ts_1 = ts\n",
        "      print(f\"{(sched_list[-1]).strftime('%a %b %d %Hh%M')}\")\n",
        "  print(f'\\n{CONTIGUOUS_REWARD=}')\n",
        "  print(f'{MAX_DAILY_SLOT_RUN=} ({RESOLUTION}s)')\n",
        "  print(f'{TH_CumSlots_SPEC=}')\n",
        "  print(f'{TH_SickProb_SPEC=}')\n",
        "  print(f'{TH_CumMerits_SPEC=}')\n",
        "  print(f'{TH_ContSlots_SPEC=}')\n",
        "  print(f'{TH_Select_SPEC=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  print_schedule_shifts(Df_Alloc_evalu_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gap_minutes(resolution):\n",
        "  if resolution == 'QUARTER_HOUR':\n",
        "    return 15\n",
        "  elif resolution == 'HOUR':\n",
        "    return 60\n",
        "  elif resolution == 'BLOCK_8_HOUR':\n",
        "    return 480\n",
        "  else:\n",
        "    print(f'ERROR: Invalid RESOLUTION: {RESOLUTION}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "DGrRIgIVRG5K"
      },
      "outputs": [],
      "source": [
        "def print_schedule_slots(df):\n",
        "  gap_mins = gap_minutes(RESOLUTION)\n",
        "  mask = df.columns.str.contains('Allocd_t')\n",
        "  resource_allocs = list(df.columns[mask])\n",
        "  sched = copy(df)\n",
        "  schedule = sched[['dt']+resource_allocs]\n",
        "\n",
        "  print(f\"SCHEDULE SLOTS:\")\n",
        "  print(f\"===============\")\n",
        "  n_gaps = 0\n",
        "  for res_alloc in resource_allocs:\n",
        "    _,_,id,resType,_,_,_ = res_alloc.split('_')\n",
        "    resName = id+'_'+resType\n",
        "    print(f'\\n************** {resName}:')\n",
        "    sched_list = list(schedule.loc[\n",
        "      schedule[res_alloc] == True,\n",
        "      ['dt', res_alloc]\n",
        "    ]['dt'])\n",
        "    if len(sched_list) > 0:\n",
        "      ## print each slot and indicate gaps\n",
        "      ts_1 = sched_list[0]\n",
        "      dow_1 = -1\n",
        "      for ts in sched_list:\n",
        "        dow = ts.day_of_week\n",
        "        if dow != dow_1: print('')\n",
        "        if (int((ts.to_datetime64() - ts_1.to_datetime64())/(1e9*60)) > gap_mins)\\\n",
        "          and (dow == dow_1):\n",
        "          n_gaps += 1\n",
        "          print(f\"{(ts-pd.Timedelta(DATE_TIME_DELTA)).strftime('%a %b %d %Hh%M')} GAP\")\n",
        "        else:\n",
        "          print(f\"{(ts-pd.Timedelta(DATE_TIME_DELTA)).strftime('%a %b %d %Hh%M')}\")\n",
        "        dow_1 = dow\n",
        "        ts_1 = ts\n",
        "  print(f'\\nTOTAL NUMBER OF GAPS FOR ALL RESOURCES: {n_gaps}')\n",
        "  print(f'{CONTIGUOUS_REWARD=}')\n",
        "  print(f'{MAX_DAILY_SLOT_RUN=} ({RESOLUTION}s)')\n",
        "  print(f'{TH_CumSlots_SPEC=}')\n",
        "  print(f'{TH_SickProb_SPEC=}')\n",
        "  print(f'{TH_CumMerits_SPEC=}')\n",
        "  print(f'{TH_ContSlots_SPEC=}')\n",
        "  print(f'{TH_Select_SPEC=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'LEARN' in MODES:\n",
        "  print_schedule_slots(Df_Alloc_evalu_opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-1Cx0uSnrk1"
      },
      "source": [
        "## 6 DEPLOYMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['APPLY']"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "U4GinisHKNZD"
      },
      "outputs": [],
      "source": [
        "def get_best_theta_Alloc():\n",
        "  best_theta_Alloc = \\\n",
        "    Policy(None).build_theta({\n",
        "      'thCumSlots': BEST_THETA_Alloc[0],\n",
        "      'thSickProb': BEST_THETA_Alloc[1],\n",
        "      'thCumMerits': BEST_THETA_Alloc[2],\n",
        "      'thContSlots': BEST_THETA_Alloc[3],\n",
        "      'thSelect': BEST_THETA_Alloc[4]\n",
        "    })\n",
        "  return best_theta_Alloc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCpz89kqbWvU",
        "outputId": "c71d19a9-853f-43a5-e3ce-5b78cf302fc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Theta(thCumSlots=0, thSickProb=0, thCumMerits=0, thContSlots=1, thSelect='random')"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_best_theta_Alloc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "NXfVopcpMC8Z"
      },
      "outputs": [],
      "source": [
        "def do_apply():\n",
        "  global DEM, MER, \\\n",
        "  ThetaStar_expCbarcum_Alloc_evalu_opt, ThetaStar_expCtilcum_Alloc_evalu_opt, \\\n",
        "  Best_theta_Alloc_evalu_opt, Worst_theta_Alloc_evalu_opt, \\\n",
        "  Record_Alloc_evalu_opt, Df_Alloc_evalu_opt\n",
        "\n",
        "  M = Model()\n",
        "  P = Policy(M)\n",
        "  ## DEM = DemandSimulator(seed=SEED_EVALU)\n",
        "  ## MER = MeritSimulator(seed=SEED_EVALU)\n",
        "  thetasOpt = []; thetasOpt.append(get_best_theta_Alloc()) ##from storage\n",
        "  ThetaStar_expCbarcum_Alloc_evalu_opt, ThetaStar_expCtilcum_Alloc_evalu_opt, \\\n",
        "  _, _, \\\n",
        "  Best_theta_Alloc_evalu_opt, Worst_theta_Alloc_evalu_opt, \\\n",
        "  _, _, \\\n",
        "  _, _, \\\n",
        "  Record_Alloc_evalu_opt = \\\n",
        "    P.perform_grid_search_sample_paths('X__Alloc', thetasOpt)\n",
        "  Df_Alloc_evalu_opt = pd.DataFrame.from_records(\n",
        "      Record_Alloc_evalu_opt[:First_n_t], columns=Labels)\n",
        "  print(\n",
        "    f'{ThetaStar_expCbarcum_Alloc_evalu_opt.iloc[-1]=:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "C1Nz1yyaasJk"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# ## to test\n",
        "# MODES = ['LEARN', 'APPLY']\n",
        "# if 'APPLY' in MODES:\n",
        "#   L = 1\n",
        "#   T = 7*SLOTS_PER_DAY\n",
        "#   First_n_t = int(1*L*T)\n",
        "#   do_apply()\n",
        "#   print_schedule_shifts(Df_Alloc_evalu_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMyvhfmWN6tL",
        "outputId": "28ef39d9-9eb8-47e8-edb4-d2d4dfdc6ce9"
      },
      "outputs": [],
      "source": [
        "# if 'APPLY' in MODES: print(L, T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "NpTsiZJg6tAm"
      },
      "outputs": [],
      "source": [
        "from io import StringIO\n",
        "def prepare_schedule_shifts(df, buf):\n",
        "  mask = df.columns.str.contains('Allocd_t')\n",
        "  resource_allocs = list(df.columns[mask])\n",
        "  sched = copy(df)\n",
        "  schedule = sched[['dt']+resource_allocs]\n",
        "\n",
        "  buf.write(f\"SCHEDULE SHIFTS:\\n\")\n",
        "  buf.write(f\"================\\n\")\n",
        "  for res_alloc in resource_allocs:\n",
        "    _,_,id,resType,_,_,_ = res_alloc.split('_')\n",
        "    resName = id+'_'+resType\n",
        "    buf.write(f'\\n************** {resName}:\\n')\n",
        "    sched_list = list(schedule.loc[\n",
        "      schedule[res_alloc] == True,\n",
        "      ['dt', res_alloc]\n",
        "    ]['dt'])\n",
        "    if len(sched_list) > 0:\n",
        "      ts_1 = sched_list[0]\n",
        "      dow_1 = sched_list[0].day_of_week\n",
        "      buf.write(f\"{(sched_list[0]-pd.Timedelta(DATE_TIME_DELTA)).strftime('%a %b %d %Hh%M')}\\n\")\n",
        "      for ts in sched_list:\n",
        "        dow = ts.day_of_week\n",
        "        if dow != dow_1:\n",
        "          buf.write(f\"{(ts_1).strftime('%a %b %d %Hh%M')}\\n\\n\")\n",
        "          buf.write(f\"{(ts-pd.Timedelta(DATE_TIME_DELTA)).strftime('%a %b %d %Hh%M')}\\n\")\n",
        "        dow_1 = dow\n",
        "        ts_1 = ts\n",
        "      buf.write(f\"{(sched_list[-1]).strftime('%a %b %d %Hh%M')}\\n\")\n",
        "  buf.write(f'\\n{CONTIGUOUS_REWARD=}\\n')\n",
        "  buf.write(f'{MAX_DAILY_SLOT_RUN=} ({RESOLUTION}s)\\n')\n",
        "  buf.write(f'{TH_CumSlots_SPEC=}\\n')\n",
        "  buf.write(f'{TH_SickProb_SPEC=}\\n')\n",
        "  buf.write(f'{TH_CumMerits_SPEC=}\\n')\n",
        "  buf.write(f'{TH_ContSlots_SPEC=}\\n')\n",
        "  buf.write(f'{TH_Select_SPEC=}\\n')\n",
        "  return buf.getvalue()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "qY5ZKfJ_bt1E"
      },
      "outputs": [],
      "source": [
        "from io import StringIO\n",
        "def prepare_schedule_slots(df, buf):\n",
        "  gap_mins = gap_minutes(RESOLUTION)\n",
        "  mask = df.columns.str.contains('Allocd_t')\n",
        "  resource_allocs = list(df.columns[mask])\n",
        "  sched = copy(df)\n",
        "  schedule = sched[['dt']+resource_allocs]\n",
        "\n",
        "  buf.write(f\"SCHEDULE SLOTS:\\n\")\n",
        "  buf.write(f\"===============\\n\")\n",
        "  n_gaps = 0\n",
        "  for res_alloc in resource_allocs:\n",
        "    _,_,id,resType,_,_,_ = res_alloc.split('_')\n",
        "    resName = id+'_'+resType\n",
        "    buf.write(f'\\n************** {resName}:\\n')\n",
        "    sched_list = list(schedule.loc[\n",
        "      schedule[res_alloc] == True,\n",
        "      ['dt', res_alloc]\n",
        "    ]['dt'])\n",
        "    if len(sched_list) > 0:\n",
        "      ## print each slot and indicate gaps\n",
        "      ts_1 = sched_list[0]\n",
        "      dow_1 = -1\n",
        "      for ts in sched_list:\n",
        "        dow = ts.day_of_week\n",
        "        if dow != dow_1: buf.write('\\n')\n",
        "        if (int((ts.to_datetime64() - ts_1.to_datetime64())/(1e9*60)) > gap_mins)\\\n",
        "          and (dow == dow_1):\n",
        "          n_gaps += 1\n",
        "          buf.write(f\"{(ts-pd.Timedelta(DATE_TIME_DELTA)).strftime('%a %b %d %Hh%M')} GAP\\n\")\n",
        "        else:\n",
        "          buf.write(f\"{(ts-pd.Timedelta(DATE_TIME_DELTA)).strftime('%a %b %d %Hh%M')}\\n\")\n",
        "        dow_1 = dow\n",
        "        ts_1 = ts\n",
        "  buf.write(f'\\nTOTAL NUMBER OF GAPS FOR ALL RESOURCES: {n_gaps}\\n')\n",
        "  buf.write(f'{CONTIGUOUS_REWARD=}\\n')\n",
        "  buf.write(f'{MAX_DAILY_SLOT_RUN=} ({RESOLUTION}s)\\n')\n",
        "  buf.write(f'{TH_CumSlots_SPEC=}\\n')\n",
        "  buf.write(f'{TH_SickProb_SPEC=}\\n')\n",
        "  buf.write(f'{TH_CumMerits_SPEC=}\\n')\n",
        "  buf.write(f'{TH_ContSlots_SPEC=}\\n')\n",
        "  buf.write(f'{TH_Select_SPEC=}\\n')\n",
        "  return buf.getvalue()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "mRIjmw9JUWe-"
      },
      "outputs": [],
      "source": [
        "@anvil.server.callable\n",
        "def get_schedule(start, slots_per_day, max_daily_slot_run, resources, demands_per_busyness, resource_expenses):\n",
        "  ## this is function, not an if statement where globals can just be used\n",
        "  global START_DATE_TIME, SLOTS_PER_DAY, MAX_DAILY_SLOT_RUN, RESOURCE_TYPES, \\\n",
        "  RESOURCE_TYPE_COUNTS, TYPES, RESOURCE_IDS, DEMANDS_PER_BUSYNESS, DEMAND_PER_BUSYNESS, \\\n",
        "  RESOURCE_EXPENSES, RESOURCE_EXPENSE, \\\n",
        "  aNAMES, bNAMES, abNAMES, Labels, \\\n",
        "  L, T, First_n_t, \\\n",
        "  ThetaStar_expCbarcum_Alloc_evalu_opt, ThetaStar_expCtilcum_Alloc_evalu_opt, \\\n",
        "  Best_theta_Alloc_evalu_opt, Df_Alloc_evalu_opt\n",
        "\n",
        "  START_DATE_TIME = start\n",
        "  sd = pd.to_datetime(start)\n",
        "  if not sd.strftime('%a')=='Mon':\n",
        "    error = f\"ERROR: {start} is a {sd.strftime('%A')}. It should be a Monday.\"\n",
        "    print(error)\n",
        "    # return f\"ERROR: {start} is a {sd.strftime('%A')}. It should be a Monday.\"\n",
        "    return error\n",
        "  for_now_sd = pd.to_datetime('2023-12-04')\n",
        "  if not sd==for_now_sd:\n",
        "    error = f\"ERROR: Start date must be {for_now_sd} for now.\"\n",
        "    print(error) \n",
        "    # return f\"ERROR: Start date must be {for_now_sd} for now.\"\n",
        "    return error\n",
        "\n",
        "  spd = int(slots_per_day)\n",
        "  if not spd == 24:\n",
        "    error = f\"ERROR: Slots per day must be 24 for now.\"\n",
        "    print(error)\n",
        "    # return f\"ERROR: Slots per day must be 24 for now.\"\n",
        "    return error\n",
        "  SLOTS_PER_DAY = spd\n",
        "  \n",
        "  mdsr = int(max_daily_slot_run)\n",
        "  if not mdsr <= spd:\n",
        "    error = f\"ERROR: 'Max daily slot run' must be less than or equal to 'Slots per day'\"\n",
        "    print(error)\n",
        "    # return f\"ERROR: 'Max daily slot run' must be less than or equal to 'Slots per day'\"\n",
        "    return error\n",
        "  MAX_DAILY_SLOT_RUN = mdsr\n",
        "\n",
        "  # /////////////////////////////////\n",
        "  resource_type_and_ids = resources.split(';')\n",
        "  resource_types = []\n",
        "  resource_ids = []\n",
        "  resource_type_counts = []\n",
        "  for itm in resource_type_and_ids:\n",
        "      res_type, res_ids = itm.split(':')\n",
        "      resource_types.append(res_type.strip())\n",
        "      sep_ids = res_ids.split(','); ##print(f'{sep_ids=}')\n",
        "      for rid in sep_ids:\n",
        "          resource_ids.append(rid.strip())\n",
        "      resource_type_counts.append(len(sep_ids))\n",
        "  print(f'{resource_types=}')\n",
        "  print(f'{resource_type_counts=}')\n",
        "  print(f'{resource_ids=}')\n",
        "  if len(resource_types) > MAX_RESOURCE_TYPES:\n",
        "    error = f\"ERROR: The number of resource types should not exceed {MAX_RESOURCE_TYPES}.\\nYou entered the following resource types: {resource_types}\"\n",
        "    print(error)\n",
        "    #  return \\\n",
        "    #   f\"ERROR: The number of resource types should not exceed {MAX_RESOURCE_TYPES}.\\nYou entered the following resource types: {resource_types}\"\n",
        "    return error\n",
        "  if len(resource_ids) > MAX_RESOURCE_IDS:\n",
        "    error = f\"ERROR: The number of resources should not exceed {MAX_RESOURCE_IDS}.\\nYou entered the following resources: {resource_ids}\"\n",
        "    print(error)\n",
        "    # return \\\n",
        "    #   f\"ERROR: The number of resources should not exceed {MAX_RESOURCE_IDS}.\\nYou entered the following resources: {resource_ids}\"\n",
        "    return error\n",
        "  RESOURCE_TYPES = resource_types; print(f'{RESOURCE_TYPES=}')\n",
        "  RESOURCE_TYPE_COUNTS = resource_type_counts; print(f'{RESOURCE_TYPE_COUNTS=}')\n",
        "  TYPES = []\n",
        "  for i in range(len(RESOURCE_TYPES)):\n",
        "    additional_types = [RESOURCE_TYPES[i]]*RESOURCE_TYPE_COUNTS[i]\n",
        "    for item in additional_types:\n",
        "      TYPES.append(item)\n",
        "  print(f'{TYPES=}')\n",
        "  RESOURCE_IDS = resource_ids; print(f'{RESOURCE_TYPE_COUNTS=}')\n",
        "\n",
        "  # rates = busyness_rates.split(',')\n",
        "  rates = demands_per_busyness.split(',')\n",
        "  if '' in rates:\n",
        "    error = f\"ERROR: There should be a demand-per-busyness for each resource type (role).\\nYou entered the following values: {demands_per_busyness}\"\n",
        "    print(error)\n",
        "    return error\n",
        "  rates = list(map(lambda x: float(x), rates))\n",
        "  print(f'{rates=}')\n",
        "  if len(rates) != len(RESOURCE_TYPES):\n",
        "    error = f\"ERROR: The number of demands-per-busyness should be the same as the number of resource types (roles).\\nYou entered the following values: {demands_per_busyness}\"\n",
        "    print(error)\n",
        "    return error\n",
        "  DEMANDS_PER_BUSYNESS = rates\n",
        "  DEMAND_PER_BUSYNESS = {e: DEMANDS_PER_BUSYNESS[i] for i,e in enumerate(RESOURCE_TYPES)}\n",
        "\n",
        "  expenses = resource_expenses.split(',')\n",
        "  if '' in expenses:\n",
        "    error = f\"ERROR: There should be a resource expense for each resource type (role).\\nYou entered the following values: {resource_expenses}\"\n",
        "    print(error)\n",
        "    return error  \n",
        "  expenses = list(map(lambda x: float(x), expenses))\n",
        "  print(f'{expenses=}')\n",
        "  if len(expenses) != len(RESOURCE_TYPES):\n",
        "    error = f\"ERROR: The number of resource expenses should be the same as the number of resource types (roles).\\nYou entered the following values: {resource_expenses}\"\n",
        "    print(error)\n",
        "    return error\n",
        "  RESOURCE_EXPENSES = expenses\n",
        "  RESOURCE_EXPENSE = {e: RESOURCE_EXPENSES[i] for i,e in enumerate(RESOURCE_TYPES)}\n",
        "\n",
        "  aNAMES = [tup[0]+'_'+tup[1] for tup in zip(TYPES, RESOURCE_IDS)]; print(f'{aNAMES=}')\n",
        "  bNAMES = RESOURCE_TYPES; print(f'{bNAMES=}')\n",
        "  abNAMES = [] ##to DEMAND b\n",
        "  for a in aNAMES:\n",
        "    a0,a1 = a.split('_')\n",
        "    for b in bNAMES:\n",
        "      if(a0==b):\n",
        "        abn = (a + '___' + b)\n",
        "        abNAMES.append(abn)\n",
        "  print(f'{abNAMES=}')\n",
        "  Labels = setup_plot_labels()\n",
        "  # \\\\\\\\\\\\\\\\\n",
        "\n",
        "  L = 1 ##set global L\n",
        "  T = 7*SLOTS_PER_DAY ##set global T\n",
        "  First_n_t = int(1*L*T) ##set global first_n_t\n",
        "\n",
        "  ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "  do_apply()\n",
        "  ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "\n",
        "  buf = StringIO()\n",
        "  ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "  ## prepped_sched = prepare_schedule_slots(Df_Alloc_evalu_opt, buf)\n",
        "  prepped_sched = prepare_schedule_shifts(Df_Alloc_evalu_opt, buf)\n",
        "  ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "  buf.close()\n",
        "\n",
        "  return prepped_sched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1tfhO4JWcco",
        "outputId": "0db321b4-51f3-4821-d630-1d6debb4e431"
      },
      "outputs": [],
      "source": [
        "# ## test\n",
        "# # MODES = ['LEARN', 'APPLY']\n",
        "# if 'APPLY' in MODES:\n",
        "#     # res = get_schedule(start='2023-12-04', slots_per_day=24, max_daily_slot_run=8)\n",
        "#     res = get_schedule(\n",
        "#         start='2023-12-04', \n",
        "#         slots_per_day=24, \n",
        "#         max_daily_slot_run=8, \n",
        "#         resources = 'Manager: John, Penelope; SalesPerson: Sally, Sarah, Jim, Costa',\n",
        "#         # resources = 'SupChief: Ruan, Francine; Sup: Azra, Wendie, Penny, Sally'\n",
        "#         # resources = 'ChiefTeller: Ruan, Francine; Teller: Azra, Wendie, Penny, Sally'\n",
        "#         # busyness_rates = '.2, 4',\n",
        "#         demands_per_busyness = '.2, 4',\n",
        "#         resource_expenses = '35.17, 23.85'\n",
        "#     )\n",
        "# res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if 'APPLY' in MODES: \n",
        "#   print(START_DATE_TIME, SLOTS_PER_DAY, MAX_DAILY_SLOT_RUN, L, T, First_n_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## test\n",
        "# if 'APPLY' in MODES:\n",
        "#   print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "## if 'APPLY' in MODES:\n",
        "#   Policy(None).plot_records(\n",
        "#   # plot_records(  \n",
        "#     df=Df_Alloc_evalu_opt,\n",
        "#     # df_non=Df_Alloc_evalu_non, \n",
        "#     df_non=None,\n",
        "#     pars=defaultdict(str, {\n",
        "#       'thCumSlots': Best_theta_Alloc_evalu_opt.thCumSlots,\n",
        "#       'thSickProb': Best_theta_Alloc_evalu_opt.thSickProb,\n",
        "#       # 'thCumSlotsNon': Best_theta_Alloc_evalu_non.thCumSlots,\n",
        "#       # 'thSickProbNon': Best_theta_Alloc_evalu_non.thSickProb,\n",
        "#       'legendLabels': [r'$\\mathrm{opt}$', r'$\\mathrm{non}$'],\n",
        "#       'suptitle': f'EVALUATION OF X__Alloc POLICY'+'\\n'+f'(first {First_n_t} records)'+'\\n'+ \\\n",
        "#       f'L = {L}, T = {T}, '+ \\\n",
        "#       r\"$\\theta^* =$(\"+ \\\n",
        "#         str(f'{Best_theta_Alloc_evalu_opt[0]:,.2f}')+\", \"+ \\\n",
        "#         str(f'{Best_theta_Alloc_evalu_opt[1]:,.2f}')+\", \"+ \\\n",
        "#         str(f'{Best_theta_Alloc_evalu_opt[2]:,.2f}')+\", \"+ \\\n",
        "#         str(f'{Best_theta_Alloc_evalu_opt[3]:,.2f}')+\", \"+\n",
        "#         f'{Best_theta_Alloc_evalu_opt[4]}'+\"), \" \\\n",
        "#     }),\n",
        "#   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Ur6K9__VeR6B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resource_types=['Manager', 'Supervisor', 'SalesPerson']\n",
            "resource_type_counts=[2, 1, 4]\n",
            "resource_ids=['John', 'Penelope', 'Me', 'Sally', 'Sarah', 'Jim', 'Costa']\n",
            "RESOURCE_TYPES=['Manager', 'Supervisor', 'SalesPerson']\n",
            "RESOURCE_TYPE_COUNTS=[2, 1, 4]\n",
            "TYPES=['Manager', 'Manager', 'Supervisor', 'SalesPerson', 'SalesPerson', 'SalesPerson', 'SalesPerson']\n",
            "RESOURCE_TYPE_COUNTS=[2, 1, 4]\n",
            "rates=[0.2, 0.3, 4.0]\n",
            "expenses=[35.0, 23.0, 23.0]\n",
            "aNAMES=['Manager_John', 'Manager_Penelope', 'Supervisor_Me', 'SalesPerson_Sally', 'SalesPerson_Sarah', 'SalesPerson_Jim', 'SalesPerson_Costa']\n",
            "bNAMES=['Manager', 'Supervisor', 'SalesPerson']\n",
            "abNAMES=['Manager_John___Manager', 'Manager_Penelope___Manager', 'Supervisor_Me___Supervisor', 'SalesPerson_Sally___SalesPerson', 'SalesPerson_Sarah___SalesPerson', 'SalesPerson_Jim___SalesPerson', 'SalesPerson_Costa___SalesPerson']\n",
            "numThetas=1\n",
            "... printing every 1th theta (if considered) ...\n",
            "\t%%% l=1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_30590/896625506.py:132: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  Ctilcum_tmp = np.sum(np.square(np.array(CcumIomega__lI) - Cbarcum_tmp))/(L - 1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/0, 36,999, Theta(thCumSlots=0, thSickProb=0, thCumMerits=0, thContSlots=1, thSelect='random')\n",
            "ThetaStar_expCbarcum_Alloc_evalu_opt.iloc[-1]=36999.00\n",
            "resource_types=['Manager', 'Supervisor', 'SalesPerson']\n",
            "resource_type_counts=[2, 1, 4]\n",
            "resource_ids=['John', 'Penelope', 'Me', 'Sally', 'Sarah', 'Jim', 'Costa']\n",
            "RESOURCE_TYPES=['Manager', 'Supervisor', 'SalesPerson']\n",
            "RESOURCE_TYPE_COUNTS=[2, 1, 4]\n",
            "TYPES=['Manager', 'Manager', 'Supervisor', 'SalesPerson', 'SalesPerson', 'SalesPerson', 'SalesPerson']\n",
            "RESOURCE_TYPE_COUNTS=[2, 1, 4]\n",
            "rates=[0.2, 0.3, 4.0]\n",
            "ERROR: There should be a resource expense for each resource type (role).\n",
            "You entered the following values: 35,23,,\n",
            "resource_types=['Manager', 'Supervisor', 'SalesPerson']\n",
            "resource_type_counts=[2, 1, 4]\n",
            "resource_ids=['John', 'Penelope', 'Me', 'Sally', 'Sarah', 'Jim', 'Costa']\n",
            "RESOURCE_TYPES=['Manager', 'Supervisor', 'SalesPerson']\n",
            "RESOURCE_TYPE_COUNTS=[2, 1, 4]\n",
            "TYPES=['Manager', 'Manager', 'Supervisor', 'SalesPerson', 'SalesPerson', 'SalesPerson', 'SalesPerson']\n",
            "RESOURCE_TYPE_COUNTS=[2, 1, 4]\n",
            "rates=[0.2, 0.3, 4.0]\n",
            "expenses=[35.0, 23.0]\n",
            "ERROR: The number of resource expenses should be the same as the number of resource types (roles).\n",
            "You entered the following values: 35,23\n",
            "resource_types=['Manager', 'Supervisor', 'SalesPerson']\n",
            "resource_type_counts=[2, 1, 4]\n",
            "resource_ids=['John', 'Penelope', 'Me', 'Sally', 'Sarah', 'Jim', 'Costa']\n",
            "RESOURCE_TYPES=['Manager', 'Supervisor', 'SalesPerson']\n",
            "RESOURCE_TYPE_COUNTS=[2, 1, 4]\n",
            "TYPES=['Manager', 'Manager', 'Supervisor', 'SalesPerson', 'SalesPerson', 'SalesPerson', 'SalesPerson']\n",
            "RESOURCE_TYPE_COUNTS=[2, 1, 4]\n",
            "rates=[0.2, 0.3, 4.0]\n",
            "expenses=[35.0, 23.0, 24.0]\n",
            "aNAMES=['Manager_John', 'Manager_Penelope', 'Supervisor_Me', 'SalesPerson_Sally', 'SalesPerson_Sarah', 'SalesPerson_Jim', 'SalesPerson_Costa']\n",
            "bNAMES=['Manager', 'Supervisor', 'SalesPerson']\n",
            "abNAMES=['Manager_John___Manager', 'Manager_Penelope___Manager', 'Supervisor_Me___Supervisor', 'SalesPerson_Sally___SalesPerson', 'SalesPerson_Sarah___SalesPerson', 'SalesPerson_Jim___SalesPerson', 'SalesPerson_Costa___SalesPerson']\n",
            "numThetas=1\n",
            "... printing every 1th theta (if considered) ...\n",
            "\t%%% l=1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_30590/896625506.py:132: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  Ctilcum_tmp = np.sum(np.square(np.array(CcumIomega__lI) - Cbarcum_tmp))/(L - 1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0/0, 36,586, Theta(thCumSlots=0, thSickProb=0, thCumMerits=0, thContSlots=1, thSelect='random')\n",
            "ThetaStar_expCbarcum_Alloc_evalu_opt.iloc[-1]=36586.00\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPPLY\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m MODES:\n\u001b[0;32m----> 2\u001b[0m   \u001b[43manvil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_forever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/anvil/server.py:437\u001b[0m, in \u001b[0;36mwait_forever\u001b[0;34m()\u001b[0m\n\u001b[1;32m    435\u001b[0m _get_connection()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 437\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if 'APPLY' in MODES:\n",
        "  anvil.server.wait_forever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
